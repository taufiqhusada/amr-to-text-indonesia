{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2db3ee0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T00:03:52.415014Z",
     "iopub.status.busy": "2022-05-24T00:03:52.413227Z",
     "iopub.status.idle": "2022-05-24T00:04:26.037135Z",
     "shell.execute_reply": "2022-05-24T00:04:26.036321Z",
     "shell.execute_reply.started": "2022-05-18T07:58:29.043157Z"
    },
    "papermill": {
     "duration": 33.6609,
     "end_time": "2022-05-24T00:04:26.037307",
     "exception": false,
     "start_time": "2022-05-24T00:03:52.376407",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.15.0)\r\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (0.1.96)\r\n",
      "Collecting indobenchmark-toolkit==0.0.4\r\n",
      "  Downloading indobenchmark_toolkit-0.0.4-py3-none-any.whl (8.0 kB)\r\n",
      "Collecting sacrebleu\r\n",
      "  Downloading sacrebleu-2.1.0-py3-none-any.whl (92 kB)\r\n",
      "     |████████████████████████████████| 92 kB 3.5 MB/s             \r\n",
      "\u001b[?25hCollecting datasets==1.4.1\r\n",
      "  Downloading datasets-1.4.1-py3-none-any.whl (186 kB)\r\n",
      "     |████████████████████████████████| 186 kB 27.0 MB/s            \r\n",
      "\u001b[?25hCollecting sentencepiece\r\n",
      "  Downloading sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2 MB)\r\n",
      "     |████████████████████████████████| 1.2 MB 58.2 MB/s            \r\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.7.1 in /opt/conda/lib/python3.7/site-packages (from indobenchmark-toolkit==0.0.4) (1.9.1)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets==1.4.1->indobenchmark-toolkit==0.0.4) (1.20.3)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets==1.4.1->indobenchmark-toolkit==0.0.4) (2.26.0)\r\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets==1.4.1->indobenchmark-toolkit==0.0.4) (0.3.4)\r\n",
      "Collecting xxhash\r\n",
      "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\r\n",
      "     |████████████████████████████████| 212 kB 56.7 MB/s            \r\n",
      "\u001b[?25hRequirement already satisfied: fsspec in /opt/conda/lib/python3.7/site-packages (from datasets==1.4.1->indobenchmark-toolkit==0.0.4) (2022.2.0)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets==1.4.1->indobenchmark-toolkit==0.0.4) (4.11.2)\r\n",
      "Collecting huggingface-hub==0.0.2\r\n",
      "  Downloading huggingface_hub-0.0.2-py3-none-any.whl (24 kB)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets==1.4.1->indobenchmark-toolkit==0.0.4) (1.3.5)\r\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets==1.4.1->indobenchmark-toolkit==0.0.4) (0.70.12.2)\r\n",
      "Collecting tqdm<4.50.0,>=4.27\r\n",
      "  Downloading tqdm-4.49.0-py2.py3-none-any.whl (69 kB)\r\n",
      "     |████████████████████████████████| 69 kB 5.4 MB/s             \r\n",
      "\u001b[?25hRequirement already satisfied: pyarrow>=0.17.1 in /opt/conda/lib/python3.7/site-packages (from datasets==1.4.1->indobenchmark-toolkit==0.0.4) (6.0.1)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub==0.0.2->datasets==1.4.1->indobenchmark-toolkit==0.0.4) (3.4.2)\r\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.3)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\r\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.47)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\r\n",
      "Collecting transformers\r\n",
      "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\r\n",
      "     |████████████████████████████████| 4.2 MB 37.2 MB/s            \r\n",
      "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\r\n",
      "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\r\n",
      "     |████████████████████████████████| 6.6 MB 36.3 MB/s            \r\n",
      "\u001b[?25hCollecting transformers\r\n",
      "  Downloading transformers-4.19.1-py3-none-any.whl (4.2 MB)\r\n",
      "     |████████████████████████████████| 4.2 MB 44.6 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.19.0-py3-none-any.whl (4.2 MB)\r\n",
      "     |████████████████████████████████| 4.2 MB 42.2 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\r\n",
      "     |████████████████████████████████| 4.0 MB 39.4 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\r\n",
      "     |████████████████████████████████| 3.8 MB 34.3 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\r\n",
      "     |████████████████████████████████| 3.5 MB 46.9 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.16.1-py3-none-any.whl (3.5 MB)\r\n",
      "     |████████████████████████████████| 3.5 MB 34.6 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.16.0-py3-none-any.whl (3.5 MB)\r\n",
      "     |████████████████████████████████| 3.5 MB 33.9 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.14.1-py3-none-any.whl (3.4 MB)\r\n",
      "     |████████████████████████████████| 3.4 MB 30.1 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.13.0-py3-none-any.whl (3.3 MB)\r\n",
      "     |████████████████████████████████| 3.3 MB 36.7 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\r\n",
      "     |████████████████████████████████| 3.1 MB 28.0 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.12.4-py3-none-any.whl (3.1 MB)\r\n",
      "     |████████████████████████████████| 3.1 MB 42.2 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.12.3-py3-none-any.whl (3.1 MB)\r\n",
      "     |████████████████████████████████| 3.1 MB 33.5 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.12.2-py3-none-any.whl (3.1 MB)\r\n",
      "     |████████████████████████████████| 3.1 MB 32.7 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.12.1-py3-none-any.whl (3.1 MB)\r\n",
      "     |████████████████████████████████| 3.1 MB 51.2 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.12.0-py3-none-any.whl (3.1 MB)\r\n",
      "     |████████████████████████████████| 3.1 MB 43.2 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.11.3-py3-none-any.whl (2.9 MB)\r\n",
      "     |████████████████████████████████| 2.9 MB 29.2 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.11.2-py3-none-any.whl (2.9 MB)\r\n",
      "     |████████████████████████████████| 2.9 MB 36.6 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.11.1-py3-none-any.whl (2.9 MB)\r\n",
      "     |████████████████████████████████| 2.9 MB 31.6 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.11.0-py3-none-any.whl (2.9 MB)\r\n",
      "     |████████████████████████████████| 2.9 MB 24.6 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.10.3-py3-none-any.whl (2.8 MB)\r\n",
      "     |████████████████████████████████| 2.8 MB 34.8 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.10.2-py3-none-any.whl (2.8 MB)\r\n",
      "     |████████████████████████████████| 2.8 MB 30.5 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.10.1-py3-none-any.whl (2.8 MB)\r\n",
      "     |████████████████████████████████| 2.8 MB 27.0 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.10.0-py3-none-any.whl (2.8 MB)\r\n",
      "     |████████████████████████████████| 2.8 MB 37.3 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.9.2-py3-none-any.whl (2.6 MB)\r\n",
      "     |████████████████████████████████| 2.6 MB 45.7 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.9.1-py3-none-any.whl (2.6 MB)\r\n",
      "     |████████████████████████████████| 2.6 MB 33.3 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.9.0-py3-none-any.whl (2.6 MB)\r\n",
      "     |████████████████████████████████| 2.6 MB 14.7 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.8.2-py3-none-any.whl (2.5 MB)\r\n",
      "     |████████████████████████████████| 2.5 MB 41.2 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.8.1-py3-none-any.whl (2.5 MB)\r\n",
      "     |████████████████████████████████| 2.5 MB 35.9 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.8.0-py3-none-any.whl (2.5 MB)\r\n",
      "     |████████████████████████████████| 2.5 MB 30.0 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.7.0-py3-none-any.whl (2.5 MB)\r\n",
      "     |████████████████████████████████| 2.5 MB 45.9 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.6.1-py3-none-any.whl (2.2 MB)\r\n",
      "     |████████████████████████████████| 2.2 MB 42.1 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.6.0-py3-none-any.whl (2.3 MB)\r\n",
      "     |████████████████████████████████| 2.3 MB 37.2 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.5.1-py3-none-any.whl (2.1 MB)\r\n",
      "     |████████████████████████████████| 2.1 MB 41.0 MB/s            \r\n",
      "\u001b[?25hRequirement already satisfied: portalocker in /opt/conda/lib/python3.7/site-packages (from sacrebleu) (2.4.0)\r\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.7/site-packages (from sacrebleu) (0.8.9)\r\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.7/site-packages (from sacrebleu) (0.4.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets==1.4.1->indobenchmark-toolkit==0.0.4) (3.1)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets==1.4.1->indobenchmark-toolkit==0.0.4) (2.0.9)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets==1.4.1->indobenchmark-toolkit==0.0.4) (1.26.7)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets==1.4.1->indobenchmark-toolkit==0.0.4) (2021.10.8)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.7.1->indobenchmark-toolkit==0.0.4) (4.1.1)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets==1.4.1->indobenchmark-toolkit==0.0.4) (3.6.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.6)\r\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.1.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.16.0)\r\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (8.0.3)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets==1.4.1->indobenchmark-toolkit==0.0.4) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets==1.4.1->indobenchmark-toolkit==0.0.4) (2021.3)\r\n",
      "Installing collected packages: tqdm, xxhash, huggingface-hub, transformers, sentencepiece, datasets, sacrebleu, indobenchmark-toolkit\r\n",
      "  Attempting uninstall: tqdm\r\n",
      "    Found existing installation: tqdm 4.62.3\r\n",
      "    Uninstalling tqdm-4.62.3:\r\n",
      "      Successfully uninstalled tqdm-4.62.3\r\n",
      "  Attempting uninstall: huggingface-hub\r\n",
      "    Found existing installation: huggingface-hub 0.2.1\r\n",
      "    Uninstalling huggingface-hub-0.2.1:\r\n",
      "      Successfully uninstalled huggingface-hub-0.2.1\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.15.0\r\n",
      "    Uninstalling transformers-4.15.0:\r\n",
      "      Successfully uninstalled transformers-4.15.0\r\n",
      "  Attempting uninstall: sentencepiece\r\n",
      "    Found existing installation: sentencepiece 0.1.96\r\n",
      "    Uninstalling sentencepiece-0.1.96:\r\n",
      "      Successfully uninstalled sentencepiece-0.1.96\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "beatrix-jupyterlab 3.1.6 requires google-cloud-bigquery-storage, which is not installed.\r\n",
      "spacy 3.2.2 requires typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\", but you have typing-extensions 4.1.1 which is incompatible.\r\n",
      "featuretools 1.6.0 requires numpy>=1.21.0, but you have numpy 1.20.3 which is incompatible.\r\n",
      "cached-path 1.0.2 requires huggingface-hub<0.3.0,>=0.0.12, but you have huggingface-hub 0.0.2 which is incompatible.\r\n",
      "cached-path 1.0.2 requires tqdm<4.63,>=4.62, but you have tqdm 4.49.0 which is incompatible.\r\n",
      "allennlp 2.9.0 requires huggingface-hub>=0.0.16, but you have huggingface-hub 0.0.2 which is incompatible.\r\n",
      "allennlp 2.9.0 requires tqdm>=4.62, but you have tqdm 4.49.0 which is incompatible.\u001b[0m\r\n",
      "Successfully installed datasets-1.4.1 huggingface-hub-0.0.2 indobenchmark-toolkit-0.0.4 sacrebleu-2.1.0 sentencepiece-0.1.95 tqdm-4.49.0 transformers-4.5.1 xxhash-3.0.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers sentencepiece indobenchmark-toolkit==0.0.4 sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d51352c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T00:04:26.249003Z",
     "iopub.status.busy": "2022-05-24T00:04:26.243636Z",
     "iopub.status.idle": "2022-05-24T00:04:30.125212Z",
     "shell.execute_reply": "2022-05-24T00:04:30.123871Z",
     "shell.execute_reply.started": "2022-05-18T07:59:01.201387Z"
    },
    "papermill": {
     "duration": 3.985314,
     "end_time": "2022-05-24T00:04:30.125367",
     "exception": false,
     "start_time": "2022-05-24T00:04:26.140053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'amr-to-text-indonesia'...\r\n",
      "remote: Enumerating objects: 2123, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (268/268), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (199/199), done.\u001b[K\r\n",
      "remote: Total 2123 (delta 74), reused 153 (delta 37), pack-reused 1855\u001b[K\r\n",
      "Receiving objects: 100% (2123/2123), 19.11 MiB | 14.48 MiB/s, done.\r\n",
      "Resolving deltas: 100% (840/840), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://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@github.com/taufiqhusada/amr-to-text-indonesia.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88ef53f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T00:04:30.349718Z",
     "iopub.status.busy": "2022-05-24T00:04:30.343948Z",
     "iopub.status.idle": "2022-05-24T00:04:43.720201Z",
     "shell.execute_reply": "2022-05-24T00:04:43.720802Z",
     "shell.execute_reply.started": "2022-05-18T07:59:06.961607Z"
    },
    "papermill": {
     "duration": 13.488941,
     "end_time": "2022-05-24T00:04:43.721116",
     "exception": false,
     "start_time": "2022-05-24T00:04:30.232175",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'amr-indo-dataset'...\r\n",
      "remote: Enumerating objects: 71, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (5/5), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (5/5), done.\u001b[K\r\n",
      "remote: Total 71 (delta 1), reused 3 (delta 0), pack-reused 66\u001b[K\r\n",
      "Unpacking objects: 100% (71/71), 60.94 MiB | 5.61 MiB/s, done.\r\n",
      "Updating files: 100% (34/34), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://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@github.com/taufiqhusada/amr-indo-dataset.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1640a43a",
   "metadata": {
    "papermill": {
     "duration": 0.122355,
     "end_time": "2022-05-24T00:04:43.969138",
     "exception": false,
     "start_time": "2022-05-24T00:04:43.846783",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Finetune indot5 with linearized penman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf279ec6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T00:04:44.223869Z",
     "iopub.status.busy": "2022-05-24T00:04:44.222862Z",
     "iopub.status.idle": "2022-05-24T00:04:44.227952Z",
     "shell.execute_reply": "2022-05-24T00:04:44.229262Z"
    },
    "papermill": {
     "duration": 0.136638,
     "end_time": "2022-05-24T00:04:44.229483",
     "exception": false,
     "start_time": "2022-05-24T00:04:44.092845",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/amr-to-text-indonesia/train\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/amr-to-text-indonesia/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6db4a023",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T00:04:44.484428Z",
     "iopub.status.busy": "2022-05-24T00:04:44.483518Z",
     "iopub.status.idle": "2022-05-24T00:04:45.227227Z",
     "shell.execute_reply": "2022-05-24T00:04:45.226357Z"
    },
    "papermill": {
     "duration": 0.874383,
     "end_time": "2022-05-24T00:04:45.227375",
     "exception": false,
     "start_time": "2022-05-24T00:04:44.352992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Branch 'hyperparam_tuning_again' set up to track remote branch 'hyperparam_tuning_again' from 'origin'.\r\n",
      "Switched to a new branch 'hyperparam_tuning_again'\r\n"
     ]
    }
   ],
   "source": [
    "!git checkout hyperparam_tuning_again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d52bd4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T00:04:45.478047Z",
     "iopub.status.busy": "2022-05-24T00:04:45.477175Z",
     "iopub.status.idle": "2022-05-24T00:13:51.328503Z",
     "shell.execute_reply": "2022-05-24T00:13:51.329242Z"
    },
    "papermill": {
     "duration": 545.979196,
     "end_time": "2022-05-24T00:13:51.329453",
     "exception": false,
     "start_time": "2022-05-24T00:04:45.350257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\r\n",
      "Downloading: 100%|███████████████████████████| 777k/777k [00:00<00:00, 1.79MB/s]\r\n",
      "Downloading: 100%|██████████████████████████████| 696/696 [00:00<00:00, 480kB/s]\r\n",
      "Downloading: 100%|███████████████████████████| 990M/990M [00:32<00:00, 30.8MB/s]\r\n",
      "added 9 tokens\r\n",
      "len train dataset:  2648\r\n",
      "len dev dataset:  19\r\n",
      "len test dataset: 306\r\n",
      "len train dataloader:  662\r\n",
      "(Epoch 1) TRAIN LOSS:2.7781 LR:0.00010000: 100%|█| 662/662 [01:33<00:00,  7.10it\r\n",
      "(Epoch 1) DEV LOSS:7.6389 LR:0.00010000: 100%|████| 5/5 [00:00<00:00, 24.58it/s]\r\n",
      "bleu score on dev:  0.9750760375995845\r\n",
      "(Epoch 2) TRAIN LOSS:5.1025 LR:0.00010000: 100%|█| 662/662 [01:32<00:00,  7.17it\r\n",
      "(Epoch 2) DEV LOSS:1.7064 LR:0.00010000: 100%|████| 5/5 [00:00<00:00, 27.91it/s]\r\n",
      "bleu score on dev:  17.56128478482164\r\n",
      "(Epoch 3) TRAIN LOSS:1.6329 LR:0.00010000: 100%|█| 662/662 [01:32<00:00,  7.18it\r\n",
      "(Epoch 3) DEV LOSS:1.1906 LR:0.00010000: 100%|████| 5/5 [00:00<00:00, 28.90it/s]\r\n",
      "bleu score on dev:  26.583318552734863\r\n",
      "(Epoch 4) TRAIN LOSS:1.0766 LR:0.00010000: 100%|█| 662/662 [01:31<00:00,  7.25it\r\n",
      "(Epoch 4) DEV LOSS:0.7588 LR:0.00010000: 100%|████| 5/5 [00:00<00:00, 28.34it/s]\r\n",
      "bleu score on dev:  39.296245282119386\r\n",
      "(Epoch 5) TRAIN LOSS:0.7720 LR:0.00010000: 100%|█| 662/662 [01:32<00:00,  7.19it\r\n",
      "(Epoch 5) DEV LOSS:0.7447 LR:0.00010000: 100%|████| 5/5 [00:00<00:00, 28.14it/s]\r\n",
      "bleu score on dev:  38.93927240957322\r\n",
      "  0%|                                                    | 0/77 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|███████████████████████████████████████████| 77/77 [00:18<00:00,  4.26it/s]\r\n",
      "sample:  balon ditipu oleh ilham ---- balon itu ditiup ilham\r\n",
      "sample:  puisi ditulis oleh obe ---- obe menulis puisi\r\n",
      "sample:  saya mengetik makalah ---- saya mengetik makalah\r\n",
      "sample:  anak ajaib yang angga anak yang ajaib ---- angga anak ajaib\r\n",
      "sample:  ibu seorang dosen ---- ibuku seorang dosen\r\n",
      "bleu score on test dataset:  39.79074619078503\r\n",
      "saya mengetik makalah\r\n"
     ]
    }
   ],
   "source": [
    "!python train_indoT5.py --model_type indo-t5 --n_epochs 5 --lr 0.0001 --data_folder ../data/preprocessed_data/linearized_penman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29311fd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T00:13:55.262290Z",
     "iopub.status.busy": "2022-05-24T00:13:55.261309Z",
     "iopub.status.idle": "2022-05-24T00:13:56.194599Z",
     "shell.execute_reply": "2022-05-24T00:13:56.193764Z"
    },
    "papermill": {
     "duration": 3.000882,
     "end_time": "2022-05-24T00:13:56.194845",
     "exception": false,
     "start_time": "2022-05-24T00:13:53.193963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu_score_test.txt  model\t\t   test_label.txt\r\n",
      "loss_data.tsv\t     test_generations.txt  tokenizer\r\n"
     ]
    }
   ],
   "source": [
    "!ls result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c039220c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T00:14:01.155499Z",
     "iopub.status.busy": "2022-05-24T00:14:01.154730Z",
     "iopub.status.idle": "2022-05-24T00:15:21.179162Z",
     "shell.execute_reply": "2022-05-24T00:15:21.178382Z"
    },
    "papermill": {
     "duration": 82.535231,
     "end_time": "2022-05-24T00:15:21.179349",
     "exception": false,
     "start_time": "2022-05-24T00:13:58.644118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: result/ (stored 0%)\r\n",
      "  adding: result/.gitignore (stored 0%)\r\n",
      "  adding: result/test_label.txt (deflated 60%)\r\n",
      "  adding: result/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/loss_data.tsv (deflated 36%)\r\n",
      "  adding: result/model/ (stored 0%)\r\n",
      "  adding: result/model/config.json (deflated 44%)\r\n",
      "  adding: result/model/pytorch_model.bin (deflated 11%)\r\n",
      "  adding: result/tokenizer/ (stored 0%)\r\n",
      "  adding: result/tokenizer/tokenizer_config.json (deflated 81%)\r\n",
      "  adding: result/tokenizer/added_tokens.json (deflated 43%)\r\n",
      "  adding: result/tokenizer/special_tokens_map.json (deflated 82%)\r\n",
      "  adding: result/tokenizer/spiece.model (deflated 49%)\r\n",
      "  adding: result/test_generations.txt (deflated 63%)\r\n"
     ]
    }
   ],
   "source": [
    "!zip -r result_without_sta.zip result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a4cf7bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T00:15:25.673538Z",
     "iopub.status.busy": "2022-05-24T00:15:25.672483Z",
     "iopub.status.idle": "2022-05-24T00:15:25.676911Z",
     "shell.execute_reply": "2022-05-24T00:15:25.677719Z"
    },
    "papermill": {
     "duration": 2.471579,
     "end_time": "2022-05-24T00:15:25.677946",
     "exception": false,
     "start_time": "2022-05-24T00:15:23.206367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/amr-to-text-indonesia/evaluate\n"
     ]
    }
   ],
   "source": [
    "%cd ../evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34d7eef3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T00:15:30.035336Z",
     "iopub.status.busy": "2022-05-24T00:15:30.034370Z",
     "iopub.status.idle": "2022-05-24T00:17:43.508774Z",
     "shell.execute_reply": "2022-05-24T00:17:43.508140Z"
    },
    "papermill": {
     "duration": 135.643288,
     "end_time": "2022-05-24T00:17:43.508992",
     "exception": false,
     "start_time": "2022-05-24T00:15:27.865704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model folder ../train/result\r\n",
      "preprocessing method linearized_penman\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data’: File exists\r\n",
      "preprocess amr_simple_test\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/amr_simple_test’: File exists\r\n",
      "Namespace(mode='linearized_penman', result_amr_path='data/test/preprocessed_data/amr_simple_test/test.amr.txt', result_sent_path='data/test/preprocessed_data/amr_simple_test/test.sent.txt', source_file_path='data/test/amr_simple_test.txt', source_folder_path=None)\r\n",
      "100%|███████████████████████████████████| 2618/2618 [00:00<00:00, 137783.90it/s]\r\n",
      "total: 306 pair sent-amr\r\n",
      "preprocess b-salah-darat\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/b-salah-darat’: File exists\r\n",
      "Namespace(mode='linearized_penman', result_amr_path='data/test/preprocessed_data/b-salah-darat/test.amr.txt', result_sent_path='data/test/preprocessed_data/b-salah-darat/test.sent.txt', source_file_path='data/test/b-salah-darat.txt', source_folder_path=None)\r\n",
      "100%|██████████████████████████████████████| 676/676 [00:00<00:00, 73802.63it/s]\r\n",
      "total: 32 pair sent-amr\r\n",
      "preprocess c-gedung-roboh\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/c-gedung-roboh’: File exists\r\n",
      "Namespace(mode='linearized_penman', result_amr_path='data/test/preprocessed_data/c-gedung-roboh/test.amr.txt', result_sent_path='data/test/preprocessed_data/c-gedung-roboh/test.sent.txt', source_file_path='data/test/c-gedung-roboh.txt', source_folder_path=None)\r\n",
      "100%|██████████████████████████████████████| 606/606 [00:00<00:00, 88822.62it/s]\r\n",
      "total: 29 pair sent-amr\r\n",
      "preprocess d-indo-fuji\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/d-indo-fuji’: File exists\r\n",
      "Namespace(mode='linearized_penman', result_amr_path='data/test/preprocessed_data/d-indo-fuji/test.amr.txt', result_sent_path='data/test/preprocessed_data/d-indo-fuji/test.sent.txt', source_file_path='data/test/d-indo-fuji.txt', source_folder_path=None)\r\n",
      "100%|██████████████████████████████████████| 745/745 [00:00<00:00, 95972.13it/s]\r\n",
      "total: 27 pair sent-amr\r\n",
      "preprocess f-bunuh-diri\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/f-bunuh-diri’: File exists\r\n",
      "Namespace(mode='linearized_penman', result_amr_path='data/test/preprocessed_data/f-bunuh-diri/test.amr.txt', result_sent_path='data/test/preprocessed_data/f-bunuh-diri/test.sent.txt', source_file_path='data/test/f-bunuh-diri.txt', source_folder_path=None)\r\n",
      "100%|█████████████████████████████████████| 468/468 [00:00<00:00, 114350.13it/s]\r\n",
      "total: 23 pair sent-amr\r\n",
      "preprocess g-gempa-dieng\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/g-gempa-dieng’: File exists\r\n",
      "Namespace(mode='linearized_penman', result_amr_path='data/test/preprocessed_data/g-gempa-dieng/test.amr.txt', result_sent_path='data/test/preprocessed_data/g-gempa-dieng/test.sent.txt', source_file_path='data/test/g-gempa-dieng.txt', source_folder_path=None)\r\n",
      "100%|█████████████████████████████████████| 412/412 [00:00<00:00, 110765.54it/s]\r\n",
      "total: 19 pair sent-amr\r\n",
      "mkdir: cannot create directory ‘result’: File exists\r\n",
      "evaluate on data amr_simple_test\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='../train/result/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"../train/result/model\",\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 306\r\n",
      "  0%|                                                    | 0/77 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|███████████████████████████████████████████| 77/77 [00:19<00:00,  4.03it/s]\r\n",
      "sample:  balon ditipu oleh ilham ---- balon itu ditiup ilham\r\n",
      "sample:  puisi ditulis oleh obe ---- obe menulis puisi\r\n",
      "sample:  saya mengetik makalah ---- saya mengetik makalah\r\n",
      "sample:  anak ajaib yang angga anak yang ajaib ---- angga anak ajaib\r\n",
      "sample:  ibu seorang dosen ---- ibuku seorang dosen\r\n",
      "sample:  dia berenang ---- dia sedang berenang\r\n",
      "sample:  buku yang hilang dicari oleh ilham ---- ilham sedang mencari bukunya yang hilang\r\n",
      "sample:  ibu menyapu halaman rumah ---- ibu sedang menyapu halaman rumah\r\n",
      "sample:  ayah sedang membajak padi di sawah ---- ayah sedang membajak padi di sawah\r\n",
      "sample:  andi pergi kemah di tepi pantai ---- andi pergi berkemah di tepi pantai\r\n",
      "bleu score on test dataset:  39.79074619078503\r\n",
      "evaluate on data b-salah-darat\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='../train/result/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"../train/result/model\",\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 32\r\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:04<00:00,  1.85it/s]\r\n",
      "sample:  di bandara soekarnohatta, terjadi insiden tumpang dari lion air dari mei 10 2016 ---- kantor imigrasi bandara soekarno-hatta bersama kantor otoritas bandara soekarno-hatta dan pt angkasa pura ii membahas insiden penumpang penerbangan pesawat lion air jt 161 yang tiba di jakarta dari singapura 10 mei 2016.\r\n",
      "sample:  di kantor imigrasi soekarnohatta, kepala kantor imigrasi alif suadi menyampaikan soal ---- kami meeting soal ini,\" ujar kepala kantor imigrasi soekarno-hatta alif suadi kepada tempo, sabtu malam ini, 14 mei 2016.\r\n",
      "sample:  anak teman natalie berangkat ke singapura pada pukul 18 55 ---- anak temannya natalie berangkat dari singapura dan menggunakan pesawat lion air jt 161, pada pukul 18.50.\r\n",
      "sample:  pt angkasa pura ii yang akan mengelola bandara internasional soekarnohatta ---- sekretaris perusahaan pt angkasa pura ii agus haryadi mengatakan selaku pengelola bandara internasional soekarno-hatta, pihaknya akan berkoordinasi dengan kantor otoritas bandara wilayah i terkait dengan peristiwa ini.\r\n",
      "sample:  kami bersiap-siap di bandara parkir di remote area ---- setiap pesawat yang parkir di remote area sudah kami siapkan bus untuk mengantar penumpang ke terminal.\r\n",
      "sample:  di padang, edward mengaku mendapat bantuan sopir jemput tumpang ---- terdapat sopir bus yang akan menjemput penumpang dari padang\" ujar edward.\r\n",
      "sample:  di bandara soetta, pihak otoritas bandara soetta memanggil dan melakukan investigasi ---- pihak otoritas bandara soetta akan memanggil pihak terkait dan dilakukan investigasi.\r\n",
      "sample:  kemenhub memberikan sanksi kepada pihakpihak yang lalai ---- kemenhub memberikan sanksi kepada pihak-pihak yang lalai,\" ujarnya.\r\n",
      "sample:  zara kutip cerita temannya di terminal ii ---- pesawat itu mendarat tidak di terminal ii, kata zara mengutip cerita temannya.\r\n",
      "sample:  kami bersiap-siap di bandara parkir di remote area ---- setiap pesawat yang parkir di remote area sudah kami siapkan bus untuk mengantar penumpang ke terminal.\r\n",
      "bleu score on test dataset:  6.148195649764363\r\n",
      "evaluate on data c-gedung-roboh\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='../train/result/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"../train/result/model\",\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 29\r\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:04<00:00,  1.82it/s]\r\n",
      "sample:  flyover yang indomobil lakukan di atas jalan boulevard bintaro xchange dan indomobil tujukan ke arah boulevard ---- pengalihan dilakukan bagi pengendara yang melaju dari arah mal bintaro xchange dan tol bintaro menuju jalan boulevard bintaro dengan menggunakan flyover di atas lampu merah indomobil.\r\n",
      "sample:  di jakarta timur, terjadi keruntuhan dan saidah saidah ---- kegagalan struktur dan kesalahan tes tanah yang mengakibatkan gedung miring juga terjadi pada menara saidah di jalan mt haryono, jakarta timur.\r\n",
      "sample:  di bintaro, terjadi peristiwa roboh gedung ---- kapolres tangerang selatan, akbp ayi supardan membenarkan peristiwa robohnya gedung di bintaro yang menarik perhatian masyarakat banyak.\r\n",
      "sample:  panin memutuskan untuk melanjutkan pembangunan gedung tersebut ---- panin memutuskan tidak melanjutkan pembangunan gedung itu karena dinyatakan tidak lulus uji kelayakan.\r\n",
      "sample:  di gedung tersebut, gedung tersebut dinyatakan lulus ujian ---- gedung tersebut dinyatakan tidak lulus uji sehingga pembangunan gedung diputuskan tidak dilanjutkan.\r\n",
      "sample:  di polres tangerang selatan, tersangka akp samian sedang melakukan selidik ---- kasat reskrim polres tangerangg selatan, akp samian mengatakan saat ini pihaknya melakukan penyelidikan untuk mengetahui penyebab runtuhnya gedung.\r\n",
      "sample:  kami masih bersiaga dalam peristiwa tersebut hingga ini ---- hingga kini kami masih mendalami peristiwa tersebut.\r\n",
      "sample:  dia menyebut dirinya sebagai korban ---- kejadian tersebut tidak timbul korban.\r\n",
      "sample:  pada akhirnya terjadi kerugian material ---- terjadi kerugian material.\r\n",
      "sample:  di sektor bintaro tangerang selatan, terjadi kecelaan ---- pembongkaran gedung di sektor 7, bintaro, tangerang selatan, diduga menyalahi prosedur.\r\n",
      "bleu score on test dataset:  6.395186702862145\r\n",
      "evaluate on data d-indo-fuji\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='../train/result/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"../train/result/model\",\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 27\r\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:04<00:00,  1.42it/s]\r\n",
      "sample:  indosat dengan fujitsu indonesia menandatangani nota kesepakatan dalam rangka meningkatkan jaringan bisnis ---- indosat ooredoo bersama fujitsu indonesia menandatangani nota kesepahaman dalam rangka memantapkan kemitraan dengan para pelanggan bisnis yang telah dibangun dalam menghadirkan solusi smart mobility dan internet of things.\r\n",
      "sample:  indosat dengan fujitsu indonesia menandatangani nota kesepakatan dalam rangka meningkatkan jaringan bisnis ---- indosat ooredoo bersama fujitsu indonesia menandatangani nota kesepahaman dalam rangka memantapkan kemitraan dengan para pelanggan bisnis yang telah dibangun dalam menghadirkan solusi smart mobility dan internet of things.\r\n",
      "sample:  smart mobility iot dan iot mengubah cara usaha dalam mengelola aset ---- smart mobility dan iot mengalami perkembangan cukup signifikan sehingga mengubah cara perusahaan dalam mengelola aset.\r\n",
      "sample:  indosat dengan fujitsu indonesia menandatangani nota kesepakatan dalam rangka meningkatkan jaringan bisnis ---- indosat ooredoo bersama fujitsu indonesia menandatangani nota kesepahaman dalam rangka memantapkan kemitraan dengan para pelanggan bisnis yang telah menghadirkan solusi smart mobility dan internet of things.\r\n",
      "sample:  di sektor transportasi dan otomotif, kerja sama dilakukan oleh perusahaan-perusahaan di indonesia ---- kerja sama ini akan berfokus pada sektor otomotif dan transportasi dan akan diperluas ke berbagai sektor industri untuk memenuhi kebutuhan pelanggan korporasi di indonesia.\r\n",
      "sample:  achmad sofwan menyampaikan keluhannya kepada president achmad sofwan ---- mobilitas akan menyediakan cara untuk mengoptimalkan strategi perusahaan dengan memanfaatkan aplikasi dan layanan yang dapat memproses data real-time, tutur achmad sofwan, president director fujitsu indonesia.\r\n",
      "sample:  di sektor transportasi dan otomotif, kerja sama dilakukan oleh perusahaan-perusahaan di indonesia ---- kerja sama ini akan berfokus pada sektor otomotif dan transportasi dan akan diperluas ke berbagai sektor industri untuk memenuhi kebutuhan pelanggan korporasi di indonesia.\r\n",
      "sample:  indosat ooredoo sedang mengerjakan solusi smart mobility dan fujitsu dengan indonesia ---- indosat ooredoo bekerja sama dengan fujitsu indonesia menghadirkan solusi smart mobility dan internet of things.\r\n",
      "sample:  achmad sofwan menyampaikan keluhannya kepada direktur fujitsu ---- president director fujitsu, achmad sofwan mengungkap, mobilitas akan menyediakan cara mengoptimalisasikan strategi perusahaan dengan memanfaatkan aplikasi dan layanan dalam aktivitas memproses data real-time.\r\n",
      "sample:  di sektor transportasi dan otomotif, kerja sama dilakukan oleh perusahaan-perusahaan di indonesia ---- kerja sama ini akan berfokus pada sektor otomotif dan transportasi dan akan diperluas ke berbagai sektor industri untuk memenuhi kebutuhan pelanggan korporasi di indonesia.\r\n",
      "bleu score on test dataset:  3.374432831402254\r\n",
      "evaluate on data f-bunuh-diri\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='../train/result/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"../train/result/model\",\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 23\r\n",
      "  0%|                                                     | 0/6 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:03<00:00,  1.81it/s]\r\n",
      "sample:  di jembatan kira tingginya, ciptadi melompat ---- ciptadi dengan nekat melompat dari megatron jembatan penyeberangan orang yang tingginya diperkirakan mencapai 15 meter.\r\n",
      "sample:  di mapolrestabes bandung, hal tersebut diungkapkan oleh kasubag reny marthaliana ---- hal tersebut diungkapkan kabag ops polrestabes bandung kompol dede rojudin didampingi kasubag humas kompol reny marthaliana, saat ditemui di mapolrestabes bandung, jumat.\r\n",
      "sample:  di kota bandung, rezha mengaku warga kota bandung ---- rezha noviana, warga kota bandung mengatakan ia dan jemaat lainnya langsung memperhatikan megatron jembatan penyeberangan orang depan kantor pos besar bandung setelah bubar salat jumat di masjid raya bandung.\r\n",
      "sample:  satpam dan satpam di atas jpo ---- ketika itu, petugas linmas dan beberapa satpam berdiri di atas jpo.\r\n",
      "sample:  di alun bandung, aksi bunuh diri ---- aksi bunuh diri di alun - alun bandung belum lama ini terjadi.\r\n",
      "sample:  orang tua terjatuh di jalanan bandung ---- seorang pria tua nekat menjatuhkan diri dari jpo di alun - alun kota bandung.\r\n",
      "sample:  sudirman menjadi saksi mata bunuh diri di alun bandung ---- sudirman, anggota linmas satpol pp kota bandung yang menjadi saksi mata aksi bunuh diri di alun - alun bandung itu mengatakan, pria tersebut diperkirakan berusia 50 tahun.\r\n",
      "sample:  di depan bandung, dirinya terjatuh ---- seorang lelaki menjatuhkan diri dari megatron jembatan penyeberangan di depan pos giro besar bandung, bandung, jumat.\r\n",
      "sample:  di tengah padatnya lalu jalan asia afrika, hidup diakhiri oleh lelaki tengah baya ---- seorang lelaki tengah baya nekat mengakhiri hidupnya di tengah kepadatan lalu lintas jalan asia afrika.\r\n",
      "sample:  asia afrika dibuat oleh pria misterius ---- pria misterius yang bunuh diri dari jembatan penyeberangan orang di jalan asia afrika, bandung, jawa barat, membuat pesan sebelum nekat terjun.\r\n",
      "bleu score on test dataset:  5.822249377105071\r\n",
      "evaluate on data g-gempa-dieng\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='../train/result/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"../train/result/model\",\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 19\r\n",
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:02<00:00,  1.77it/s]\r\n",
      "sample:  dieng, gempa berkekuatan 4 8 skala richter terjadi pada pukul 19 wib ---- stasiun geofisika badan meteorologi klimatologi dan geofisika banjarnegara, jawa tengah, menyatakan bahwa gempa yang mengguncang dataran tinggi dieng pukul 19.00 wib berkekuatan 4,8 pada skala richter.\r\n",
      "sample:  di desa tersebut, ada tanji yang gugur ---- pusat gempa diperkirakan berada di desa tanji gugur, kecamatan bawang, kabupaten batang.\r\n",
      "sample:  di jalan dekat kawah desa sumberejo, ditutup sementara ---- pvmbg merekomendasikan seluruh jalan yang mendekati kawah timbang di desa sumberejo sementara ditutup.\r\n",
      "sample:  dieng, kepala vulkanologi mitigasi bencana geologi terjadi pada pukul 19 wib ---- kepala pusat vulkanologi dan mitigasi bencana geologi surono mengatakan bahwa gempa yang terjadi di dataran tinggi dieng pukul 19.00 wib terekam sebanyak 86 kali.\r\n",
      "sample:  di lapangan, tim ukur konsentrasi gas dilakukan ---- penutupan ini dilakukan hingga tim di lapangan yang mengukur konsentrasi gas menyatakan tidak ada gas yang berbahaya.\r\n",
      "sample:  di jalan dekat kawah desa sumberejo, ditutup sementara ---- pvmbg merekomendasikan seluruh jalan yang mendekati kawah timbang di desa sumberejo sementara ditutup.\r\n",
      "sample:  di kawah timbang, petugas vulkanologi melakukan pemantauan dan beri informasi ---- petugas pusat vulkanologi dan mitigasi bencana geologi diterjunkan untuk memantau aktivitas kawah timbang dan memberikan informasi.\r\n",
      "sample:  di pusat vulkanologi, semua data yang dikeluarkan oleh pusat vulkanologi mitigasi bencana geologi ---- data yang dikeluarkan dari pusat vulkanologi dan mitigasi bencana geologi menyebutkan gempa mulai terasa pukul 19.00 wib dan telah terekam gempa sebanyak 86 kali.\r\n",
      "sample:  sabtu pagi, ungsi di ungsi ---- pengungsi di kabupaten banjarnegara, pada sabtu pagi mulai meninggalkan pengungsian.\r\n",
      "sample:  dieng, gempa berkekuatan 4 8 skala richter mengguncang pada pukul 19 wib ---- stasiun geofisika badan meteorologi klimatologi dan geofisika banjarnegara menyatakan gempa yang mengguncang dataran tinggi dieng pukul 19.00 wib berkekuatan 4,8 skala richter *(sr)*.\r\n",
      "bleu score on test dataset:  6.751436144181087\r\n",
      "mv: cannot move 'result/linearized_penman' to a subdirectory of itself, 'result/linearized_penman/linearized_penman'\r\n"
     ]
    }
   ],
   "source": [
    "!chmod +x ./evaluate_indoT5_to_all.sh\n",
    "!mkdir result\n",
    "!./evaluate_indoT5_to_all.sh ../train/result linearized_penman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17c133e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T00:17:47.713361Z",
     "iopub.status.busy": "2022-05-24T00:17:47.712497Z",
     "iopub.status.idle": "2022-05-24T00:17:48.459517Z",
     "shell.execute_reply": "2022-05-24T00:17:48.459011Z"
    },
    "papermill": {
     "duration": 2.936903,
     "end_time": "2022-05-24T00:17:48.459695",
     "exception": false,
     "start_time": "2022-05-24T00:17:45.522792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: result/ (stored 0%)\r\n",
      "  adding: result/linearized_penman/ (stored 0%)\r\n",
      "  adding: result/linearized_penman/c-gedung-roboh/ (stored 0%)\r\n",
      "  adding: result/linearized_penman/c-gedung-roboh/test_label.txt (deflated 62%)\r\n",
      "  adding: result/linearized_penman/c-gedung-roboh/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/linearized_penman/c-gedung-roboh/test_generations.txt (deflated 60%)\r\n",
      "  adding: result/linearized_penman/g-gempa-dieng/ (stored 0%)\r\n",
      "  adding: result/linearized_penman/g-gempa-dieng/test_label.txt (deflated 67%)\r\n",
      "  adding: result/linearized_penman/g-gempa-dieng/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/linearized_penman/g-gempa-dieng/test_generations.txt (deflated 62%)\r\n",
      "  adding: result/linearized_penman/b-salah-darat/ (stored 0%)\r\n",
      "  adding: result/linearized_penman/b-salah-darat/test_label.txt (deflated 66%)\r\n",
      "  adding: result/linearized_penman/b-salah-darat/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/linearized_penman/b-salah-darat/test_generations.txt (deflated 61%)\r\n",
      "  adding: result/linearized_penman/d-indo-fuji/ (stored 0%)\r\n",
      "  adding: result/linearized_penman/d-indo-fuji/test_label.txt (deflated 86%)\r\n",
      "  adding: result/linearized_penman/d-indo-fuji/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/linearized_penman/d-indo-fuji/test_generations.txt (deflated 83%)\r\n",
      "  adding: result/linearized_penman/amr_simple_test/ (stored 0%)\r\n",
      "  adding: result/linearized_penman/amr_simple_test/test_label.txt (deflated 60%)\r\n",
      "  adding: result/linearized_penman/amr_simple_test/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/linearized_penman/amr_simple_test/test_generations.txt (deflated 63%)\r\n",
      "  adding: result/linearized_penman/f-bunuh-diri/ (stored 0%)\r\n",
      "  adding: result/linearized_penman/f-bunuh-diri/test_label.txt (deflated 68%)\r\n",
      "  adding: result/linearized_penman/f-bunuh-diri/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/linearized_penman/f-bunuh-diri/test_generations.txt (deflated 61%)\r\n"
     ]
    }
   ],
   "source": [
    "!zip -r result_without_sta.zip result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579f6a33",
   "metadata": {
    "papermill": {
     "duration": 2.032222,
     "end_time": "2022-05-24T00:17:53.006762",
     "exception": false,
     "start_time": "2022-05-24T00:17:50.974540",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Finetune indot5 with linearized penman + tree level embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13e45cf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T00:17:57.221313Z",
     "iopub.status.busy": "2022-05-24T00:17:57.220403Z",
     "iopub.status.idle": "2022-05-24T00:17:57.226854Z",
     "shell.execute_reply": "2022-05-24T00:17:57.226220Z"
    },
    "papermill": {
     "duration": 2.105626,
     "end_time": "2022-05-24T00:17:57.227044",
     "exception": false,
     "start_time": "2022-05-24T00:17:55.121418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/amr-to-text-indonesia/tree_level_embeddings\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/amr-to-text-indonesia/tree_level_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd9a8b1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T00:18:01.762854Z",
     "iopub.status.busy": "2022-05-24T00:18:01.761999Z",
     "iopub.status.idle": "2022-05-24T00:18:02.497409Z",
     "shell.execute_reply": "2022-05-24T00:18:02.496835Z"
    },
    "papermill": {
     "duration": 2.843874,
     "end_time": "2022-05-24T00:18:02.497554",
     "exception": false,
     "start_time": "2022-05-24T00:17:59.653680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a90aeefe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T00:18:06.721408Z",
     "iopub.status.busy": "2022-05-24T00:18:06.720551Z",
     "iopub.status.idle": "2022-05-24T00:26:41.999287Z",
     "shell.execute_reply": "2022-05-24T00:26:41.998585Z"
    },
    "papermill": {
     "duration": 517.288263,
     "end_time": "2022-05-24T00:26:41.999447",
     "exception": false,
     "start_time": "2022-05-24T00:18:04.711184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\r\n",
      "Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at Wikidepia/IndoT5-base and are newly initialized: ['encoder.tree_embed.weight']\r\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\r\n",
      "added 9 tokens\r\n",
      "len train dataset:  2648\r\n",
      "len dev dataset:  19\r\n",
      "len test dataset: 306\r\n",
      "len train dataloader:  662\r\n",
      "(Epoch 1) TRAIN LOSS:2.5103 LR:0.00010000: 100%|█| 662/662 [01:33<00:00,  7.06it\r\n",
      "(Epoch 1) DEV LOSS:1.5872 LR:0.00010000: 100%|████| 5/5 [00:00<00:00, 24.53it/s]\r\n",
      "bleu score on dev:  44.76096279578911\r\n",
      "(Epoch 2) TRAIN LOSS:1.2102 LR:0.00010000: 100%|█| 662/662 [01:34<00:00,  7.02it\r\n",
      "(Epoch 2) DEV LOSS:1.2154 LR:0.00010000: 100%|████| 5/5 [00:00<00:00, 16.44it/s]\r\n",
      "bleu score on dev:  34.093011287101554\r\n",
      "(Epoch 3) TRAIN LOSS:0.8014 LR:0.00010000: 100%|█| 662/662 [01:33<00:00,  7.10it\r\n",
      "(Epoch 3) DEV LOSS:0.7935 LR:0.00010000: 100%|████| 5/5 [00:00<00:00, 25.49it/s]\r\n",
      "bleu score on dev:  38.793880775077895\r\n",
      "(Epoch 4) TRAIN LOSS:0.5166 LR:0.00010000: 100%|█| 662/662 [01:36<00:00,  6.84it\r\n",
      "(Epoch 4) DEV LOSS:0.6266 LR:0.00010000: 100%|████| 5/5 [00:00<00:00, 24.15it/s]\r\n",
      "bleu score on dev:  45.90847262751481\r\n",
      "(Epoch 5) TRAIN LOSS:0.4826 LR:0.00010000: 100%|█| 662/662 [01:34<00:00,  6.99it\r\n",
      "(Epoch 5) DEV LOSS:0.7883 LR:0.00010000: 100%|████| 5/5 [00:00<00:00, 24.88it/s]\r\n",
      "bleu score on dev:  45.23374469889808\r\n",
      "  0%|                                                    | 0/77 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|███████████████████████████████████████████| 77/77 [00:21<00:00,  3.52it/s]\r\n",
      "sample:  balon ditiup oleh ilham ---- balon itu ditiup ilham\r\n",
      "sample:  puisi ditulis oleh obe ---- obe menulis puisi\r\n",
      "sample:  saya mengetik makalah ---- saya mengetik makalah\r\n",
      "sample:  angga anak yang ajaib ---- angga anak ajaib\r\n",
      "sample:  ibu adalah seorang dosen ---- ibuku seorang dosen\r\n",
      "bleu score on test dataset:  38.33993975219217\r\n"
     ]
    }
   ],
   "source": [
    "!python train_indoT5.py --model_type indo-t5 --n_epochs 5 --lr 0.0001 --data_folder ../data/preprocessed_data/linearized_penman_with_tree_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7eadd59d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T00:26:50.875574Z",
     "iopub.status.busy": "2022-05-24T00:26:50.874691Z",
     "iopub.status.idle": "2022-05-24T00:26:51.641045Z",
     "shell.execute_reply": "2022-05-24T00:26:51.640157Z"
    },
    "papermill": {
     "duration": 5.524739,
     "end_time": "2022-05-24T00:26:51.641191",
     "exception": false,
     "start_time": "2022-05-24T00:26:46.116452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!chmod +x ./evaluate_indoT5_to_all.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d60cfb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T00:27:00.080127Z",
     "iopub.status.busy": "2022-05-24T00:27:00.079313Z",
     "iopub.status.idle": "2022-05-24T00:29:07.812032Z",
     "shell.execute_reply": "2022-05-24T00:29:07.812547Z"
    },
    "papermill": {
     "duration": 132.000135,
     "end_time": "2022-05-24T00:29:07.812749",
     "exception": false,
     "start_time": "2022-05-24T00:26:55.812614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model folder result\r\n",
      "preprocessing method linearized_penman_with_tree_level\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data’: File exists\r\n",
      "preprocess amr_simple_test\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/amr_simple_test’: File exists\r\n",
      "Namespace(mode='linearized_penman_with_tree_level', result_amr_path='data/test/preprocessed_data/amr_simple_test/test.amr.txt', result_sent_path='data/test/preprocessed_data/amr_simple_test/test.sent.txt', source_file_path='data/test/amr_simple_test.txt', source_folder_path=None)\r\n",
      "100%|███████████████████████████████████| 2618/2618 [00:00<00:00, 154000.36it/s]\r\n",
      "total: 306  tuple_sent_amr_level\r\n",
      "preprocess b-salah-darat\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/b-salah-darat’: File exists\r\n",
      "Namespace(mode='linearized_penman_with_tree_level', result_amr_path='data/test/preprocessed_data/b-salah-darat/test.amr.txt', result_sent_path='data/test/preprocessed_data/b-salah-darat/test.sent.txt', source_file_path='data/test/b-salah-darat.txt', source_folder_path=None)\r\n",
      "100%|█████████████████████████████████████| 676/676 [00:00<00:00, 108426.37it/s]\r\n",
      "total: 32  tuple_sent_amr_level\r\n",
      "preprocess c-gedung-roboh\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/c-gedung-roboh’: File exists\r\n",
      "Namespace(mode='linearized_penman_with_tree_level', result_amr_path='data/test/preprocessed_data/c-gedung-roboh/test.amr.txt', result_sent_path='data/test/preprocessed_data/c-gedung-roboh/test.sent.txt', source_file_path='data/test/c-gedung-roboh.txt', source_folder_path=None)\r\n",
      "100%|█████████████████████████████████████| 606/606 [00:00<00:00, 122570.68it/s]\r\n",
      "total: 29  tuple_sent_amr_level\r\n",
      "preprocess d-indo-fuji\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/d-indo-fuji’: File exists\r\n",
      "Namespace(mode='linearized_penman_with_tree_level', result_amr_path='data/test/preprocessed_data/d-indo-fuji/test.amr.txt', result_sent_path='data/test/preprocessed_data/d-indo-fuji/test.sent.txt', source_file_path='data/test/d-indo-fuji.txt', source_folder_path=None)\r\n",
      "100%|█████████████████████████████████████| 745/745 [00:00<00:00, 109337.50it/s]\r\n",
      "total: 27  tuple_sent_amr_level\r\n",
      "preprocess f-bunuh-diri\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/f-bunuh-diri’: File exists\r\n",
      "Namespace(mode='linearized_penman_with_tree_level', result_amr_path='data/test/preprocessed_data/f-bunuh-diri/test.amr.txt', result_sent_path='data/test/preprocessed_data/f-bunuh-diri/test.sent.txt', source_file_path='data/test/f-bunuh-diri.txt', source_folder_path=None)\r\n",
      "100%|█████████████████████████████████████| 468/468 [00:00<00:00, 115364.93it/s]\r\n",
      "total: 23  tuple_sent_amr_level\r\n",
      "preprocess g-gempa-dieng\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/g-gempa-dieng’: File exists\r\n",
      "Namespace(mode='linearized_penman_with_tree_level', result_amr_path='data/test/preprocessed_data/g-gempa-dieng/test.amr.txt', result_sent_path='data/test/preprocessed_data/g-gempa-dieng/test.sent.txt', source_file_path='data/test/g-gempa-dieng.txt', source_folder_path=None)\r\n",
      "100%|█████████████████████████████████████| 412/412 [00:00<00:00, 107245.90it/s]\r\n",
      "total: 19  tuple_sent_amr_level\r\n",
      "evaluate on data amr_simple_test\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='result/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"result/model\",\r\n",
      "  \"additional_config\": {\r\n",
      "    \"tree_max\": 512\r\n",
      "  },\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 306\r\n",
      "  0%|                                                    | 0/77 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|███████████████████████████████████████████| 77/77 [00:17<00:00,  4.31it/s]\r\n",
      "sample:  balon ditiup oleh ilham ---- balon itu ditiup ilham\r\n",
      "sample:  puisi ditulis oleh obe ---- obe menulis puisi\r\n",
      "sample:  saya mengetik makalah ---- saya mengetik makalah\r\n",
      "sample:  angga anak yang ajaib ---- angga anak ajaib\r\n",
      "sample:  ibu adalah seorang dosen ---- ibuku seorang dosen\r\n",
      "sample:  dia yang berenang ---- dia sedang berenang\r\n",
      "sample:  ilham mencari buku yang hilang ---- ilham sedang mencari bukunya yang hilang\r\n",
      "sample:  di halaman rumah, ibu menyapu ---- ibu sedang menyapu halaman rumah\r\n",
      "sample:  di sawah, ayah membajak padi ---- ayah sedang membajak padi di sawah\r\n",
      "sample:  andi pergi ke kemah di tepi pantai ---- andi pergi berkemah di tepi pantai\r\n",
      "bleu score on test dataset:  38.33993975219217\r\n",
      "evaluate on data b-salah-darat\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='result/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"result/model\",\r\n",
      "  \"additional_config\": {\r\n",
      "    \"tree_max\": 512\r\n",
      "  },\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 32\r\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:04<00:00,  1.69it/s]\r\n",
      "sample:  di kantor pt sama, kejadian tumpang terbangnya pesawat itu terjadi pada mei 10 2016 dan di bandara soekarnohatta, insiden tumpang terbangnya itu terjadi ---- kantor imigrasi bandara soekarno-hatta bersama kantor otoritas bandara soekarno-hatta dan pt angkasa pura ii membahas insiden penumpang penerbangan pesawat lion air jt 161 yang tiba di jakarta dari singapura 10 mei 2016.\r\n",
      "sample:  kepala kantor imigrasi soekarno suadi menyampaikan meeting kepada kami pada sabtu malam ---- kami meeting soal ini,\" ujar kepala kantor imigrasi soekarno-hatta alif suadi kepada tempo, sabtu malam ini, 14 mei 2016.\r\n",
      "sample:  anak temannya natalie berangkat ke singapura pada pukul 18 55 dan menggunakan pesawat lion air jt 161 ---- anak temannya natalie berangkat dari singapura dan menggunakan pesawat lion air jt 161, pada pukul 18.50.\r\n",
      "sample:  di bandara internasional soekarnohatta, perusahaan itu akan melakukan koordinasi dengan kantor otoritas bandara ---- sekretaris perusahaan pt angkasa pura ii agus haryadi mengatakan selaku pengelola bandara internasional soekarno-hatta, pihaknya akan berkoordinasi dengan kantor otoritas bandara wilayah i terkait dengan peristiwa ini.\r\n",
      "sample:  kami menyiapkan pesawat parkir di area remote area ---- setiap pesawat yang parkir di remote area sudah kami siapkan bus untuk mengantar penumpang ke terminal.\r\n",
      "sample:  edward mendapat sopir jemputan di padang ---- terdapat sopir bus yang akan menjemput penumpang dari padang\" ujar edward.\r\n",
      "sample:  pihak otoritas bandara soetta yang memanggil dan melakukan investigasi ---- pihak otoritas bandara soetta akan memanggil pihak terkait dan dilakukan investigasi.\r\n",
      "sample:  kemenhub memberikan sanksi kepada pihak yang lalai ---- kemenhub memberikan sanksi kepada pihak-pihak yang lalai,\" ujarnya.\r\n",
      "sample:  zara mengutip cerita temannya di terminal ii ---- pesawat itu mendarat tidak di terminal ii, kata zara mengutip cerita temannya.\r\n",
      "sample:  kami menyiapkan pesawat parkir di area remote area ---- setiap pesawat yang parkir di remote area sudah kami siapkan bus untuk mengantar penumpang ke terminal.\r\n",
      "bleu score on test dataset:  8.847431880082397\r\n",
      "evaluate on data c-gedung-roboh\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='result/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"result/model\",\r\n",
      "  \"additional_config\": {\r\n",
      "    \"tree_max\": 512\r\n",
      "  },\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 29\r\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:06<00:00,  1.26it/s]\r\n",
      "sample:  kendaraan itu bergerak ke arah mal bintaro xchange dan flyover itu merupakan guna dari flyover atas lampu merah ---- pengalihan dilakukan bagi pengendara yang melaju dari arah mal bintaro xchange dan tol bintaro menuju jalan boulevard bintaro dengan menggunakan flyover di atas lampu merah indomobil.\r\n",
      "sample:  terjadi kegagalan dan salah satu tes tanah terjadi di menara saidah ---- kegagalan struktur dan kesalahan tes tanah yang mengakibatkan gedung miring juga terjadi pada menara saidah di jalan mt haryono, jakarta timur.\r\n",
      "sample:  kejadian di bintaro terjadi roboh gedung ---- kapolres tangerang selatan, akbp ayi supardan membenarkan peristiwa robohnya gedung di bintaro yang menarik perhatian masyarakat banyak.\r\n",
      "sample:  panin memutuskan melanjutkan pembangunan gedung itu karena nyata lulus uji kelayakan ---- panin memutuskan tidak melanjutkan pembangunan gedung itu karena dinyatakan tidak lulus uji kelayakan.\r\n",
      "sample:  gedung itu lulus uji, sehingga pembangunan putuskan untuk membangun gedung ---- gedung tersebut dinyatakan tidak lulus uji sehingga pembangunan gedung diputuskan tidak dilanjutkan.\r\n",
      "sample:  di polres tangerang selatan, kasat akp samian melakukan selidik saat ini ---- kasat reskrim polres tangerangg selatan, akp samian mengatakan saat ini pihaknya melakukan penyelidikan untuk mengetahui penyebab runtuhnya gedung.\r\n",
      "sample:  kami masih berada di dalam peristiwa itu sampai ini ---- hingga kini kami masih mendalami peristiwa tersebut.\r\n",
      "sample:  yang menjadi korban ---- kejadian tersebut tidak timbul korban.\r\n",
      "sample:  kerugian material yang terjadi ---- terjadi kerugian material.\r\n",
      "sample:  di sektor bintaro tangerang selatan, ada yang salah dengan prosedur ---- pembongkaran gedung di sektor 7, bintaro, tangerang selatan, diduga menyalahi prosedur.\r\n",
      "bleu score on test dataset:  9.06008859352565\r\n",
      "evaluate on data d-indo-fuji\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='result/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"result/model\",\r\n",
      "  \"additional_config\": {\r\n",
      "    \"tree_max\": 512\r\n",
      "  },\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 27\r\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:04<00:00,  1.52it/s]\r\n",
      "sample:  indosat bersama fujitsu indonesia menandatangani nota paham dalam rangka meningkatkan kesuksesan bisnis ---- indosat ooredoo bersama fujitsu indonesia menandatangani nota kesepahaman dalam rangka memantapkan kemitraan dengan para pelanggan bisnis yang telah dibangun dalam menghadirkan solusi smart mobility dan internet of things.\r\n",
      "sample:  indosat bersama fujitsu indonesia menandatangani nota paham dalam rangka meningkatkan kesuksesan bisnis ---- indosat ooredoo bersama fujitsu indonesia menandatangani nota kesepahaman dalam rangka memantapkan kemitraan dengan para pelanggan bisnis yang telah dibangun dalam menghadirkan solusi smart mobility dan internet of things.\r\n",
      "sample:  mobility iot dan tumbuh dengan signifikan pada saat itu ---- smart mobility dan iot mengalami perkembangan cukup signifikan sehingga mengubah cara perusahaan dalam mengelola aset.\r\n",
      "sample:  indosat bersama fujitsu indonesia menandatangani nota paham dalam rangka meningkatkan kesuksesan bisnis ---- indosat ooredoo bersama fujitsu indonesia menandatangani nota kesepahaman dalam rangka memantapkan kemitraan dengan para pelanggan bisnis yang telah menghadirkan solusi smart mobility dan internet of things.\r\n",
      "sample:  di sektor transportasi dan otomotif, kerja sama dilakukan oleh pemerintah dan korporasi indonesia ---- kerja sama ini akan berfokus pada sektor otomotif dan transportasi dan akan diperluas ke berbagai sektor industri untuk memenuhi kebutuhan pelanggan korporasi di indonesia.\r\n",
      "sample:  presiden achmad sofwan menyampaikan manfaat dari teknologi dan teknologi merupakan cara optimal untuk meningkatkan strategi usaha ---- mobilitas akan menyediakan cara untuk mengoptimalkan strategi perusahaan dengan memanfaatkan aplikasi dan layanan yang dapat memproses data real-time, tutur achmad sofwan, president director fujitsu indonesia.\r\n",
      "sample:  di sektor transportasi dan otomotif, kerja sama dilakukan oleh pemerintah dan korporasi indonesia ---- kerja sama ini akan berfokus pada sektor otomotif dan transportasi dan akan diperluas ke berbagai sektor industri untuk memenuhi kebutuhan pelanggan korporasi di indonesia.\r\n",
      "sample:  indosat ooredoo sedang mengerjakan solusi smart mobility dan fujitsu dengan indonesia ---- indosat ooredoo bekerja sama dengan fujitsu indonesia menghadirkan solusi smart mobility dan internet of things.\r\n",
      "sample:  pemerintah achmad sofwan menyampaikan manfaat dari teknologi dan teknologi merupakan cara optimal untuk meningkatkan strategi usaha ---- president director fujitsu, achmad sofwan mengungkap, mobilitas akan menyediakan cara mengoptimalisasikan strategi perusahaan dengan memanfaatkan aplikasi dan layanan dalam aktivitas memproses data real-time.\r\n",
      "sample:  di sektor transportasi dan otomotif, kerja sama dilakukan oleh pemerintah dan korporasi indonesia ---- kerja sama ini akan berfokus pada sektor otomotif dan transportasi dan akan diperluas ke berbagai sektor industri untuk memenuhi kebutuhan pelanggan korporasi di indonesia.\r\n",
      "bleu score on test dataset:  4.194047862982366\r\n",
      "evaluate on data f-bunuh-diri\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='result/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"result/model\",\r\n",
      "  \"additional_config\": {\r\n",
      "    \"tree_max\": 512\r\n",
      "  },\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 23\r\n",
      "  0%|                                                     | 0/6 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.04it/s]\r\n",
      "sample:  di sepanjang jembatan, ia melompat setinggi 15 meter ---- ciptadi dengan nekat melompat dari megatron jembatan penyeberangan orang yang tingginya diperkirakan mencapai 15 meter.\r\n",
      "sample:  hal tersebut diungkapkan oleh kasubag reny marthaliana ---- hal tersebut diungkapkan kabag ops polrestabes bandung kompol dede rojudin didampingi kasubag humas kompol reny marthaliana, saat ditemui di mapolrestabes bandung, jumat.\r\n",
      "sample:  di masjid raya bandung, ia melihat jemaat yang lain ---- rezha noviana, warga kota bandung mengatakan ia dan jemaat lainnya langsung memperhatikan megatron jembatan penyeberangan orang depan kantor pos besar bandung setelah bubar salat jumat di masjid raya bandung.\r\n",
      "sample:  di atas jpo, petugas linmas melakukan tugasnya ---- ketika itu, petugas linmas dan beberapa satpam berdiri di atas jpo.\r\n",
      "sample:  di alun bandung, aksi bunuh diri terjadi ---- aksi bunuh diri di alun - alun bandung belum lama ini terjadi.\r\n",
      "sample:  dirinya terjatuh di alun bandung ---- seorang pria tua nekat menjatuhkan diri dari jpo di alun - alun kota bandung.\r\n",
      "sample:  sudirman menjadi saksi mata di alun bandung ---- sudirman, anggota linmas satpol pp kota bandung yang menjadi saksi mata aksi bunuh diri di alun - alun bandung itu mengatakan, pria tersebut diperkirakan berusia 50 tahun.\r\n",
      "sample:  dirinya terjatuh di pos giro besar bandung pada hari jumat ---- seorang lelaki menjatuhkan diri dari megatron jembatan penyeberangan di depan pos giro besar bandung, bandung, jumat.\r\n",
      "sample:  di tengah padatnya lalu lintas, lelaki itu mengakhiri hidupnya ---- seorang lelaki tengah baya nekat mengakhiri hidupnya di tengah kepadatan lalu lintas jalan asia afrika.\r\n",
      "sample:  di jembatan jalan asia afrika, pria misterius itu membuat pesan belum terjun ke dalam ---- pria misterius yang bunuh diri dari jembatan penyeberangan orang di jalan asia afrika, bandung, jawa barat, membuat pesan sebelum nekat terjun.\r\n",
      "bleu score on test dataset:  6.579701950685511\r\n",
      "evaluate on data g-gempa-dieng\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='result/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"result/model\",\r\n",
      "  \"additional_config\": {\r\n",
      "    \"tree_max\": 512\r\n",
      "  },\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 19\r\n",
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:02<00:00,  2.06it/s]\r\n",
      "sample:  stasiun banjarnegara jawa tengah mengumumkan gempa yang kuat pada pukul 19. 00 wib ---- stasiun geofisika badan meteorologi klimatologi dan geofisika banjarnegara, jawa tengah, menyatakan bahwa gempa yang mengguncang dataran tinggi dieng pukul 19.00 wib berkekuatan 4,8 pada skala richter.\r\n",
      "sample:  pusat gempa yang ada di desa tanji gugur ---- pusat gempa diperkirakan berada di desa tanji gugur, kecamatan bawang, kabupaten batang.\r\n",
      "sample:  jalan dekat kawah desa sumberejo ditutup sementara ---- pvmbg merekomendasikan seluruh jalan yang mendekati kawah timbang di desa sumberejo sementara ditutup.\r\n",
      "sample:  di dataran tinggi dieng, banyak kejadian terjadi ---- kepala pusat vulkanologi dan mitigasi bencana geologi surono mengatakan bahwa gempa yang terjadi di dataran tinggi dieng pukul 19.00 wib terekam sebanyak 86 kali.\r\n",
      "sample:  di lapangan, tim ukur konsentrasi gas dilakukan tutup ---- penutupan ini dilakukan hingga tim di lapangan yang mengukur konsentrasi gas menyatakan tidak ada gas yang berbahaya.\r\n",
      "sample:  jalan dekat kawah desa sumberejo ditutup sementara ---- pvmbg merekomendasikan seluruh jalan yang mendekati kawah timbang di desa sumberejo sementara ditutup.\r\n",
      "sample:  petugas di pusat vulkanologi mitigasi bencana geologi terjun dan memberikan informasi ---- petugas pusat vulkanologi dan mitigasi bencana geologi diterjunkan untuk memantau aktivitas kawah timbang dan memberikan informasi.\r\n",
      "sample:  data keluar dari pusat vulkanologi mitigasi bencana geologi pada pukul 19.00 wib ---- data yang dikeluarkan dari pusat vulkanologi dan mitigasi bencana geologi menyebutkan gempa mulai terasa pukul 19.00 wib dan telah terekam gempa sebanyak 86 kali.\r\n",
      "sample:  di sabtu pagi, ungsi tersebut ditinggalkan ---- pengungsi di kabupaten banjarnegara, pada sabtu pagi mulai meninggalkan pengungsian.\r\n",
      "sample:  di dataran tinggi dieng, terjadi gempa yang kuat 4 8 skala richter ---- stasiun geofisika badan meteorologi klimatologi dan geofisika banjarnegara menyatakan gempa yang mengguncang dataran tinggi dieng pukul 19.00 wib berkekuatan 4,8 skala richter *(sr)*.\r\n",
      "bleu score on test dataset:  6.618898264836624\r\n"
     ]
    }
   ],
   "source": [
    "!./evaluate_indoT5_to_all.sh result linearized_penman_with_tree_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74d95106",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T00:29:16.273763Z",
     "iopub.status.busy": "2022-05-24T00:29:16.272793Z",
     "iopub.status.idle": "2022-05-24T00:30:38.132197Z",
     "shell.execute_reply": "2022-05-24T00:30:38.131056Z"
    },
    "papermill": {
     "duration": 86.162252,
     "end_time": "2022-05-24T00:30:38.132378",
     "exception": false,
     "start_time": "2022-05-24T00:29:11.970126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: result/ (stored 0%)\r\n",
      "  adding: result/c-gedung-roboh/ (stored 0%)\r\n",
      "  adding: result/c-gedung-roboh/test_label.txt (deflated 62%)\r\n",
      "  adding: result/c-gedung-roboh/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/c-gedung-roboh/test_generations.txt (deflated 58%)\r\n",
      "  adding: result/g-gempa-dieng/ (stored 0%)\r\n",
      "  adding: result/g-gempa-dieng/test_label.txt (deflated 67%)\r\n",
      "  adding: result/g-gempa-dieng/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/g-gempa-dieng/test_generations.txt (deflated 59%)\r\n",
      "  adding: result/b-salah-darat/ (stored 0%)\r\n",
      "  adding: result/b-salah-darat/test_label.txt (deflated 66%)\r\n",
      "  adding: result/b-salah-darat/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/b-salah-darat/test_generations.txt (deflated 61%)\r\n",
      "  adding: result/test_label.txt (deflated 60%)\r\n",
      "  adding: result/d-indo-fuji/ (stored 0%)\r\n",
      "  adding: result/d-indo-fuji/test_label.txt (deflated 86%)\r\n",
      "  adding: result/d-indo-fuji/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/d-indo-fuji/test_generations.txt (deflated 82%)\r\n",
      "  adding: result/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/amr_simple_test/ (stored 0%)\r\n",
      "  adding: result/amr_simple_test/test_label.txt (deflated 60%)\r\n",
      "  adding: result/amr_simple_test/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/amr_simple_test/test_generations.txt (deflated 62%)\r\n",
      "  adding: result/loss_data.tsv (deflated 36%)\r\n",
      "  adding: result/f-bunuh-diri/ (stored 0%)\r\n",
      "  adding: result/f-bunuh-diri/test_label.txt (deflated 68%)\r\n",
      "  adding: result/f-bunuh-diri/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/f-bunuh-diri/test_generations.txt (deflated 59%)\r\n",
      "  adding: result/model/ (stored 0%)\r\n",
      "  adding: result/model/config.json (deflated 45%)\r\n",
      "  adding: result/model/pytorch_model.bin (deflated 11%)\r\n",
      "  adding: result/tokenizer/ (stored 0%)\r\n",
      "  adding: result/tokenizer/tokenizer_config.json (deflated 81%)\r\n",
      "  adding: result/tokenizer/added_tokens.json (deflated 43%)\r\n",
      "  adding: result/tokenizer/special_tokens_map.json (deflated 82%)\r\n",
      "  adding: result/tokenizer/spiece.model (deflated 49%)\r\n",
      "  adding: result/test_generations.txt (deflated 62%)\r\n"
     ]
    }
   ],
   "source": [
    "!zip -r result_without_sta.zip result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980baf97",
   "metadata": {
    "papermill": {
     "duration": 3.85725,
     "end_time": "2022-05-24T00:30:45.896053",
     "exception": false,
     "start_time": "2022-05-24T00:30:42.038803",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Finetune indot5 with linearized penman + supervised task adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a37a21de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T00:30:54.596189Z",
     "iopub.status.busy": "2022-05-24T00:30:54.595336Z",
     "iopub.status.idle": "2022-05-24T00:30:54.599195Z",
     "shell.execute_reply": "2022-05-24T00:30:54.599729Z"
    },
    "papermill": {
     "duration": 4.63337,
     "end_time": "2022-05-24T00:30:54.599939",
     "exception": false,
     "start_time": "2022-05-24T00:30:49.966569",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/amr-to-text-indonesia/train\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/amr-to-text-indonesia/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15e7abe5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T00:31:02.744955Z",
     "iopub.status.busy": "2022-05-24T00:31:02.744036Z",
     "iopub.status.idle": "2022-05-24T00:31:03.447614Z",
     "shell.execute_reply": "2022-05-24T00:31:03.448277Z"
    },
    "papermill": {
     "duration": 4.918245,
     "end_time": "2022-05-24T00:31:03.448476",
     "exception": false,
     "start_time": "2022-05-24T00:30:58.530231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'result/model': Is a directory\r\n",
      "rm: cannot remove 'result/tokenizer': Is a directory\r\n"
     ]
    }
   ],
   "source": [
    "!rm result/* -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5004107b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T00:31:11.743646Z",
     "iopub.status.busy": "2022-05-24T00:31:11.742736Z",
     "iopub.status.idle": "2022-05-24T02:30:09.116107Z",
     "shell.execute_reply": "2022-05-24T02:30:09.055256Z"
    },
    "papermill": {
     "duration": 7141.682778,
     "end_time": "2022-05-24T02:30:09.116345",
     "exception": false,
     "start_time": "2022-05-24T00:31:07.433567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing method linearized_penman\r\n",
      "silver data folder ../amr-indo-dataset/data_154k_raw_silver_amr_indo4b_news\r\n",
      "Namespace(mode='linearized_penman', result_amr_path='data/preprocessed_silver_data/train.amr.txt', result_sent_path='data/preprocessed_silver_data/train.sent.txt', source_file_path=None, source_folder_path='../amr-indo-dataset/data_154k_raw_silver_amr_indo4b_news')\r\n",
      "100%|███████████████████████████████| 263263/263263 [00:01<00:00, 132607.23it/s]\r\n",
      "100%|███████████████████████████████| 264330/264330 [00:02<00:00, 130094.04it/s]\r\n",
      "100%|███████████████████████████████| 263508/263508 [00:01<00:00, 139136.89it/s]\r\n",
      "100%|███████████████████████████████| 264253/264253 [00:01<00:00, 136163.18it/s]\r\n",
      "100%|███████████████████████████████| 268572/268572 [00:02<00:00, 122592.09it/s]\r\n",
      "100%|███████████████████████████████| 268262/268262 [00:02<00:00, 132628.70it/s]\r\n",
      "100%|███████████████████████████████| 265325/265325 [00:02<00:00, 105128.34it/s]\r\n",
      "100%|███████████████████████████████| 266966/266966 [00:02<00:00, 129713.88it/s]\r\n",
      "100%|███████████████████████████████| 270251/270251 [00:02<00:00, 122663.39it/s]\r\n",
      "100%|███████████████████████████████| 269258/269258 [00:02<00:00, 117821.51it/s]\r\n",
      "total: 154892 pair sent-amr\r\n",
      "Running on the GPU\r\n",
      "added 9 tokens\r\n",
      "len train dataset:  154892\r\n",
      "len dev dataset:  19\r\n",
      "len test dataset: 306\r\n",
      "len train dataloader:  38723\r\n",
      "(Epoch 1) TRAIN LOSS:0.9334 LR:0.00010000: 100%|█| 38723/38723 [1:57:29<00:00,  \r\n",
      "(Epoch 1) DEV LOSS:2.8465 LR:0.00010000: 100%|████| 5/5 [00:00<00:00, 25.92it/s]\r\n",
      "bleu score on dev:  22.155900222992248\r\n",
      "  0%|                                                    | 0/77 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|███████████████████████████████████████████| 77/77 [00:30<00:00,  2.55it/s]\r\n",
      "sample:  ilham meniup balon. ---- balon itu ditiup ilham\r\n",
      "sample:  obe menulis puisi. ---- obe menulis puisi\r\n",
      "sample:  saya mengetik makalah. ---- saya mengetik makalah\r\n",
      "sample:  angga anak ajaib. ---- angga anak ajaib\r\n",
      "sample:  ibu saya orang dosen. ---- ibuku seorang dosen\r\n",
      "bleu score on test dataset:  36.869697692607325\r\n",
      "saya mengetik makalah.\r\n"
     ]
    }
   ],
   "source": [
    "!chmod +x train_indoT5_on_silver_data.sh\n",
    "!./train_indoT5_on_silver_data.sh linearized_penman ../amr-indo-dataset/data_154k_raw_silver_amr_indo4b_news 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17ec5f38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T02:31:02.277804Z",
     "iopub.status.busy": "2022-05-24T02:31:02.276989Z",
     "iopub.status.idle": "2022-05-24T02:31:02.992764Z",
     "shell.execute_reply": "2022-05-24T02:31:02.992226Z"
    },
    "papermill": {
     "duration": 26.830509,
     "end_time": "2022-05-24T02:31:02.992914",
     "exception": false,
     "start_time": "2022-05-24T02:30:36.162405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu_score_test.txt  model\t\t   test_label.txt\r\n",
      "loss_data.tsv\t     test_generations.txt  tokenizer\r\n"
     ]
    }
   ],
   "source": [
    "!ls result/result_supervised_task_adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3d5f0c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T02:31:56.358115Z",
     "iopub.status.busy": "2022-05-24T02:31:56.357163Z",
     "iopub.status.idle": "2022-05-24T02:31:57.086423Z",
     "shell.execute_reply": "2022-05-24T02:31:57.085905Z"
    },
    "papermill": {
     "duration": 27.353966,
     "end_time": "2022-05-24T02:31:57.086566",
     "exception": false,
     "start_time": "2022-05-24T02:31:29.732600",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir result/result_linearized_penman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28869488",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T02:32:49.694419Z",
     "iopub.status.busy": "2022-05-24T02:32:49.693452Z",
     "iopub.status.idle": "2022-05-24T02:36:26.105850Z",
     "shell.execute_reply": "2022-05-24T02:36:26.106422Z"
    },
    "papermill": {
     "duration": 242.299511,
     "end_time": "2022-05-24T02:36:26.106617",
     "exception": false,
     "start_time": "2022-05-24T02:32:23.807106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\r\n",
      "resume from checkpoint\r\n",
      "added 0 tokens\r\n",
      "len train dataset:  2648\r\n",
      "len dev dataset:  19\r\n",
      "len test dataset: 306\r\n",
      "len train dataloader:  662\r\n",
      "(Epoch 1) TRAIN LOSS:0.8004 LR:0.00010000: 100%|█| 662/662 [01:28<00:00,  7.52it\r\n",
      "(Epoch 1) DEV LOSS:0.8735 LR:0.00010000: 100%|████| 5/5 [00:00<00:00, 19.14it/s]\r\n",
      "bleu score on dev:  42.35537236394542\r\n",
      "(Epoch 2) TRAIN LOSS:0.4703 LR:0.00010000: 100%|█| 662/662 [01:27<00:00,  7.54it\r\n",
      "(Epoch 2) DEV LOSS:0.7072 LR:0.00010000: 100%|████| 5/5 [00:00<00:00, 28.08it/s]\r\n",
      "bleu score on dev:  45.069540989129706\r\n",
      "  0%|                                                    | 0/77 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|███████████████████████████████████████████| 77/77 [00:18<00:00,  4.14it/s]\r\n",
      "sample:  balon ditiup ilham ---- balon itu ditiup ilham\r\n",
      "sample:  puisi ditulis obe ---- obe menulis puisi\r\n",
      "sample:  saya mengetik makalah ---- saya mengetik makalah\r\n",
      "sample:  angga anak yang ajaib ---- angga anak ajaib\r\n",
      "sample:  ibu seorang dosen ---- ibuku seorang dosen\r\n",
      "bleu score on test dataset:  50.47638222111287\r\n",
      "saya mengetik makalah\r\n"
     ]
    }
   ],
   "source": [
    "!python train_indoT5.py --model_type indo-t5 --n_epochs 2 --lr 0.0001 --data_folder ../data/preprocessed_data/linearized_penman  --result_folder result/result_linearized_penman --resume_from_checkpoint True --saved_model_folder_path result/result_supervised_task_adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60d4ae01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T02:37:20.640092Z",
     "iopub.status.busy": "2022-05-24T02:37:20.639160Z",
     "iopub.status.idle": "2022-05-24T02:38:26.353238Z",
     "shell.execute_reply": "2022-05-24T02:38:26.352660Z"
    },
    "papermill": {
     "duration": 92.94284,
     "end_time": "2022-05-24T02:38:26.353407",
     "exception": false,
     "start_time": "2022-05-24T02:36:53.410567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: result/result_linearized_penman/ (stored 0%)\r\n",
      "  adding: result/result_linearized_penman/test_label.txt (deflated 60%)\r\n",
      "  adding: result/result_linearized_penman/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/result_linearized_penman/loss_data.tsv (deflated 20%)\r\n",
      "  adding: result/result_linearized_penman/model/ (stored 0%)\r\n",
      "  adding: result/result_linearized_penman/model/config.json (deflated 45%)\r\n",
      "  adding: result/result_linearized_penman/model/pytorch_model.bin (deflated 9%)\r\n",
      "  adding: result/result_linearized_penman/tokenizer/ (stored 0%)\r\n",
      "  adding: result/result_linearized_penman/tokenizer/tokenizer_config.json (deflated 81%)\r\n",
      "  adding: result/result_linearized_penman/tokenizer/added_tokens.json (deflated 44%)\r\n",
      "  adding: result/result_linearized_penman/tokenizer/special_tokens_map.json (deflated 83%)\r\n",
      "  adding: result/result_linearized_penman/tokenizer/spiece.model (deflated 49%)\r\n",
      "  adding: result/result_linearized_penman/test_generations.txt (deflated 62%)\r\n"
     ]
    }
   ],
   "source": [
    "!zip -r result_with_sta.zip result/result_linearized_penman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71902e5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T02:39:19.687080Z",
     "iopub.status.busy": "2022-05-24T02:39:19.686133Z",
     "iopub.status.idle": "2022-05-24T02:39:19.697383Z",
     "shell.execute_reply": "2022-05-24T02:39:19.696091Z"
    },
    "papermill": {
     "duration": 26.62073,
     "end_time": "2022-05-24T02:39:19.697710",
     "exception": false,
     "start_time": "2022-05-24T02:38:53.076980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/amr-to-text-indonesia/evaluate\n"
     ]
    }
   ],
   "source": [
    "%cd ../evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "463d4ef6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T02:40:13.378671Z",
     "iopub.status.busy": "2022-05-24T02:40:13.377796Z",
     "iopub.status.idle": "2022-05-24T02:40:14.092863Z",
     "shell.execute_reply": "2022-05-24T02:40:14.092252Z"
    },
    "papermill": {
     "duration": 27.410566,
     "end_time": "2022-05-24T02:40:14.093011",
     "exception": false,
     "start_time": "2022-05-24T02:39:46.682445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'result/linearized_penman': Is a directory\r\n"
     ]
    }
   ],
   "source": [
    "!rm result/* -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d178fb57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T02:41:08.718974Z",
     "iopub.status.busy": "2022-05-24T02:41:08.718170Z",
     "iopub.status.idle": "2022-05-24T02:43:27.395259Z",
     "shell.execute_reply": "2022-05-24T02:43:27.395725Z"
    },
    "papermill": {
     "duration": 165.821428,
     "end_time": "2022-05-24T02:43:27.395921",
     "exception": false,
     "start_time": "2022-05-24T02:40:41.574493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model folder ../train/result/result_linearized_penman\r\n",
      "preprocessing method linearized_penman\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data’: File exists\r\n",
      "preprocess amr_simple_test\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/amr_simple_test’: File exists\r\n",
      "Namespace(mode='linearized_penman', result_amr_path='data/test/preprocessed_data/amr_simple_test/test.amr.txt', result_sent_path='data/test/preprocessed_data/amr_simple_test/test.sent.txt', source_file_path='data/test/amr_simple_test.txt', source_folder_path=None)\r\n",
      "100%|████████████████████████████████████| 2618/2618 [00:00<00:00, 92161.62it/s]\r\n",
      "total: 306 pair sent-amr\r\n",
      "preprocess b-salah-darat\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/b-salah-darat’: File exists\r\n",
      "Namespace(mode='linearized_penman', result_amr_path='data/test/preprocessed_data/b-salah-darat/test.amr.txt', result_sent_path='data/test/preprocessed_data/b-salah-darat/test.sent.txt', source_file_path='data/test/b-salah-darat.txt', source_folder_path=None)\r\n",
      "100%|██████████████████████████████████████| 676/676 [00:00<00:00, 72069.28it/s]\r\n",
      "total: 32 pair sent-amr\r\n",
      "preprocess c-gedung-roboh\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/c-gedung-roboh’: File exists\r\n",
      "Namespace(mode='linearized_penman', result_amr_path='data/test/preprocessed_data/c-gedung-roboh/test.amr.txt', result_sent_path='data/test/preprocessed_data/c-gedung-roboh/test.sent.txt', source_file_path='data/test/c-gedung-roboh.txt', source_folder_path=None)\r\n",
      "100%|█████████████████████████████████████| 606/606 [00:00<00:00, 110405.19it/s]\r\n",
      "total: 29 pair sent-amr\r\n",
      "preprocess d-indo-fuji\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/d-indo-fuji’: File exists\r\n",
      "Namespace(mode='linearized_penman', result_amr_path='data/test/preprocessed_data/d-indo-fuji/test.amr.txt', result_sent_path='data/test/preprocessed_data/d-indo-fuji/test.sent.txt', source_file_path='data/test/d-indo-fuji.txt', source_folder_path=None)\r\n",
      "100%|█████████████████████████████████████| 745/745 [00:00<00:00, 109833.27it/s]\r\n",
      "total: 27 pair sent-amr\r\n",
      "preprocess f-bunuh-diri\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/f-bunuh-diri’: File exists\r\n",
      "Namespace(mode='linearized_penman', result_amr_path='data/test/preprocessed_data/f-bunuh-diri/test.amr.txt', result_sent_path='data/test/preprocessed_data/f-bunuh-diri/test.sent.txt', source_file_path='data/test/f-bunuh-diri.txt', source_folder_path=None)\r\n",
      "100%|█████████████████████████████████████| 468/468 [00:00<00:00, 110283.40it/s]\r\n",
      "total: 23 pair sent-amr\r\n",
      "preprocess g-gempa-dieng\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/g-gempa-dieng’: File exists\r\n",
      "Namespace(mode='linearized_penman', result_amr_path='data/test/preprocessed_data/g-gempa-dieng/test.amr.txt', result_sent_path='data/test/preprocessed_data/g-gempa-dieng/test.sent.txt', source_file_path='data/test/g-gempa-dieng.txt', source_folder_path=None)\r\n",
      "100%|█████████████████████████████████████| 412/412 [00:00<00:00, 105983.03it/s]\r\n",
      "total: 19 pair sent-amr\r\n",
      "mkdir: cannot create directory ‘result’: File exists\r\n",
      "evaluate on data amr_simple_test\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='../train/result/result_linearized_penman/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"../train/result/result_linearized_penman/model\",\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 306\r\n",
      "  0%|                                                    | 0/77 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|███████████████████████████████████████████| 77/77 [00:19<00:00,  4.04it/s]\r\n",
      "sample:  balon ditiup ilham ---- balon itu ditiup ilham\r\n",
      "sample:  puisi ditulis obe ---- obe menulis puisi\r\n",
      "sample:  saya mengetik makalah ---- saya mengetik makalah\r\n",
      "sample:  angga anak yang ajaib ---- angga anak ajaib\r\n",
      "sample:  ibu seorang dosen ---- ibuku seorang dosen\r\n",
      "sample:  dia yang berenang ---- dia sedang berenang\r\n",
      "sample:  ilham mencari buku yang hilang ---- ilham sedang mencari bukunya yang hilang\r\n",
      "sample:  ibu menyapu halaman rumah ---- ibu sedang menyapu halaman rumah\r\n",
      "sample:  ayah membajak padi di sawah ---- ayah sedang membajak padi di sawah\r\n",
      "sample:  andi pergi ke perkemahan di tepi pantai ---- andi pergi berkemah di tepi pantai\r\n",
      "bleu score on test dataset:  50.47638222111287\r\n",
      "evaluate on data b-salah-darat\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='../train/result/result_linearized_penman/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"../train/result/result_linearized_penman/model\",\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 32\r\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:07<00:00,  1.11it/s]\r\n",
      "sample:  kantor yang sama dan pt angkasa pura ii otoritas bandara soekarno-hatta membahas insiden penumpang yang tiba di jakarta dari singapura pada 10 mei 2016 di lion air jt 161 ---- kantor imigrasi bandara soekarno-hatta bersama kantor otoritas bandara soekarno-hatta dan pt angkasa pura ii membahas insiden penumpang penerbangan pesawat lion air jt 161 yang tiba di jakarta dari singapura 10 mei 2016.\r\n",
      "sample:  kepala kantor imigrasi soekarno-hatta alif suadi menuturkan, kami meeting soal kepada tempo sabtu malam ini 14 mei 2016 ---- kami meeting soal ini,\" ujar kepala kantor imigrasi soekarno-hatta alif suadi kepada tempo, sabtu malam ini, 14 mei 2016.\r\n",
      "sample:  anak temannya, natalie, berangkat ke singapura dan menggunakan pesawat lion air jt 161 jt ---- anak temannya natalie berangkat dari singapura dan menggunakan pesawat lion air jt 161, pada pukul 18.50.\r\n",
      "sample:  sekretaris agus haryadi dari perusahaan pt angkasa pura ii mengatakan, untuk mengelola bandara internasional soekarno-hatta, pihaknya akan berkoordinasi dengan kantor otoritas bandara wilayah 1 terkait dengan perisitiwa ---- sekretaris perusahaan pt angkasa pura ii agus haryadi mengatakan selaku pengelola bandara internasional soekarno-hatta, pihaknya akan berkoordinasi dengan kantor otoritas bandara wilayah i terkait dengan peristiwa ini.\r\n",
      "sample:  pesawat parkir di remote area kami siapkan bus antar penumpang ke terminal ---- setiap pesawat yang parkir di remote area sudah kami siapkan bus untuk mengantar penumpang ke terminal.\r\n",
      "sample:  edward menuturkan terdapat sopir yang menjemput penumpang di padang dengan bus ---- terdapat sopir bus yang akan menjemput penumpang dari padang\" ujar edward.\r\n",
      "sample:  pihak otoritas bandara soetta memanggil pihak terkait dan yang melakukan investigasi ---- pihak otoritas bandara soetta akan memanggil pihak terkait dan dilakukan investigasi.\r\n",
      "sample:  kemenhub memberikan sanksi kepada pihak-pihak yang lalai ---- kemenhub memberikan sanksi kepada pihak-pihak yang lalai,\" ujarnya.\r\n",
      "sample:  zara mengatakan mengutip cerita temannya bahwa pesawat itu tidak mendarat di terminal ii ---- pesawat itu mendarat tidak di terminal ii, kata zara mengutip cerita temannya.\r\n",
      "sample:  pesawat parkir di remote area kami siapkan bus antar penumpang ke terminal ---- setiap pesawat yang parkir di remote area sudah kami siapkan bus untuk mengantar penumpang ke terminal.\r\n",
      "bleu score on test dataset:  33.15305857930267\r\n",
      "evaluate on data c-gedung-roboh\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='../train/result/result_linearized_penman/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"../train/result/result_linearized_penman/model\",\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 29\r\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:05<00:00,  1.39it/s]\r\n",
      "sample:  pengalihan dilakukan kendaraan yang melaju dari arah mal bintaro xchange dan tol bintaro menuju jalan boulevard bintaro dengan menggunakan flyover di atas lampu indomobil merah ---- pengalihan dilakukan bagi pengendara yang melaju dari arah mal bintaro xchange dan tol bintaro menuju jalan boulevard bintaro dengan menggunakan flyover di atas lampu merah indomobil.\r\n",
      "sample:  kegagalan dan kesalahan tes tanah mengakibatkan struktur menjadi gedung miring di menara saidah di jalan jakarta timur mt haryono mt haryono ---- kegagalan struktur dan kesalahan tes tanah yang mengakibatkan gedung miring juga terjadi pada menara saidah di jalan mt haryono, jakarta timur.\r\n",
      "sample:  kapolres ayi supardan akbp di tangerang selatan membenarkan peristiwa di bintaro yang roboh gedung menarik hati masyarakat banyak ---- kapolres tangerang selatan, akbp ayi supardan membenarkan peristiwa robohnya gedung di bintaro yang menarik perhatian masyarakat banyak.\r\n",
      "sample:  panin memutuskan melanjutkan pembangunan gedung tersebut dikarenakan dinyatakan tidak lulus uji kelayakan ---- panin memutuskan tidak melanjutkan pembangunan gedung itu karena dinyatakan tidak lulus uji kelayakan.\r\n",
      "sample:  gedung yang disebut dinyatakan tidak lulus ujian tersebut dinyatakan sehingga pembangunan gedung itu memutuskan untuk tidak dilanjutkan ---- gedung tersebut dinyatakan tidak lulus uji sehingga pembangunan gedung diputuskan tidak dilanjutkan.\r\n",
      "sample:  kasat akp samian di polres tangerang selatan melalui reskrim mengatakan, penyelidikan dilakukan pihaknya saat ini untuk mengetahui penyebab runtuhnya gedung ---- kasat reskrim polres tangerangg selatan, akp samian mengatakan saat ini pihaknya melakukan penyelidikan untuk mengetahui penyebab runtuhnya gedung.\r\n",
      "sample:  hingga ini, kami mendalami peristiwa yang disebut ---- hingga kini kami masih mendalami peristiwa tersebut.\r\n",
      "sample:  disebutkan, korban tidak menimbulkan korban ---- kejadian tersebut tidak timbul korban.\r\n",
      "sample:  menjadi kerugian material ---- terjadi kerugian material.\r\n",
      "sample:  di sektor bintaro, tangerang selatan, 7 gedung diduga menyalahi prosedur ---- pembongkaran gedung di sektor 7, bintaro, tangerang selatan, diduga menyalahi prosedur.\r\n",
      "bleu score on test dataset:  32.934517772138726\r\n",
      "evaluate on data d-indo-fuji\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='../train/result/result_linearized_penman/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"../train/result/result_linearized_penman/model\",\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 27\r\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:07<00:00,  1.05s/it]\r\n",
      "sample:  indosat bersama fujitsu indonesia ooredoo menandatangani nota kesepahaman di dalam rangka memantapkan mitra bisnis yang telah dibangunnya dalam rangka menghadirkan solusi smart dan internet of things di mobility ---- indosat ooredoo bersama fujitsu indonesia menandatangani nota kesepahaman dalam rangka memantapkan kemitraan dengan para pelanggan bisnis yang telah dibangun dalam menghadirkan solusi smart mobility dan internet of things.\r\n",
      "sample:  indosat bersama fujitsu indonesia ooredoo menandatangani nota kesepahaman di dalam rangka memantapkan mitra bisnis yang telah dibangunnya dalam rangka menghadirkan solusi smart dan internet of things di mobility ---- indosat ooredoo bersama fujitsu indonesia menandatangani nota kesepahaman dalam rangka memantapkan kemitraan dengan para pelanggan bisnis yang telah dibangun dalam menghadirkan solusi smart mobility dan internet of things.\r\n",
      "sample:  smart mobility dan iot mengalami perkembangan yang cukup signifikan hingga hingga mengubah cara perusahaan yang mendalam mengelola aset ---- smart mobility dan iot mengalami perkembangan cukup signifikan sehingga mengubah cara perusahaan dalam mengelola aset.\r\n",
      "sample:  indosat bersama fujitsu indonesia ooredoo menandatangani nota kesepahaman di dalam rangka memantapkan mitra bisnis yang telah dibangunnya dalam rangka menghadirkan solusi smart dan internet of things di mobility ---- indosat ooredoo bersama fujitsu indonesia menandatangani nota kesepahaman dalam rangka memantapkan kemitraan dengan para pelanggan bisnis yang telah menghadirkan solusi smart mobility dan internet of things.\r\n",
      "sample:  kerja sama difokuskan pada sektor transportasi dan transportasi otomotif secara luas dan luas untuk memenuhi kebutuhan pelanggan korporasi di indonesia dan sektor industribagainya. ---- kerja sama ini akan berfokus pada sektor otomotif dan transportasi dan akan diperluas ke berbagai sektor industri untuk memenuhi kebutuhan pelanggan korporasi di indonesia.\r\n",
      "sample:  president achmad sofwan, director fujitsu indonesia menuturkan, tersedianya mobilitas untuk memanfaatkan layanan memproses data realtime dan memanfaatkan teknologi untuk mengoptimalkan strategi perusahaan. ---- mobilitas akan menyediakan cara untuk mengoptimalkan strategi perusahaan dengan memanfaatkan aplikasi dan layanan yang dapat memproses data real-time, tutur achmad sofwan, president director fujitsu indonesia.\r\n",
      "sample:  kerja sama difokuskan pada sektor transportasi dan transportasi otomotif secara luas dan luas untuk memenuhi kebutuhan pelanggan korporasi di indonesia dan sektor industribagainya. ---- kerja sama ini akan berfokus pada sektor otomotif dan transportasi dan akan diperluas ke berbagai sektor industri untuk memenuhi kebutuhan pelanggan korporasi di indonesia.\r\n",
      "sample:  indosat ooredoo bekerja sama dengan fujitsu indonesia untuk menghadirkan solusi smart mobility dan internet of things ---- indosat ooredoo bekerja sama dengan fujitsu indonesia menghadirkan solusi smart mobility dan internet of things.\r\n",
      "sample:  president achmad sofwan, director fujitsu, mengungkapkan tersedianya mobilitas untuk memanfaatkan layanan memproses data realtime dan memanfaatkan teknologi untuk mengoptimalkan strategi perusahaan. ---- president director fujitsu, achmad sofwan mengungkap, mobilitas akan menyediakan cara mengoptimalisasikan strategi perusahaan dengan memanfaatkan aplikasi dan layanan dalam aktivitas memproses data real-time.\r\n",
      "sample:  kerja sama difokuskan pada sektor transportasi dan transportasi otomotif secara luas dan luas untuk memenuhi kebutuhan pelanggan korporasi di indonesia dan sektor industribagainya. ---- kerja sama ini akan berfokus pada sektor otomotif dan transportasi dan akan diperluas ke berbagai sektor industri untuk memenuhi kebutuhan pelanggan korporasi di indonesia.\r\n",
      "bleu score on test dataset:  28.182682532038704\r\n",
      "evaluate on data f-bunuh-diri\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='../train/result/result_linearized_penman/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"../train/result/result_linearized_penman/model\",\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 23\r\n",
      "  0%|                                                     | 0/6 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:05<00:00,  1.14it/s]\r\n",
      "sample:  ciptadi melompat dari megatron jembatan yang ketinggiannya diperkirakan mencapai 1,5 meter yang disebrangi orang ---- ciptadi dengan nekat melompat dari megatron jembatan penyeberangan orang yang tingginya diperkirakan mencapai 15 meter.\r\n",
      "sample:  hal yang disebut diungkapkan kasubag reny marthaliana dari humas kompol mengungkapkan, kabag dede rojudin dari kompol ops polrestabes bandung bertemu jumat di mapolrestabes bandung ---- hal tersebut diungkapkan kabag ops polrestabes bandung kompol dede rojudin didampingi kasubag humas kompol reny marthaliana, saat ditemui di mapolrestabes bandung, jumat.\r\n",
      "sample:  rezha, warga kota bandung, noviana, mengatakan ia dan jemaat lainnya memperhatikan megatron di depan kantor pos besar di bandung di jembatan penyeberangan orang ---- rezha noviana, warga kota bandung mengatakan ia dan jemaat lainnya langsung memperhatikan megatron jembatan penyeberangan orang depan kantor pos besar bandung setelah bubar salat jumat di masjid raya bandung.\r\n",
      "sample:  petugas linmas dan berapa satpam berdiri di atas jpo ---- ketika itu, petugas linmas dan beberapa satpam berdiri di atas jpo.\r\n",
      "sample:  aksi bunuh diri terjadi di alun alun bandung belum lama ini ---- aksi bunuh diri di alun - alun bandung belum lama ini terjadi.\r\n",
      "sample:  orang tua itu menjatuhkan diri ke jpo di alun kota bandung di alun ---- seorang pria tua nekat menjatuhkan diri dari jpo di alun - alun kota bandung.\r\n",
      "sample:  sudirman, yang menjadi saksi mata pembunuhan di alun alun bandung, mengatakan dirinya anggota linmas satpol pp sudirman mengatakan, pria yang disebutnya itu diperkirakan berusia 30 tahun ---- sudirman, anggota linmas satpol pp kota bandung yang menjadi saksi mata aksi bunuh diri di alun - alun bandung itu mengatakan, pria tersebut diperkirakan berusia 50 tahun.\r\n",
      "sample:  pada jumat, seorang lelaki orang itu terjatuh dari megatron di depan bandung di pos giro besar bandung di jembatan penyeberangan ---- seorang lelaki menjatuhkan diri dari megatron jembatan penyeberangan di depan pos giro besar bandung, bandung, jumat.\r\n",
      "sample:  lelaki tengah baya itu mengakhiri hidupnya di tengah padatnya lalu lintas di jalan asia afrika ---- seorang lelaki tengah baya nekat mengakhiri hidupnya di tengah kepadatan lalu lintas jalan asia afrika.\r\n",
      "sample:  pria misterius yang bunuh diri di jembatan di jalan bandung jawa barat ke asia afrika di seberang orang membuat pesan belum terjun secara nekat ---- pria misterius yang bunuh diri dari jembatan penyeberangan orang di jalan asia afrika, bandung, jawa barat, membuat pesan sebelum nekat terjun.\r\n",
      "bleu score on test dataset:  25.962400389946577\r\n",
      "evaluate on data g-gempa-dieng\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='../train/result/result_linearized_penman/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"../train/result/result_linearized_penman/model\",\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 19\r\n",
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:04<00:00,  1.07it/s]\r\n",
      "sample:  stasiun banjarnegara, jawa tengah, menyatakan badan meteorologi klimatologi geofisika geofisika menyatakan gempa berkekuatan 4 8 skala richter mengguncang dataran tinggi dieng pada pukul 19 00 wib ---- stasiun geofisika badan meteorologi klimatologi dan geofisika banjarnegara, jawa tengah, menyatakan bahwa gempa yang mengguncang dataran tinggi dieng pukul 19.00 wib berkekuatan 4,8 pada skala richter.\r\n",
      "sample:  pusat gempa diperkirakan ada di desa di kecamatan batang bawang, tanji gugur ---- pusat gempa diperkirakan berada di desa tanji gugur, kecamatan bawang, kabupaten batang.\r\n",
      "sample:  pvmbg merekomendasikan untuk sementara jalan yang berdekatan dengan kawah di desa sumberejo yang ditimbang ditutup seluruhnya ---- pvmbg merekomendasikan seluruh jalan yang mendekati kawah timbang di desa sumberejo sementara ditutup.\r\n",
      "sample:  kepala surono di pusat vulkanologi mitigasi bencana geologi mengatakan rekaman sebanyak 86 kali gempa yang terjadi pukul 19. 00 wib di dataran tinggi dieng ---- kepala pusat vulkanologi dan mitigasi bencana geologi surono mengatakan bahwa gempa yang terjadi di dataran tinggi dieng pukul 19.00 wib terekam sebanyak 86 kali.\r\n",
      "sample:  penutupan dilakukan hingga tim yang mengukur konsentrasi gas di lapangan menyatakan tidak ada gas berbahaya ---- penutupan ini dilakukan hingga tim di lapangan yang mengukur konsentrasi gas menyatakan tidak ada gas yang berbahaya.\r\n",
      "sample:  pvmbg merekomendasikan untuk sementara jalan yang berdekatan dengan kawah di desa sumberejo yang ditimbang ditutup seluruhnya ---- pvmbg merekomendasikan seluruh jalan yang mendekati kawah timbang di desa sumberejo sementara ditutup.\r\n",
      "sample:  petugas pusat vulkanologi mitigasi bencana geologi terjun-01 untuk memantau aktivitas kawah timbang dan memberikan informasi ---- petugas pusat vulkanologi dan mitigasi bencana geologi diterjunkan untuk memantau aktivitas kawah timbang dan memberikan informasi.\r\n",
      "sample:  data yang dikeluarkan oleh pusat vulkanologi mitigasi bencana geologi menyebutkan, rasa dan telah merekam gempa sebanyak 86 kali mulai gempa pada pukul 19:00 wib ---- data yang dikeluarkan dari pusat vulkanologi dan mitigasi bencana geologi menyebutkan gempa mulai terasa pukul 19.00 wib dan telah terekam gempa sebanyak 86 kali.\r\n",
      "sample:  pengungsi yang mengungsi di kabupaten banjarnegara meninggal sabtu pagi ---- pengungsi di kabupaten banjarnegara, pada sabtu pagi mulai meninggalkan pengungsian.\r\n",
      "sample:  stasiun banjarnegara, badan meteorologi klimatologi geofisika, menyatakan geofisika gempa berkekuatan 4 8 skala richter mengguncang dataran tinggi dieng pada pukul 19 00 wib ---- stasiun geofisika badan meteorologi klimatologi dan geofisika banjarnegara menyatakan gempa yang mengguncang dataran tinggi dieng pukul 19.00 wib berkekuatan 4,8 skala richter *(sr)*.\r\n",
      "bleu score on test dataset:  30.770939715069208\r\n",
      "mkdir: cannot create directory ‘result/linearized_penman’: File exists\r\n",
      "mv: cannot move 'result/amr_simple_test' to 'result/linearized_penman/amr_simple_test': Directory not empty\r\n",
      "mv: cannot move 'result/b-salah-darat' to 'result/linearized_penman/b-salah-darat': Directory not empty\r\n",
      "mv: cannot move 'result/c-gedung-roboh' to 'result/linearized_penman/c-gedung-roboh': Directory not empty\r\n",
      "mv: cannot move 'result/d-indo-fuji' to 'result/linearized_penman/d-indo-fuji': Directory not empty\r\n",
      "mv: cannot move 'result/f-bunuh-diri' to 'result/linearized_penman/f-bunuh-diri': Directory not empty\r\n",
      "mv: cannot move 'result/g-gempa-dieng' to 'result/linearized_penman/g-gempa-dieng': Directory not empty\r\n",
      "mv: cannot move 'result/linearized_penman' to a subdirectory of itself, 'result/linearized_penman/linearized_penman'\r\n"
     ]
    }
   ],
   "source": [
    "!./evaluate_indoT5_to_all.sh ../train/result/result_linearized_penman linearized_penman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e52ef68a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T02:44:21.433341Z",
     "iopub.status.busy": "2022-05-24T02:44:21.432504Z",
     "iopub.status.idle": "2022-05-24T02:44:22.145388Z",
     "shell.execute_reply": "2022-05-24T02:44:22.144722Z"
    },
    "papermill": {
     "duration": 27.550879,
     "end_time": "2022-05-24T02:44:22.145538",
     "exception": false,
     "start_time": "2022-05-24T02:43:54.594659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: result/ (stored 0%)\r\n",
      "  adding: result/c-gedung-roboh/ (stored 0%)\r\n",
      "  adding: result/c-gedung-roboh/test_label.txt (deflated 62%)\r\n",
      "  adding: result/c-gedung-roboh/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/c-gedung-roboh/test_generations.txt (deflated 62%)\r\n",
      "  adding: result/g-gempa-dieng/ (stored 0%)\r\n",
      "  adding: result/g-gempa-dieng/test_label.txt (deflated 67%)\r\n",
      "  adding: result/g-gempa-dieng/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/g-gempa-dieng/test_generations.txt (deflated 66%)\r\n",
      "  adding: result/b-salah-darat/ (stored 0%)\r\n",
      "  adding: result/b-salah-darat/test_label.txt (deflated 66%)\r\n",
      "  adding: result/b-salah-darat/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/b-salah-darat/test_generations.txt (deflated 67%)\r\n",
      "  adding: result/linearized_penman/ (stored 0%)\r\n",
      "  adding: result/linearized_penman/c-gedung-roboh/ (stored 0%)\r\n",
      "  adding: result/linearized_penman/c-gedung-roboh/test_label.txt (deflated 62%)\r\n",
      "  adding: result/linearized_penman/c-gedung-roboh/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/linearized_penman/c-gedung-roboh/test_generations.txt (deflated 60%)\r\n",
      "  adding: result/linearized_penman/g-gempa-dieng/ (stored 0%)\r\n",
      "  adding: result/linearized_penman/g-gempa-dieng/test_label.txt (deflated 67%)\r\n",
      "  adding: result/linearized_penman/g-gempa-dieng/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/linearized_penman/g-gempa-dieng/test_generations.txt (deflated 62%)\r\n",
      "  adding: result/linearized_penman/b-salah-darat/ (stored 0%)\r\n",
      "  adding: result/linearized_penman/b-salah-darat/test_label.txt (deflated 66%)\r\n",
      "  adding: result/linearized_penman/b-salah-darat/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/linearized_penman/b-salah-darat/test_generations.txt (deflated 61%)\r\n",
      "  adding: result/linearized_penman/d-indo-fuji/ (stored 0%)\r\n",
      "  adding: result/linearized_penman/d-indo-fuji/test_label.txt (deflated 86%)\r\n",
      "  adding: result/linearized_penman/d-indo-fuji/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/linearized_penman/d-indo-fuji/test_generations.txt (deflated 83%)\r\n",
      "  adding: result/linearized_penman/amr_simple_test/ (stored 0%)\r\n",
      "  adding: result/linearized_penman/amr_simple_test/test_label.txt (deflated 60%)\r\n",
      "  adding: result/linearized_penman/amr_simple_test/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/linearized_penman/amr_simple_test/test_generations.txt (deflated 63%)\r\n",
      "  adding: result/linearized_penman/f-bunuh-diri/ (stored 0%)\r\n",
      "  adding: result/linearized_penman/f-bunuh-diri/test_label.txt (deflated 68%)\r\n",
      "  adding: result/linearized_penman/f-bunuh-diri/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/linearized_penman/f-bunuh-diri/test_generations.txt (deflated 61%)\r\n",
      "  adding: result/d-indo-fuji/ (stored 0%)\r\n",
      "  adding: result/d-indo-fuji/test_label.txt (deflated 86%)\r\n",
      "  adding: result/d-indo-fuji/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/d-indo-fuji/test_generations.txt (deflated 86%)\r\n",
      "  adding: result/amr_simple_test/ (stored 0%)\r\n",
      "  adding: result/amr_simple_test/test_label.txt (deflated 60%)\r\n",
      "  adding: result/amr_simple_test/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/amr_simple_test/test_generations.txt (deflated 62%)\r\n",
      "  adding: result/f-bunuh-diri/ (stored 0%)\r\n",
      "  adding: result/f-bunuh-diri/test_label.txt (deflated 68%)\r\n",
      "  adding: result/f-bunuh-diri/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/f-bunuh-diri/test_generations.txt (deflated 65%)\r\n"
     ]
    }
   ],
   "source": [
    "!zip -r result_with_sta.zip result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f9b53b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T02:45:15.130481Z",
     "iopub.status.busy": "2022-05-24T02:45:15.126603Z",
     "iopub.status.idle": "2022-05-24T02:45:15.813715Z",
     "shell.execute_reply": "2022-05-24T02:45:15.813026Z"
    },
    "papermill": {
     "duration": 27.305671,
     "end_time": "2022-05-24T02:45:15.813859",
     "exception": false,
     "start_time": "2022-05-24T02:44:48.508188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate_indoBART.py\t     result_without_sta.zip\r\n",
      "evaluate_indoBART_to_all.sh  zeroshot_evaluate_indoBART.py\r\n",
      "evaluate_indoT5.py\t     zeroshot_evaluate_indoBART_to_all.sh\r\n",
      "evaluate_indoT5_to_all.sh    zeroshot_evaluate_indoT5.py\r\n",
      "result\t\t\t     zeroshot_evaluate_indoT5_to_all.sh\r\n",
      "result_with_sta.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b897a46",
   "metadata": {
    "papermill": {
     "duration": 27.267354,
     "end_time": "2022-05-24T02:46:09.911456",
     "exception": false,
     "start_time": "2022-05-24T02:45:42.644102",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## linearized penman + tree level embeddings + supervised task adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c83b0f96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T02:47:03.988142Z",
     "iopub.status.busy": "2022-05-24T02:47:03.987284Z",
     "iopub.status.idle": "2022-05-24T02:47:03.991329Z",
     "shell.execute_reply": "2022-05-24T02:47:03.991832Z"
    },
    "papermill": {
     "duration": 26.877786,
     "end_time": "2022-05-24T02:47:03.992018",
     "exception": false,
     "start_time": "2022-05-24T02:46:37.114232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/amr-to-text-indonesia/tree_level_embeddings\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/amr-to-text-indonesia/tree_level_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6508ddb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T02:47:56.899353Z",
     "iopub.status.busy": "2022-05-24T02:47:56.898305Z",
     "iopub.status.idle": "2022-05-24T02:47:57.614906Z",
     "shell.execute_reply": "2022-05-24T02:47:57.614298Z"
    },
    "papermill": {
     "duration": 27.664269,
     "end_time": "2022-05-24T02:47:57.615072",
     "exception": false,
     "start_time": "2022-05-24T02:47:29.950803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'result/amr_simple_test': Is a directory\r\n",
      "rm: cannot remove 'result/b-salah-darat': Is a directory\r\n",
      "rm: cannot remove 'result/c-gedung-roboh': Is a directory\r\n",
      "rm: cannot remove 'result/d-indo-fuji': Is a directory\r\n",
      "rm: cannot remove 'result/f-bunuh-diri': Is a directory\r\n",
      "rm: cannot remove 'result/g-gempa-dieng': Is a directory\r\n",
      "rm: cannot remove 'result/model': Is a directory\r\n",
      "rm: cannot remove 'result/tokenizer': Is a directory\r\n"
     ]
    }
   ],
   "source": [
    "!rm result/* -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a1dfe10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T02:48:51.243446Z",
     "iopub.status.busy": "2022-05-24T02:48:51.242612Z",
     "iopub.status.idle": "2022-05-24T04:47:45.648885Z",
     "shell.execute_reply": "2022-05-24T04:47:45.648336Z"
    },
    "papermill": {
     "duration": 7161.44209,
     "end_time": "2022-05-24T04:47:45.649042",
     "exception": false,
     "start_time": "2022-05-24T02:48:24.206952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing method linearized_penman_with_tree_level\r\n",
      "silver data folder ../amr-indo-dataset/data_154k_raw_silver_amr_indo4b_news\r\n",
      "mkdir: cannot create directory ‘data/preprocessed_silver_data’: File exists\r\n",
      "Namespace(mode='linearized_penman_with_tree_level', result_amr_path='data/preprocessed_silver_data/train.amr.txt', result_sent_path='data/preprocessed_silver_data/train.sent.txt', source_file_path=None, source_folder_path='../amr-indo-dataset/data_154k_raw_silver_amr_indo4b_news')\r\n",
      "100%|███████████████████████████████| 263263/263263 [00:02<00:00, 130861.74it/s]\r\n",
      "15995\r\n",
      "100%|███████████████████████████████| 264330/264330 [00:02<00:00, 129873.02it/s]\r\n",
      "15942\r\n",
      "100%|███████████████████████████████| 263508/263508 [00:02<00:00, 125921.41it/s]\r\n",
      "15926\r\n",
      "100%|███████████████████████████████| 264253/264253 [00:01<00:00, 133087.52it/s]\r\n",
      "16046\r\n",
      "100%|███████████████████████████████| 268572/268572 [00:02<00:00, 133854.16it/s]\r\n",
      "14937\r\n",
      "100%|███████████████████████████████| 268262/268262 [00:02<00:00, 108249.75it/s]\r\n",
      "14991\r\n",
      "100%|███████████████████████████████| 265325/265325 [00:02<00:00, 127350.93it/s]\r\n",
      "16077\r\n",
      "100%|███████████████████████████████| 266966/266966 [00:02<00:00, 132894.07it/s]\r\n",
      "14930\r\n",
      "100%|███████████████████████████████| 270251/270251 [00:02<00:00, 114550.92it/s]\r\n",
      "14986\r\n",
      "100%|███████████████████████████████| 269258/269258 [00:02<00:00, 132139.17it/s]\r\n",
      "15062\r\n",
      "total: 154892  tuple_sent_amr_level\r\n",
      "Running on the GPU\r\n",
      "Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at Wikidepia/IndoT5-base and are newly initialized: ['encoder.tree_embed.weight']\r\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\r\n",
      "added 9 tokens\r\n",
      "len train dataset:  154892\r\n",
      "len dev dataset:  19\r\n",
      "len test dataset: 306\r\n",
      "len train dataloader:  38723\r\n",
      "(Epoch 1) TRAIN LOSS:0.9531 LR:0.00010000: 100%|█| 38723/38723 [1:57:33<00:00,  \r\n",
      "(Epoch 1) DEV LOSS:2.7189 LR:0.00010000: 100%|████| 5/5 [00:00<00:00, 25.38it/s]\r\n",
      "bleu score on dev:  26.574067459963715\r\n",
      "  0%|                                                    | 0/77 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|███████████████████████████████████████████| 77/77 [00:20<00:00,  3.79it/s]\r\n",
      "sample:  ilham meniup balon. ---- balon itu ditiup ilham\r\n",
      "sample:  obe menulis puisi. ---- obe menulis puisi\r\n",
      "sample:  saya mengetik makalah itu. ---- saya mengetik makalah\r\n",
      "sample:  angga anak ajaib. ---- angga anak ajaib\r\n",
      "sample:  ibu saya orang dosen. ---- ibuku seorang dosen\r\n",
      "bleu score on test dataset:  33.90272040917121\r\n"
     ]
    }
   ],
   "source": [
    "!chmod +x train_indoT5_on_silver_data.sh\n",
    "!./train_indoT5_on_silver_data.sh linearized_penman_with_tree_level ../amr-indo-dataset/data_154k_raw_silver_amr_indo4b_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a1422b3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T04:49:20.846222Z",
     "iopub.status.busy": "2022-05-24T04:49:20.845153Z",
     "iopub.status.idle": "2022-05-24T04:52:50.255232Z",
     "shell.execute_reply": "2022-05-24T04:52:50.254505Z"
    },
    "papermill": {
     "duration": 256.567378,
     "end_time": "2022-05-24T04:52:50.255385",
     "exception": false,
     "start_time": "2022-05-24T04:48:33.688007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\r\n",
      "resume from checkpoint\r\n",
      "added 0 tokens\r\n",
      "len train dataset:  2648\r\n",
      "len dev dataset:  19\r\n",
      "len test dataset: 306\r\n",
      "len train dataloader:  662\r\n",
      "(Epoch 1) TRAIN LOSS:0.8003 LR:0.00010000: 100%|█| 662/662 [01:26<00:00,  7.65it\r\n",
      "(Epoch 1) DEV LOSS:0.7957 LR:0.00010000: 100%|████| 5/5 [00:00<00:00, 26.99it/s]\r\n",
      "bleu score on dev:  35.61641995529009\r\n",
      "(Epoch 2) TRAIN LOSS:0.4653 LR:0.00010000: 100%|█| 662/662 [01:27<00:00,  7.59it\r\n",
      "(Epoch 2) DEV LOSS:0.7845 LR:0.00010000: 100%|████| 5/5 [00:00<00:00, 26.69it/s]\r\n",
      "bleu score on dev:  45.63851718376595\r\n",
      "  0%|                                                    | 0/77 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|███████████████████████████████████████████| 77/77 [00:17<00:00,  4.29it/s]\r\n",
      "sample:  balon ditiup ilham ---- balon itu ditiup ilham\r\n",
      "sample:  puisi ditulis obe ---- obe menulis puisi\r\n",
      "sample:  makalah diketik oleh saya ---- saya mengetik makalah\r\n",
      "sample:  angga anak ajaib ---- angga anak ajaib\r\n",
      "sample:  ibu seorang dosen ---- ibuku seorang dosen\r\n",
      "bleu score on test dataset:  40.67158203442678\r\n"
     ]
    }
   ],
   "source": [
    "!python train_indoT5.py --model_type indo-t5 --n_epochs 2 --lr 0.0001 --data_folder ../data/preprocessed_data/linearized_penman_with_tree_level  --result_folder result --resume_from_checkpoint True --saved_model_folder_path result/result_supervised_task_adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a9f630e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T04:54:25.139253Z",
     "iopub.status.busy": "2022-05-24T04:54:25.138483Z",
     "iopub.status.idle": "2022-05-24T04:56:37.612426Z",
     "shell.execute_reply": "2022-05-24T04:56:37.611641Z"
    },
    "papermill": {
     "duration": 179.716538,
     "end_time": "2022-05-24T04:56:37.612602",
     "exception": false,
     "start_time": "2022-05-24T04:53:37.896064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model folder result\r\n",
      "preprocessing method linearized_penman_with_tree_level\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data’: File exists\r\n",
      "preprocess amr_simple_test\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/amr_simple_test’: File exists\r\n",
      "Namespace(mode='linearized_penman_with_tree_level', result_amr_path='data/test/preprocessed_data/amr_simple_test/test.amr.txt', result_sent_path='data/test/preprocessed_data/amr_simple_test/test.sent.txt', source_file_path='data/test/amr_simple_test.txt', source_folder_path=None)\r\n",
      "100%|███████████████████████████████████| 2618/2618 [00:00<00:00, 100107.47it/s]\r\n",
      "total: 306  tuple_sent_amr_level\r\n",
      "preprocess b-salah-darat\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/b-salah-darat’: File exists\r\n",
      "Namespace(mode='linearized_penman_with_tree_level', result_amr_path='data/test/preprocessed_data/b-salah-darat/test.amr.txt', result_sent_path='data/test/preprocessed_data/b-salah-darat/test.sent.txt', source_file_path='data/test/b-salah-darat.txt', source_folder_path=None)\r\n",
      "100%|██████████████████████████████████████| 676/676 [00:00<00:00, 72738.57it/s]\r\n",
      "total: 32  tuple_sent_amr_level\r\n",
      "preprocess c-gedung-roboh\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/c-gedung-roboh’: File exists\r\n",
      "Namespace(mode='linearized_penman_with_tree_level', result_amr_path='data/test/preprocessed_data/c-gedung-roboh/test.amr.txt', result_sent_path='data/test/preprocessed_data/c-gedung-roboh/test.sent.txt', source_file_path='data/test/c-gedung-roboh.txt', source_folder_path=None)\r\n",
      "100%|█████████████████████████████████████| 606/606 [00:00<00:00, 127049.30it/s]\r\n",
      "total: 29  tuple_sent_amr_level\r\n",
      "preprocess d-indo-fuji\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/d-indo-fuji’: File exists\r\n",
      "Namespace(mode='linearized_penman_with_tree_level', result_amr_path='data/test/preprocessed_data/d-indo-fuji/test.amr.txt', result_sent_path='data/test/preprocessed_data/d-indo-fuji/test.sent.txt', source_file_path='data/test/d-indo-fuji.txt', source_folder_path=None)\r\n",
      "100%|█████████████████████████████████████| 745/745 [00:00<00:00, 122712.71it/s]\r\n",
      "total: 27  tuple_sent_amr_level\r\n",
      "preprocess f-bunuh-diri\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/f-bunuh-diri’: File exists\r\n",
      "Namespace(mode='linearized_penman_with_tree_level', result_amr_path='data/test/preprocessed_data/f-bunuh-diri/test.amr.txt', result_sent_path='data/test/preprocessed_data/f-bunuh-diri/test.sent.txt', source_file_path='data/test/f-bunuh-diri.txt', source_folder_path=None)\r\n",
      "100%|█████████████████████████████████████| 468/468 [00:00<00:00, 123649.40it/s]\r\n",
      "total: 23  tuple_sent_amr_level\r\n",
      "preprocess g-gempa-dieng\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/g-gempa-dieng’: File exists\r\n",
      "Namespace(mode='linearized_penman_with_tree_level', result_amr_path='data/test/preprocessed_data/g-gempa-dieng/test.amr.txt', result_sent_path='data/test/preprocessed_data/g-gempa-dieng/test.sent.txt', source_file_path='data/test/g-gempa-dieng.txt', source_folder_path=None)\r\n",
      "100%|█████████████████████████████████████| 412/412 [00:00<00:00, 129762.95it/s]\r\n",
      "total: 19  tuple_sent_amr_level\r\n",
      "evaluate on data amr_simple_test\r\n",
      "mkdir: cannot create directory ‘result/amr_simple_test’: File exists\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='result/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"result/model\",\r\n",
      "  \"additional_config\": {\r\n",
      "    \"tree_max\": 512\r\n",
      "  },\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 306\r\n",
      "  0%|                                                    | 0/77 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|███████████████████████████████████████████| 77/77 [00:17<00:00,  4.36it/s]\r\n",
      "sample:  balon ditiup ilham ---- balon itu ditiup ilham\r\n",
      "sample:  puisi ditulis obe ---- obe menulis puisi\r\n",
      "sample:  makalah diketik oleh saya ---- saya mengetik makalah\r\n",
      "sample:  angga anak ajaib ---- angga anak ajaib\r\n",
      "sample:  ibu seorang dosen ---- ibuku seorang dosen\r\n",
      "sample:  dia sedang berenang ---- dia sedang berenang\r\n",
      "sample:  ilham mencari buku yang hilang ---- ilham sedang mencari bukunya yang hilang\r\n",
      "sample:  di halaman rumah, ibu menyapu ---- ibu sedang menyapu halaman rumah\r\n",
      "sample:  padi dibajak oleh ayah di sawah ---- ayah sedang membajak padi di sawah\r\n",
      "sample:  andi pergi ke perkemahan di tepi pantai ---- andi pergi berkemah di tepi pantai\r\n",
      "bleu score on test dataset:  40.67158203442678\r\n",
      "evaluate on data b-salah-darat\r\n",
      "mkdir: cannot create directory ‘result/b-salah-darat’: File exists\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='result/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"result/model\",\r\n",
      "  \"additional_config\": {\r\n",
      "    \"tree_max\": 512\r\n",
      "  },\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 32\r\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:06<00:00,  1.25it/s]\r\n",
      "sample:  kantor sama pt angkasa pura ii dengan otoritas bandara soekarno-hatta membahas insiden penumpang yang terbang dari pesawat lion air jt 161 dari jakarta ---- kantor imigrasi bandara soekarno-hatta bersama kantor otoritas bandara soekarno-hatta dan pt angkasa pura ii membahas insiden penumpang penerbangan pesawat lion air jt 161 yang tiba di jakarta dari singapura 10 mei 2016.\r\n",
      "sample:  kepala kantor imigrasi soekarno-hatta alif suadi menuturkan, kami meeting soal itu kepada tempo pada sabtu malam ini (14 mei) ---- kami meeting soal ini,\" ujar kepala kantor imigrasi soekarno-hatta alif suadi kepada tempo, sabtu malam ini, 14 mei 2016.\r\n",
      "sample:  anak temannya, natalie, berangkat ke singapura dan menggunakan pesawat lion air jt 161 ---- anak temannya natalie berangkat dari singapura dan menggunakan pesawat lion air jt 161, pada pukul 18.50.\r\n",
      "sample:  sekretaris agus haryadi dari perusahaan pt angkasa pura ii mengatakan, pihaknya akan melakukan koordinasi dengan kantor otoritas bandara wilayah 1 berkaitan dengan perisitiwa ---- sekretaris perusahaan pt angkasa pura ii agus haryadi mengatakan selaku pengelola bandara internasional soekarno-hatta, pihaknya akan berkoordinasi dengan kantor otoritas bandara wilayah i terkait dengan peristiwa ini.\r\n",
      "sample:  di remote area, kami menyiapkan bus antar penumpang di terminal ---- setiap pesawat yang parkir di remote area sudah kami siapkan bus untuk mengantar penumpang ke terminal.\r\n",
      "sample:  edward menuturkan, terdapat sopir yang menjemput penumpang di padang dengan bus ---- terdapat sopir bus yang akan menjemput penumpang dari padang\" ujar edward.\r\n",
      "sample:  pihak otoritas bandara soetta memanggil pihak terkait dan melakukan investigasi ---- pihak otoritas bandara soetta akan memanggil pihak terkait dan dilakukan investigasi.\r\n",
      "sample:  kemenhub memberikan sanksi kepada pihak-pihak yang lalai ---- kemenhub memberikan sanksi kepada pihak-pihak yang lalai,\" ujarnya.\r\n",
      "sample:  zara mengatakan mengutip cerita temannya bahwa pesawat itu tidak mendarat di terminal ii ---- pesawat itu mendarat tidak di terminal ii, kata zara mengutip cerita temannya.\r\n",
      "sample:  di remote area, kami menyiapkan bus antar penumpang di terminal ---- setiap pesawat yang parkir di remote area sudah kami siapkan bus untuk mengantar penumpang ke terminal.\r\n",
      "bleu score on test dataset:  27.278250528903214\r\n",
      "evaluate on data c-gedung-roboh\r\n",
      "mkdir: cannot create directory ‘result/c-gedung-roboh’: File exists\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='result/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"result/model\",\r\n",
      "  \"additional_config\": {\r\n",
      "    \"tree_max\": 512\r\n",
      "  },\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 29\r\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:05<00:00,  1.35it/s]\r\n",
      "sample:  pengalihan dilakukan kendaraan laju dari arah mal bintaro xchange dan tol bintaro menuju jalan boulevard bintaro dengan menggunakan flyover di atas lampu merah ---- pengalihan dilakukan bagi pengendara yang melaju dari arah mal bintaro xchange dan tol bintaro menuju jalan boulevard bintaro dengan menggunakan flyover di atas lampu merah indomobil.\r\n",
      "sample:  kegagalan dan kesalahan tes tanah mengakibatkan gedung miring menjadi menara di jalan jakarta timur mt haryono mt saidah ---- kegagalan struktur dan kesalahan tes tanah yang mengakibatkan gedung miring juga terjadi pada menara saidah di jalan mt haryono, jakarta timur.\r\n",
      "sample:  kapolres ayi supardan akbp di tangerang selatan membenarkan peristiwa di bintaro robohnya gedung menarik hati masyarakat banyak ---- kapolres tangerang selatan, akbp ayi supardan membenarkan peristiwa robohnya gedung di bintaro yang menarik perhatian masyarakat banyak.\r\n",
      "sample:  panin memutuskan melanjutkan pembangunan gedung tersebut dikarenakan dinyatakan tidak lulus uji kelayakan ---- panin memutuskan tidak melanjutkan pembangunan gedung itu karena dinyatakan tidak lulus uji kelayakan.\r\n",
      "sample:  gedung yang disebut tersebut dinyatakan tidak lulus uji sehingga pembangunan gedung tersebut memutuskan untuk tidak dilanjutkan ---- gedung tersebut dinyatakan tidak lulus uji sehingga pembangunan gedung diputuskan tidak dilanjutkan.\r\n",
      "sample:  kasat akp samian di polres tangerang selatan mengatakan, reskrim sedang melakukan penyelidikan untuk mengetahui penyebab runtuhnya gedung saat ini ---- kasat reskrim polres tangerangg selatan, akp samian mengatakan saat ini pihaknya melakukan penyelidikan untuk mengetahui penyebab runtuhnya gedung.\r\n",
      "sample:  hingga ini, kami masih mendalami peristiwa yang disebutnya ---- hingga kini kami masih mendalami peristiwa tersebut.\r\n",
      "sample:  disebutkan, tidak terjadi korban ---- kejadian tersebut tidak timbul korban.\r\n",
      "sample:  terjadi kerugian material ---- terjadi kerugian material.\r\n",
      "sample:  di sektor 7, bintaro, tangerang selatan, gedung tersebut diduga menyalahi prosedur ---- pembongkaran gedung di sektor 7, bintaro, tangerang selatan, diduga menyalahi prosedur.\r\n",
      "bleu score on test dataset:  35.919969357581884\r\n",
      "evaluate on data d-indo-fuji\r\n",
      "mkdir: cannot create directory ‘result/d-indo-fuji’: File exists\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='result/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"result/model\",\r\n",
      "  \"additional_config\": {\r\n",
      "    \"tree_max\": 512\r\n",
      "  },\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 27\r\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:07<00:00,  1.01s/it]\r\n",
      "sample:  indosat bersama fujitsu indonesia menandatangani nota kesepahaman di dalam rangka memantapkan mitra pembangunan yang telah terjalin bisnis di dalam hadirnya solusi smart dan internet of things mobility ---- indosat ooredoo bersama fujitsu indonesia menandatangani nota kesepahaman dalam rangka memantapkan kemitraan dengan para pelanggan bisnis yang telah dibangun dalam menghadirkan solusi smart mobility dan internet of things.\r\n",
      "sample:  indosat bersama fujitsu indonesia menandatangani nota kesepahaman di dalam rangka memantapkan mitra pembangunan yang telah terjalin bisnis di dalam hadirnya solusi smart dan internet of things mobility ---- indosat ooredoo bersama fujitsu indonesia menandatangani nota kesepahaman dalam rangka memantapkan kemitraan dengan para pelanggan bisnis yang telah dibangun dalam menghadirkan solusi smart mobility dan internet of things.\r\n",
      "sample:  smart mobility dan iot mengalami perkembangan yang cukup signifikan hingga mengubah cara perusahaan di dalam mengelola aset ---- smart mobility dan iot mengalami perkembangan cukup signifikan sehingga mengubah cara perusahaan dalam mengelola aset.\r\n",
      "sample:  indosat bersama fujitsu indonesia menandatangani nota kesepahaman di dalam rangka memantapkan mitra pembangunan yang telah terjalin bisnis di dalam hadirnya solusi smart dan internet of things mobility ---- indosat ooredoo bersama fujitsu indonesia menandatangani nota kesepahaman dalam rangka memantapkan kemitraan dengan para pelanggan bisnis yang telah menghadirkan solusi smart mobility dan internet of things.\r\n",
      "sample:  kerja sama difokuskan pada sektor transportasi dan otomotif secara luas dan untuk memenuhi kebutuhan pelanggan korporasi di indonesia sebagai bagian dari sektor industri ---- kerja sama ini akan berfokus pada sektor otomotif dan transportasi dan akan diperluas ke berbagai sektor industri untuk memenuhi kebutuhan pelanggan korporasi di indonesia.\r\n",
      "sample:  president achmad sofwan, director fujitsu indonesia, menuturkan, mobilitas memanfaatkan layanan aplikasi dan proses data real-time dengan cara mengoptimalkan strategi perusahaan. ---- mobilitas akan menyediakan cara untuk mengoptimalkan strategi perusahaan dengan memanfaatkan aplikasi dan layanan yang dapat memproses data real-time, tutur achmad sofwan, president director fujitsu indonesia.\r\n",
      "sample:  kerja sama difokuskan pada sektor transportasi dan otomotif secara luas dan untuk memenuhi kebutuhan pelanggan korporasi di indonesia sebagai bagian dari sektor industri ---- kerja sama ini akan berfokus pada sektor otomotif dan transportasi dan akan diperluas ke berbagai sektor industri untuk memenuhi kebutuhan pelanggan korporasi di indonesia.\r\n",
      "sample:  indosat ooredoo bekerja sama dengan fujitsu indonesia untuk menghadirkan solusi smart mobility dan internet of things ---- indosat ooredoo bekerja sama dengan fujitsu indonesia menghadirkan solusi smart mobility dan internet of things.\r\n",
      "sample:  president achmad sofwan, director fujitsu, mengungkapkan, mobilitas memanfaatkan layanan aplikasi memproses data real-time dan mobilitas menggunakan cara mengoptimalkan strategi perusahaan. ---- president director fujitsu, achmad sofwan mengungkap, mobilitas akan menyediakan cara mengoptimalisasikan strategi perusahaan dengan memanfaatkan aplikasi dan layanan dalam aktivitas memproses data real-time.\r\n",
      "sample:  kerja sama difokuskan pada sektor transportasi dan otomotif secara luas dan untuk memenuhi kebutuhan pelanggan korporasi di indonesia sebagai bagian dari sektor industri ---- kerja sama ini akan berfokus pada sektor otomotif dan transportasi dan akan diperluas ke berbagai sektor industri untuk memenuhi kebutuhan pelanggan korporasi di indonesia.\r\n",
      "bleu score on test dataset:  28.682189394322666\r\n",
      "evaluate on data f-bunuh-diri\r\n",
      "mkdir: cannot create directory ‘result/f-bunuh-diri’: File exists\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='result/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"result/model\",\r\n",
      "  \"additional_config\": {\r\n",
      "    \"tree_max\": 512\r\n",
      "  },\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 23\r\n",
      "  0%|                                                     | 0/6 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:05<00:00,  1.15it/s]\r\n",
      "sample:  ciptadi melompat di megatron jembatan yang tingginya diperkirakan mencapai 15 meter yang disebrangi orang ---- ciptadi dengan nekat melompat dari megatron jembatan penyeberangan orang yang tingginya diperkirakan mencapai 15 meter.\r\n",
      "sample:  hal yang disebutnya terungkap ketika kasubag reny marthaliana didampingi kasubag humas kompol dede rojudin dari ops di polrestabes bandung, jumat, di mapolrestabes bandung ---- hal tersebut diungkapkan kabag ops polrestabes bandung kompol dede rojudin didampingi kasubag humas kompol reny marthaliana, saat ditemui di mapolrestabes bandung, jumat.\r\n",
      "sample:  rezha, warga kota bandung, noviana, mengatakan noviana telah selesai salat jumat di depan kantor pos besar bandung di jembatan penyeberangan orang itu ---- rezha noviana, warga kota bandung mengatakan ia dan jemaat lainnya langsung memperhatikan megatron jembatan penyeberangan orang depan kantor pos besar bandung setelah bubar salat jumat di masjid raya bandung.\r\n",
      "sample:  petugas linmas dan satpam berapa berdiri di atas jpo ---- ketika itu, petugas linmas dan beberapa satpam berdiri di atas jpo.\r\n",
      "sample:  aksi bunuh diri terjadi di alun-alun bandung belum lama ini ---- aksi bunuh diri di alun - alun bandung belum lama ini terjadi.\r\n",
      "sample:  orang tua itu menjatuhkan diri di jpo di alun kota bandung ---- seorang pria tua nekat menjatuhkan diri dari jpo di alun - alun kota bandung.\r\n",
      "sample:  sudirman yang menjadi saksi mata pembunuhan di alun-alun bandung mengatakan, dirinya adalah anggota linmas kota bandung satpol pp. ---- sudirman, anggota linmas satpol pp kota bandung yang menjadi saksi mata aksi bunuh diri di alun - alun bandung itu mengatakan, pria tersebut diperkirakan berusia 50 tahun.\r\n",
      "sample:  lelaki itu menjatuhkan diri di megatron depan bandung di pos giro besar bandung di jembatan penyeberangan jumat ---- seorang lelaki menjatuhkan diri dari megatron jembatan penyeberangan di depan pos giro besar bandung, bandung, jumat.\r\n",
      "sample:  lelaki tengah baya itu mengakhiri hidupnya di tengah kepadatan lalu lintas di jalan asia afrika ---- seorang lelaki tengah baya nekat mengakhiri hidupnya di tengah kepadatan lalu lintas jalan asia afrika.\r\n",
      "sample:  pria misterius yang bunuh diri di jembatan jalan di bandung, jawa barat, asia afrika di seberang orang itu membuat pesan belum terjun nekat ---- pria misterius yang bunuh diri dari jembatan penyeberangan orang di jalan asia afrika, bandung, jawa barat, membuat pesan sebelum nekat terjun.\r\n",
      "bleu score on test dataset:  26.901951841941415\r\n",
      "evaluate on data g-gempa-dieng\r\n",
      "mkdir: cannot create directory ‘result/g-gempa-dieng’: File exists\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='result/tokenizer', vocab_size=32100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "T5Config {\r\n",
      "  \"_name_or_path\": \"result/model\",\r\n",
      "  \"additional_config\": {\r\n",
      "    \"tree_max\": 512\r\n",
      "  },\r\n",
      "  \"architectures\": [\r\n",
      "    \"T5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"t5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 32109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 19\r\n",
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:04<00:00,  1.17it/s]\r\n",
      "sample:  stasiun banjarnegara, jawa tengah, dalam badan meteorologi klimatologi geofisika menyatakan, gempa berkekuatan 4, 8 skala richter mengguncang dataran tinggi dieng pada pukul 19: 00 wib ---- stasiun geofisika badan meteorologi klimatologi dan geofisika banjarnegara, jawa tengah, menyatakan bahwa gempa yang mengguncang dataran tinggi dieng pukul 19.00 wib berkekuatan 4,8 pada skala richter.\r\n",
      "sample:  pusat gempa diperkirakan berada di desa kecamatan kabupaten batang, tanji gugur ---- pusat gempa diperkirakan berada di desa tanji gugur, kecamatan bawang, kabupaten batang.\r\n",
      "sample:  pvmbg merekomendasikan agar sementara jalan yang berdekatan dengan kawah di desa sumberejo ditutup untuk timbang ---- pvmbg merekomendasikan seluruh jalan yang mendekati kawah timbang di desa sumberejo sementara ditutup.\r\n",
      "sample:  kepala surono di pusat vulkanologi mitigasi bencana geologi mengatakan sebanyak 86 kali rekaman gempa yang terjadi pada pukul 19: 00 wib di dataran tinggi dieng ---- kepala pusat vulkanologi dan mitigasi bencana geologi surono mengatakan bahwa gempa yang terjadi di dataran tinggi dieng pukul 19.00 wib terekam sebanyak 86 kali.\r\n",
      "sample:  penutupan dilakukan hingga tim yang mengukur konsentrasi gas di lapangan menyatakan tidak ada gas berbahaya ---- penutupan ini dilakukan hingga tim di lapangan yang mengukur konsentrasi gas menyatakan tidak ada gas yang berbahaya.\r\n",
      "sample:  pvmbg merekomendasikan agar sementara jalan yang berdekatan dengan kawah di desa sumberejo ditutup untuk timbang ---- pvmbg merekomendasikan seluruh jalan yang mendekati kawah timbang di desa sumberejo sementara ditutup.\r\n",
      "sample:  petugas pusat vulkanologi mitigasi bencana geologi diterjunkan untuk memantau aktivitas kawah timbang dan memberikan informasi ---- petugas pusat vulkanologi dan mitigasi bencana geologi diterjunkan untuk memantau aktivitas kawah timbang dan memberikan informasi.\r\n",
      "sample:  data yang dikeluarkan oleh pusat vulkanologi mitigasi bencana geologi menyebutkan, gempa dirasakan dan telah direkam sebanyak 86 kali pada pukul 19: 00 wib ---- data yang dikeluarkan dari pusat vulkanologi dan mitigasi bencana geologi menyebutkan gempa mulai terasa pukul 19.00 wib dan telah terekam gempa sebanyak 86 kali.\r\n",
      "sample:  pengungsi meninggal di kabupaten banjarnegara pada sabtu pagi ---- pengungsi di kabupaten banjarnegara, pada sabtu pagi mulai meninggalkan pengungsian.\r\n",
      "sample:  stasiun banjarnegara dari badan meteorologi klimatologi geofisika menyatakan, gempa berkekuatan 4, 8 skala richter mengguncang dataran tinggi dieng pada pukul 19: 00 wib ---- stasiun geofisika badan meteorologi klimatologi dan geofisika banjarnegara menyatakan gempa yang mengguncang dataran tinggi dieng pukul 19.00 wib berkekuatan 4,8 skala richter *(sr)*.\r\n",
      "bleu score on test dataset:  32.787791963214\r\n"
     ]
    }
   ],
   "source": [
    "!chmod +x ./evaluate_indoT5_to_all.sh\n",
    "!./evaluate_indoT5_to_all.sh result linearized_penman_with_tree_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8bc38011",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-24T04:58:12.805005Z",
     "iopub.status.busy": "2022-05-24T04:58:12.804257Z",
     "iopub.status.idle": "2022-05-24T05:00:19.179812Z",
     "shell.execute_reply": "2022-05-24T05:00:19.179254Z"
    },
    "papermill": {
     "duration": 173.640236,
     "end_time": "2022-05-24T05:00:19.179971",
     "exception": false,
     "start_time": "2022-05-24T04:57:25.539735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: result/ (stored 0%)\r\n",
      "  adding: result/c-gedung-roboh/ (stored 0%)\r\n",
      "  adding: result/c-gedung-roboh/test_label.txt (deflated 62%)\r\n",
      "  adding: result/c-gedung-roboh/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/c-gedung-roboh/test_generations.txt (deflated 63%)\r\n",
      "  adding: result/g-gempa-dieng/ (stored 0%)\r\n",
      "  adding: result/g-gempa-dieng/test_label.txt (deflated 67%)\r\n",
      "  adding: result/g-gempa-dieng/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/g-gempa-dieng/test_generations.txt (deflated 66%)\r\n",
      "  adding: result/b-salah-darat/ (stored 0%)\r\n",
      "  adding: result/b-salah-darat/test_label.txt (deflated 66%)\r\n",
      "  adding: result/b-salah-darat/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/b-salah-darat/test_generations.txt (deflated 64%)\r\n",
      "  adding: result/result_supervised_task_adaptation/ (stored 0%)\r\n",
      "  adding: result/result_supervised_task_adaptation/test_label.txt (deflated 60%)\r\n",
      "  adding: result/result_supervised_task_adaptation/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/result_supervised_task_adaptation/loss_data.tsv (deflated 5%)\r\n",
      "  adding: result/result_supervised_task_adaptation/model/ (stored 0%)\r\n",
      "  adding: result/result_supervised_task_adaptation/model/config.json (deflated 45%)\r\n",
      "  adding: result/result_supervised_task_adaptation/model/pytorch_model.bin (deflated 9%)\r\n",
      "  adding: result/result_supervised_task_adaptation/tokenizer/ (stored 0%)\r\n",
      "  adding: result/result_supervised_task_adaptation/tokenizer/tokenizer_config.json (deflated 81%)\r\n",
      "  adding: result/result_supervised_task_adaptation/tokenizer/added_tokens.json (deflated 44%)\r\n",
      "  adding: result/result_supervised_task_adaptation/tokenizer/special_tokens_map.json (deflated 82%)\r\n",
      "  adding: result/result_supervised_task_adaptation/tokenizer/spiece.model (deflated 49%)\r\n",
      "  adding: result/result_supervised_task_adaptation/test_generations.txt (deflated 64%)\r\n",
      "  adding: result/test_label.txt (deflated 60%)\r\n",
      "  adding: result/d-indo-fuji/ (stored 0%)\r\n",
      "  adding: result/d-indo-fuji/test_label.txt (deflated 86%)\r\n",
      "  adding: result/d-indo-fuji/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/d-indo-fuji/test_generations.txt (deflated 86%)\r\n",
      "  adding: result/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/amr_simple_test/ (stored 0%)\r\n",
      "  adding: result/amr_simple_test/test_label.txt (deflated 60%)\r\n",
      "  adding: result/amr_simple_test/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/amr_simple_test/test_generations.txt (deflated 63%)\r\n",
      "  adding: result/loss_data.tsv (deflated 19%)\r\n",
      "  adding: result/f-bunuh-diri/ (stored 0%)\r\n",
      "  adding: result/f-bunuh-diri/test_label.txt (deflated 68%)\r\n",
      "  adding: result/f-bunuh-diri/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/f-bunuh-diri/test_generations.txt (deflated 64%)\r\n",
      "  adding: result/model/ (stored 0%)\r\n",
      "  adding: result/model/config.json (deflated 45%)\r\n",
      "  adding: result/model/pytorch_model.bin (deflated 9%)\r\n",
      "  adding: result/tokenizer/ (stored 0%)\r\n",
      "  adding: result/tokenizer/tokenizer_config.json (deflated 81%)\r\n",
      "  adding: result/tokenizer/added_tokens.json (deflated 42%)\r\n",
      "  adding: result/tokenizer/special_tokens_map.json (deflated 83%)\r\n",
      "  adding: result/tokenizer/spiece.model (deflated 49%)\r\n",
      "  adding: result/test_generations.txt (deflated 63%)\r\n"
     ]
    }
   ],
   "source": [
    "!zip -r result_with_sta.zip result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17845.07516,
   "end_time": "2022-05-24T05:01:07.400370",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-05-24T00:03:42.325210",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
