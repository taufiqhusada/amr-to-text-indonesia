{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e2d63e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T10:27:35.023212Z",
     "iopub.status.busy": "2022-06-15T10:27:35.022401Z",
     "iopub.status.idle": "2022-06-15T10:28:06.725570Z",
     "shell.execute_reply": "2022-06-15T10:28:06.724511Z"
    },
    "papermill": {
     "duration": 31.744444,
     "end_time": "2022-06-15T10:28:06.725780",
     "exception": false,
     "start_time": "2022-06-15T10:27:34.981336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.15.0)\r\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (0.1.96)\r\n",
      "Collecting indobenchmark-toolkit==0.0.4\r\n",
      "  Downloading indobenchmark_toolkit-0.0.4-py3-none-any.whl (8.0 kB)\r\n",
      "Collecting sacrebleu\r\n",
      "  Downloading sacrebleu-2.1.0-py3-none-any.whl (92 kB)\r\n",
      "     |████████████████████████████████| 92 kB 1.0 MB/s            \r\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.7.1 in /opt/conda/lib/python3.7/site-packages (from indobenchmark-toolkit==0.0.4) (1.9.1)\r\n",
      "Collecting datasets==1.4.1\r\n",
      "  Downloading datasets-1.4.1-py3-none-any.whl (186 kB)\r\n",
      "     |████████████████████████████████| 186 kB 4.0 MB/s            \r\n",
      "\u001b[?25hCollecting sentencepiece\r\n",
      "  Downloading sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2 MB)\r\n",
      "     |████████████████████████████████| 1.2 MB 10.6 MB/s            \r\n",
      "\u001b[?25hCollecting xxhash\r\n",
      "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\r\n",
      "     |████████████████████████████████| 212 kB 58.5 MB/s            \r\n",
      "\u001b[?25hCollecting huggingface-hub==0.0.2\r\n",
      "  Downloading huggingface_hub-0.0.2-py3-none-any.whl (24 kB)\r\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets==1.4.1->indobenchmark-toolkit==0.0.4) (0.3.4)\r\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets==1.4.1->indobenchmark-toolkit==0.0.4) (0.70.12.2)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets==1.4.1->indobenchmark-toolkit==0.0.4) (1.20.3)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.7/site-packages (from datasets==1.4.1->indobenchmark-toolkit==0.0.4) (2022.2.0)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets==1.4.1->indobenchmark-toolkit==0.0.4) (2.26.0)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets==1.4.1->indobenchmark-toolkit==0.0.4) (4.11.2)\r\n",
      "Requirement already satisfied: pyarrow>=0.17.1 in /opt/conda/lib/python3.7/site-packages (from datasets==1.4.1->indobenchmark-toolkit==0.0.4) (6.0.1)\r\n",
      "Collecting tqdm<4.50.0,>=4.27\r\n",
      "  Downloading tqdm-4.49.0-py2.py3-none-any.whl (69 kB)\r\n",
      "     |████████████████████████████████| 69 kB 6.4 MB/s             \r\n",
      "\u001b[?25hRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets==1.4.1->indobenchmark-toolkit==0.0.4) (1.3.5)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub==0.0.2->datasets==1.4.1->indobenchmark-toolkit==0.0.4) (3.4.2)\r\n",
      "Collecting transformers\r\n",
      "  Downloading transformers-4.19.4-py3-none-any.whl (4.2 MB)\r\n",
      "     |████████████████████████████████| 4.2 MB 59.6 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.19.3-py3-none-any.whl (4.2 MB)\r\n",
      "     |████████████████████████████████| 4.2 MB 47.7 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\r\n",
      "     |████████████████████████████████| 4.2 MB 57.5 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.19.1-py3-none-any.whl (4.2 MB)\r\n",
      "     |████████████████████████████████| 4.2 MB 25.6 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.19.0-py3-none-any.whl (4.2 MB)\r\n",
      "     |████████████████████████████████| 4.2 MB 51.9 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\r\n",
      "     |████████████████████████████████| 4.0 MB 54.1 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\r\n",
      "     |████████████████████████████████| 3.8 MB 50.0 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\r\n",
      "     |████████████████████████████████| 3.5 MB 49.5 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.16.1-py3-none-any.whl (3.5 MB)\r\n",
      "     |████████████████████████████████| 3.5 MB 55.8 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.16.0-py3-none-any.whl (3.5 MB)\r\n",
      "     |████████████████████████████████| 3.5 MB 48.5 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.14.1-py3-none-any.whl (3.4 MB)\r\n",
      "     |████████████████████████████████| 3.4 MB 47.6 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.13.0-py3-none-any.whl (3.3 MB)\r\n",
      "     |████████████████████████████████| 3.3 MB 46.3 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\r\n",
      "     |████████████████████████████████| 3.1 MB 45.1 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.12.4-py3-none-any.whl (3.1 MB)\r\n",
      "     |████████████████████████████████| 3.1 MB 49.7 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.12.3-py3-none-any.whl (3.1 MB)\r\n",
      "     |████████████████████████████████| 3.1 MB 55.1 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.12.2-py3-none-any.whl (3.1 MB)\r\n",
      "     |████████████████████████████████| 3.1 MB 47.0 MB/s            \r\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\r\n",
      "  Downloading transformers-4.12.1-py3-none-any.whl (3.1 MB)\r\n",
      "     |████████████████████████████████| 3.1 MB 31.6 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.12.0-py3-none-any.whl (3.1 MB)\r\n",
      "     |████████████████████████████████| 3.1 MB 45.9 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.11.3-py3-none-any.whl (2.9 MB)\r\n",
      "     |████████████████████████████████| 2.9 MB 54.4 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.11.2-py3-none-any.whl (2.9 MB)\r\n",
      "     |████████████████████████████████| 2.9 MB 50.7 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.11.1-py3-none-any.whl (2.9 MB)\r\n",
      "     |████████████████████████████████| 2.9 MB 54.2 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.11.0-py3-none-any.whl (2.9 MB)\r\n",
      "     |████████████████████████████████| 2.9 MB 50.4 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.10.3-py3-none-any.whl (2.8 MB)\r\n",
      "     |████████████████████████████████| 2.8 MB 55.8 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.10.2-py3-none-any.whl (2.8 MB)\r\n",
      "     |████████████████████████████████| 2.8 MB 24.9 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.10.1-py3-none-any.whl (2.8 MB)\r\n",
      "     |████████████████████████████████| 2.8 MB 30.7 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.10.0-py3-none-any.whl (2.8 MB)\r\n",
      "     |████████████████████████████████| 2.8 MB 53.7 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.9.2-py3-none-any.whl (2.6 MB)\r\n",
      "     |████████████████████████████████| 2.6 MB 46.4 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.9.1-py3-none-any.whl (2.6 MB)\r\n",
      "     |████████████████████████████████| 2.6 MB 42.3 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.9.0-py3-none-any.whl (2.6 MB)\r\n",
      "     |████████████████████████████████| 2.6 MB 48.8 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.8.2-py3-none-any.whl (2.5 MB)\r\n",
      "     |████████████████████████████████| 2.5 MB 43.9 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.8.1-py3-none-any.whl (2.5 MB)\r\n",
      "     |████████████████████████████████| 2.5 MB 55.6 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.8.0-py3-none-any.whl (2.5 MB)\r\n",
      "     |████████████████████████████████| 2.5 MB 56.1 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.7.0-py3-none-any.whl (2.5 MB)\r\n",
      "     |████████████████████████████████| 2.5 MB 46.2 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.6.1-py3-none-any.whl (2.2 MB)\r\n",
      "     |████████████████████████████████| 2.2 MB 43.4 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.6.0-py3-none-any.whl (2.3 MB)\r\n",
      "     |████████████████████████████████| 2.3 MB 47.8 MB/s            \r\n",
      "\u001b[?25h  Downloading transformers-4.5.1-py3-none-any.whl (2.1 MB)\r\n",
      "     |████████████████████████████████| 2.1 MB 56.8 MB/s            \r\n",
      "\u001b[?25hRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.47)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\r\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.3)\r\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.7/site-packages (from sacrebleu) (0.8.9)\r\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.7/site-packages (from sacrebleu) (0.4.4)\r\n",
      "Requirement already satisfied: portalocker in /opt/conda/lib/python3.7/site-packages (from sacrebleu) (2.4.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets==1.4.1->indobenchmark-toolkit==0.0.4) (2021.10.8)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets==1.4.1->indobenchmark-toolkit==0.0.4) (3.1)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets==1.4.1->indobenchmark-toolkit==0.0.4) (2.0.9)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets==1.4.1->indobenchmark-toolkit==0.0.4) (1.26.7)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.7.1->indobenchmark-toolkit==0.0.4) (4.1.1)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets==1.4.1->indobenchmark-toolkit==0.0.4) (3.6.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers) (3.0.6)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.16.0)\r\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.1.0)\r\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (8.0.3)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets==1.4.1->indobenchmark-toolkit==0.0.4) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets==1.4.1->indobenchmark-toolkit==0.0.4) (2021.3)\r\n",
      "Installing collected packages: tqdm, xxhash, huggingface-hub, transformers, sentencepiece, datasets, sacrebleu, indobenchmark-toolkit\r\n",
      "  Attempting uninstall: tqdm\r\n",
      "    Found existing installation: tqdm 4.62.3\r\n",
      "    Uninstalling tqdm-4.62.3:\r\n",
      "      Successfully uninstalled tqdm-4.62.3\r\n",
      "  Attempting uninstall: huggingface-hub\r\n",
      "    Found existing installation: huggingface-hub 0.2.1\r\n",
      "    Uninstalling huggingface-hub-0.2.1:\r\n",
      "      Successfully uninstalled huggingface-hub-0.2.1\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.15.0\r\n",
      "    Uninstalling transformers-4.15.0:\r\n",
      "      Successfully uninstalled transformers-4.15.0\r\n",
      "  Attempting uninstall: sentencepiece\r\n",
      "    Found existing installation: sentencepiece 0.1.96\r\n",
      "    Uninstalling sentencepiece-0.1.96:\r\n",
      "      Successfully uninstalled sentencepiece-0.1.96\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "beatrix-jupyterlab 3.1.6 requires google-cloud-bigquery-storage, which is not installed.\r\n",
      "spacy 3.2.2 requires typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\", but you have typing-extensions 4.1.1 which is incompatible.\r\n",
      "featuretools 1.6.0 requires numpy>=1.21.0, but you have numpy 1.20.3 which is incompatible.\r\n",
      "cached-path 1.0.2 requires huggingface-hub<0.3.0,>=0.0.12, but you have huggingface-hub 0.0.2 which is incompatible.\r\n",
      "cached-path 1.0.2 requires tqdm<4.63,>=4.62, but you have tqdm 4.49.0 which is incompatible.\r\n",
      "allennlp 2.9.0 requires huggingface-hub>=0.0.16, but you have huggingface-hub 0.0.2 which is incompatible.\r\n",
      "allennlp 2.9.0 requires tqdm>=4.62, but you have tqdm 4.49.0 which is incompatible.\u001b[0m\r\n",
      "Successfully installed datasets-1.4.1 huggingface-hub-0.0.2 indobenchmark-toolkit-0.0.4 sacrebleu-2.1.0 sentencepiece-0.1.95 tqdm-4.49.0 transformers-4.5.1 xxhash-3.0.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers sentencepiece indobenchmark-toolkit==0.0.4 sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce4d0e79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T10:28:06.922050Z",
     "iopub.status.busy": "2022-06-15T10:28:06.921337Z",
     "iopub.status.idle": "2022-06-15T10:28:11.381237Z",
     "shell.execute_reply": "2022-06-15T10:28:11.381723Z"
    },
    "papermill": {
     "duration": 4.558177,
     "end_time": "2022-06-15T10:28:11.381874",
     "exception": false,
     "start_time": "2022-06-15T10:28:06.823697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'amr-to-text-indonesia'...\r\n",
      "remote: Enumerating objects: 2341, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (486/486), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (329/329), done.\u001b[K\r\n",
      "remote: Total 2341 (delta 190), reused 315 (delta 97), pack-reused 1855\u001b[K\r\n",
      "Receiving objects: 100% (2341/2341), 22.96 MiB | 16.96 MiB/s, done.\r\n",
      "Resolving deltas: 100% (956/956), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://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@github.com/taufiqhusada/amr-to-text-indonesia.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5f23078",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T10:28:11.590718Z",
     "iopub.status.busy": "2022-06-15T10:28:11.589950Z",
     "iopub.status.idle": "2022-06-15T10:28:23.712466Z",
     "shell.execute_reply": "2022-06-15T10:28:23.711788Z"
    },
    "papermill": {
     "duration": 12.228564,
     "end_time": "2022-06-15T10:28:23.712654",
     "exception": false,
     "start_time": "2022-06-15T10:28:11.484090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'amr-indo-dataset'...\r\n",
      "remote: Enumerating objects: 71, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (5/5), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (5/5), done.\u001b[K\r\n",
      "remote: Total 71 (delta 1), reused 3 (delta 0), pack-reused 66\u001b[K\r\n",
      "Unpacking objects: 100% (71/71), 60.94 MiB | 6.40 MiB/s, done.\r\n",
      "Updating files: 100% (34/34), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://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@github.com/taufiqhusada/amr-indo-dataset.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c6a669",
   "metadata": {
    "papermill": {
     "duration": 0.183751,
     "end_time": "2022-06-15T10:28:24.098152",
     "exception": false,
     "start_time": "2022-06-15T10:28:23.914401",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Finetune mt5 with linearized penman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dd55d88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T10:28:24.508680Z",
     "iopub.status.busy": "2022-06-15T10:28:24.507897Z",
     "iopub.status.idle": "2022-06-15T10:28:24.513569Z",
     "shell.execute_reply": "2022-06-15T10:28:24.514556Z"
    },
    "papermill": {
     "duration": 0.233098,
     "end_time": "2022-06-15T10:28:24.514787",
     "exception": false,
     "start_time": "2022-06-15T10:28:24.281689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/amr-to-text-indonesia/train\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/amr-to-text-indonesia/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ef383b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T10:28:24.781177Z",
     "iopub.status.busy": "2022-06-15T10:28:24.780449Z",
     "iopub.status.idle": "2022-06-15T10:28:25.593707Z",
     "shell.execute_reply": "2022-06-15T10:28:25.594095Z"
    },
    "papermill": {
     "duration": 0.92624,
     "end_time": "2022-06-15T10:28:25.594276",
     "exception": false,
     "start_time": "2022-06-15T10:28:24.668036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Branch 'mt5' set up to track remote branch 'mt5' from 'origin'.\r\n",
      "Switched to a new branch 'mt5'\r\n"
     ]
    }
   ],
   "source": [
    "!git checkout mt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ab196f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T10:28:25.820028Z",
     "iopub.status.busy": "2022-06-15T10:28:25.819311Z",
     "iopub.status.idle": "2022-06-15T10:28:25.821779Z",
     "shell.execute_reply": "2022-06-15T10:28:25.821353Z"
    },
    "papermill": {
     "duration": 0.116805,
     "end_time": "2022-06-15T10:28:25.821885",
     "exception": false,
     "start_time": "2022-06-15T10:28:25.705080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python train_mT5.py --model_type mT5 --n_epochs 13 --lr 0.0001 --data_folder ../data/preprocessed_data/linearized_penman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "794dabe3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T10:28:26.061470Z",
     "iopub.status.busy": "2022-06-15T10:28:26.060709Z",
     "iopub.status.idle": "2022-06-15T10:28:26.063253Z",
     "shell.execute_reply": "2022-06-15T10:28:26.062826Z"
    },
    "papermill": {
     "duration": 0.131447,
     "end_time": "2022-06-15T10:28:26.063372",
     "exception": false,
     "start_time": "2022-06-15T10:28:25.931925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !ls result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b214a4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T10:28:26.291812Z",
     "iopub.status.busy": "2022-06-15T10:28:26.291022Z",
     "iopub.status.idle": "2022-06-15T10:28:26.293512Z",
     "shell.execute_reply": "2022-06-15T10:28:26.293053Z"
    },
    "papermill": {
     "duration": 0.119673,
     "end_time": "2022-06-15T10:28:26.293632",
     "exception": false,
     "start_time": "2022-06-15T10:28:26.173959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df = pd.read_csv('result/loss_data.tsv', sep='\\t')\n",
    "# list_train_loss = df['train_loss'].values\n",
    "# list_val_loss = df['val_loss'].values\n",
    "\n",
    "\n",
    "# # importing package\n",
    "# import matplotlib.pyplot as plt\n",
    "# x = list(range(13))\n",
    "# plt.plot(x, list_train_loss)\n",
    "# plt.plot(x, list_val_loss)\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce3b6211",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T10:28:26.520877Z",
     "iopub.status.busy": "2022-06-15T10:28:26.520052Z",
     "iopub.status.idle": "2022-06-15T10:28:26.522431Z",
     "shell.execute_reply": "2022-06-15T10:28:26.521980Z"
    },
    "papermill": {
     "duration": 0.116872,
     "end_time": "2022-06-15T10:28:26.522541",
     "exception": false,
     "start_time": "2022-06-15T10:28:26.405669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !zip -r result_without_sta.zip result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c8029d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T10:28:26.745810Z",
     "iopub.status.busy": "2022-06-15T10:28:26.745017Z",
     "iopub.status.idle": "2022-06-15T10:28:26.747513Z",
     "shell.execute_reply": "2022-06-15T10:28:26.746987Z"
    },
    "papermill": {
     "duration": 0.115335,
     "end_time": "2022-06-15T10:28:26.747630",
     "exception": false,
     "start_time": "2022-06-15T10:28:26.632295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %cd ../evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b21dbddf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T10:28:26.972057Z",
     "iopub.status.busy": "2022-06-15T10:28:26.971366Z",
     "iopub.status.idle": "2022-06-15T10:28:26.973937Z",
     "shell.execute_reply": "2022-06-15T10:28:26.973513Z"
    },
    "papermill": {
     "duration": 0.117065,
     "end_time": "2022-06-15T10:28:26.974039",
     "exception": false,
     "start_time": "2022-06-15T10:28:26.856974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !chmod +x ./evaluate_mT5_to_all.sh\n",
    "# !mkdir result\n",
    "# !./evaluate_mT5_to_all.sh ../train/result linearized_penman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "848a8656",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T10:28:27.199270Z",
     "iopub.status.busy": "2022-06-15T10:28:27.198459Z",
     "iopub.status.idle": "2022-06-15T10:28:27.200818Z",
     "shell.execute_reply": "2022-06-15T10:28:27.200411Z"
    },
    "papermill": {
     "duration": 0.115542,
     "end_time": "2022-06-15T10:28:27.200924",
     "exception": false,
     "start_time": "2022-06-15T10:28:27.085382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !zip -r result_without_sta.zip result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0865874f",
   "metadata": {
    "papermill": {
     "duration": 0.109905,
     "end_time": "2022-06-15T10:28:27.421797",
     "exception": false,
     "start_time": "2022-06-15T10:28:27.311892",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Finetune mt5 with linearized penman + tree level embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e529d6f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T10:28:27.646694Z",
     "iopub.status.busy": "2022-06-15T10:28:27.645772Z",
     "iopub.status.idle": "2022-06-15T10:28:27.648194Z",
     "shell.execute_reply": "2022-06-15T10:28:27.647678Z"
    },
    "papermill": {
     "duration": 0.116759,
     "end_time": "2022-06-15T10:28:27.648307",
     "exception": false,
     "start_time": "2022-06-15T10:28:27.531548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %cd /kaggle/working/amr-to-text-indonesia/tree_level_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af59cca6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T10:28:27.873344Z",
     "iopub.status.busy": "2022-06-15T10:28:27.872665Z",
     "iopub.status.idle": "2022-06-15T10:28:27.875197Z",
     "shell.execute_reply": "2022-06-15T10:28:27.874754Z"
    },
    "papermill": {
     "duration": 0.117324,
     "end_time": "2022-06-15T10:28:27.875311",
     "exception": false,
     "start_time": "2022-06-15T10:28:27.757987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !mkdir result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0df16df3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T10:28:28.100849Z",
     "iopub.status.busy": "2022-06-15T10:28:28.100118Z",
     "iopub.status.idle": "2022-06-15T10:28:28.103348Z",
     "shell.execute_reply": "2022-06-15T10:28:28.102910Z"
    },
    "papermill": {
     "duration": 0.117677,
     "end_time": "2022-06-15T10:28:28.103460",
     "exception": false,
     "start_time": "2022-06-15T10:28:27.985783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python train_mT5.py --model_type mT5 --n_epochs 13 --lr 0.0001 --data_folder ../data/preprocessed_data/linearized_penman_with_tree_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "451512cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T10:28:28.334363Z",
     "iopub.status.busy": "2022-06-15T10:28:28.332696Z",
     "iopub.status.idle": "2022-06-15T10:28:28.334960Z",
     "shell.execute_reply": "2022-06-15T10:28:28.335410Z"
    },
    "papermill": {
     "duration": 0.119113,
     "end_time": "2022-06-15T10:28:28.335561",
     "exception": false,
     "start_time": "2022-06-15T10:28:28.216448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !chmod +x ./evaluate_mT5_to_all.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "417ef1a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T10:28:28.565711Z",
     "iopub.status.busy": "2022-06-15T10:28:28.564907Z",
     "iopub.status.idle": "2022-06-15T10:28:28.566928Z",
     "shell.execute_reply": "2022-06-15T10:28:28.567350Z"
    },
    "papermill": {
     "duration": 0.119602,
     "end_time": "2022-06-15T10:28:28.567478",
     "exception": false,
     "start_time": "2022-06-15T10:28:28.447876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !./evaluate_mT5_to_all.sh result linearized_penman_with_tree_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5376bf65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T10:28:28.801518Z",
     "iopub.status.busy": "2022-06-15T10:28:28.800725Z",
     "iopub.status.idle": "2022-06-15T10:28:28.803158Z",
     "shell.execute_reply": "2022-06-15T10:28:28.802753Z"
    },
    "papermill": {
     "duration": 0.123505,
     "end_time": "2022-06-15T10:28:28.803300",
     "exception": false,
     "start_time": "2022-06-15T10:28:28.679795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !zip -r result_without_sta.zip result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3fb845",
   "metadata": {
    "papermill": {
     "duration": 0.112046,
     "end_time": "2022-06-15T10:28:29.027573",
     "exception": false,
     "start_time": "2022-06-15T10:28:28.915527",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Finetune mt5 with linearized penman + supervised task adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d4b56a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T10:28:29.260988Z",
     "iopub.status.busy": "2022-06-15T10:28:29.259394Z",
     "iopub.status.idle": "2022-06-15T10:28:29.263248Z",
     "shell.execute_reply": "2022-06-15T10:28:29.262789Z"
    },
    "papermill": {
     "duration": 0.122427,
     "end_time": "2022-06-15T10:28:29.263356",
     "exception": false,
     "start_time": "2022-06-15T10:28:29.140929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/amr-to-text-indonesia/train\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/amr-to-text-indonesia/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e39e9060",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T10:28:29.494661Z",
     "iopub.status.busy": "2022-06-15T10:28:29.493928Z",
     "iopub.status.idle": "2022-06-15T10:28:30.140751Z",
     "shell.execute_reply": "2022-06-15T10:28:30.139908Z"
    },
    "papermill": {
     "duration": 0.763263,
     "end_time": "2022-06-15T10:28:30.140898",
     "exception": false,
     "start_time": "2022-06-15T10:28:29.377635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm result/* -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b2a8783",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T10:28:30.376413Z",
     "iopub.status.busy": "2022-06-15T10:28:30.375682Z",
     "iopub.status.idle": "2022-06-15T13:21:39.841378Z",
     "shell.execute_reply": "2022-06-15T13:21:39.840874Z"
    },
    "papermill": {
     "duration": 10389.587,
     "end_time": "2022-06-15T13:21:39.841519",
     "exception": false,
     "start_time": "2022-06-15T10:28:30.254519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing method linearized_penman\r\n",
      "silver data folder ../amr-indo-dataset/data_154k_raw_silver_amr_indo4b_news\r\n",
      "Namespace(mode='linearized_penman', result_amr_path='data/preprocessed_silver_data/train.amr.txt', result_sent_path='data/preprocessed_silver_data/train.sent.txt', source_file_path=None, source_folder_path='../amr-indo-dataset/data_154k_raw_silver_amr_indo4b_news')\r\n",
      "100%|███████████████████████████████| 268572/268572 [00:01<00:00, 144281.81it/s]\r\n",
      "100%|███████████████████████████████| 265325/265325 [00:01<00:00, 145125.33it/s]\r\n",
      "100%|███████████████████████████████| 263263/263263 [00:01<00:00, 150213.44it/s]\r\n",
      "100%|███████████████████████████████| 264253/264253 [00:01<00:00, 150119.69it/s]\r\n",
      "100%|███████████████████████████████| 263508/263508 [00:01<00:00, 149753.99it/s]\r\n",
      "100%|███████████████████████████████| 264330/264330 [00:02<00:00, 130677.04it/s]\r\n",
      "100%|███████████████████████████████| 266966/266966 [00:01<00:00, 147194.99it/s]\r\n",
      "100%|███████████████████████████████| 269258/269258 [00:01<00:00, 145429.33it/s]\r\n",
      "100%|███████████████████████████████| 268262/268262 [00:01<00:00, 148358.23it/s]\r\n",
      "100%|███████████████████████████████| 270251/270251 [00:01<00:00, 146600.02it/s]\r\n",
      "total: 154892 pair sent-amr\r\n",
      "Running on the GPU\r\n",
      "Downloading: 100%|█████████████████████████| 4.31M/4.31M [00:00<00:00, 8.35MB/s]\r\n",
      "Downloading: 100%|███████████████████████████| 65.0/65.0 [00:00<00:00, 64.8kB/s]\r\n",
      "Downloading: 100%|██████████████████████████████| 376/376 [00:00<00:00, 381kB/s]\r\n",
      "Downloading: 100%|██████████████████████████████| 702/702 [00:00<00:00, 383kB/s]\r\n",
      "Downloading: 100%|█████████████████████████| 2.33G/2.33G [01:38<00:00, 23.7MB/s]\r\n",
      "added 9 tokens\r\n",
      "len train dataset:  154892\r\n",
      "len dev dataset:  19\r\n",
      "len test dataset: 306\r\n",
      "len train dataloader:  38723\r\n",
      "(Epoch 1) TRAIN LOSS:1.5013 LR:0.00010000: 100%|█| 38723/38723 [2:49:47<00:00,  \r\n",
      "(Epoch 1) DEV LOSS:2.4479 LR:0.00010000: 100%|████| 5/5 [00:00<00:00, 23.69it/s]\r\n",
      "bleu score on dev:  15.564449152910045\r\n",
      "  0%|                                                    | 0/77 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|███████████████████████████████████████████| 77/77 [00:36<00:00,  2.11it/s]\r\n",
      "sample:  ilham meniupkan balon. ---- balon itu ditiup ilham\r\n",
      "sample:  obe bertuliskan puisi. ---- obe menulis puisi\r\n",
      "sample:  saya ketik makalah. ---- saya mengetik makalah\r\n",
      "sample:  angga anak ajaib. ---- angga anak ajaib\r\n",
      "sample:  ibunya orang dosen. ---- ibuku seorang dosen\r\n",
      "bleu score on test dataset:  31.07534849875195\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"train_mT5.py\", line 281, in <module>\r\n",
      "    print(generate(\"( ketik :ARG0 ( saya ) :ARG1 ( makalah ) ) )\", model, tokenizer, num_beams, model_type, 'cpu'))    \r\n",
      "  File \"../utils/eval.py\", line 10, in generate\r\n",
      "    raise ValueError(f'Unknown model_type `{model_type}`')\r\n",
      "ValueError: Unknown model_type `mT5`\r\n"
     ]
    }
   ],
   "source": [
    "!chmod +x train_mT5_on_silver_data.sh\n",
    "!./train_mT5_on_silver_data.sh linearized_penman ../amr-indo-dataset/data_154k_raw_silver_amr_indo4b_news 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87b73b01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T13:22:27.983898Z",
     "iopub.status.busy": "2022-06-15T13:22:27.983270Z",
     "iopub.status.idle": "2022-06-15T13:22:27.986416Z",
     "shell.execute_reply": "2022-06-15T13:22:27.986817Z"
    },
    "papermill": {
     "duration": 23.482832,
     "end_time": "2022-06-15T13:22:27.986958",
     "exception": false,
     "start_time": "2022-06-15T13:22:04.504126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "441"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc5c659d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T13:23:16.401826Z",
     "iopub.status.busy": "2022-06-15T13:23:16.396410Z",
     "iopub.status.idle": "2022-06-15T13:23:17.056863Z",
     "shell.execute_reply": "2022-06-15T13:23:17.056028Z"
    },
    "papermill": {
     "duration": 25.03014,
     "end_time": "2022-06-15T13:23:17.057004",
     "exception": false,
     "start_time": "2022-06-15T13:22:52.026864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu_score_test.txt  model\t\t   test_label.txt\r\n",
      "loss_data.tsv\t     test_generations.txt  tokenizer\r\n"
     ]
    }
   ],
   "source": [
    "!ls result/result_supervised_task_adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6514fcb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T13:24:04.442352Z",
     "iopub.status.busy": "2022-06-15T13:24:04.438491Z",
     "iopub.status.idle": "2022-06-15T13:24:05.086560Z",
     "shell.execute_reply": "2022-06-15T13:24:05.086070Z"
    },
    "papermill": {
     "duration": 24.021964,
     "end_time": "2022-06-15T13:24:05.086689",
     "exception": false,
     "start_time": "2022-06-15T13:23:41.064725",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir result/result_linearized_penman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "159941db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T13:24:53.105048Z",
     "iopub.status.busy": "2022-06-15T13:24:53.104302Z",
     "iopub.status.idle": "2022-06-15T13:30:19.126305Z",
     "shell.execute_reply": "2022-06-15T13:30:19.125458Z"
    },
    "papermill": {
     "duration": 350.182373,
     "end_time": "2022-06-15T13:30:19.126531",
     "exception": false,
     "start_time": "2022-06-15T13:24:28.944158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\r\n",
      "resume from checkpoint\r\n",
      "added 0 tokens\r\n",
      "len train dataset:  2648\r\n",
      "len dev dataset:  19\r\n",
      "len test dataset: 306\r\n",
      "len train dataloader:  662\r\n",
      "(Epoch 1) TRAIN LOSS:0.8245 LR:0.00010000: 100%|█| 662/662 [02:09<00:00,  5.11it\r\n",
      "(Epoch 1) DEV LOSS:0.9725 LR:0.00010000: 100%|████| 5/5 [00:00<00:00, 21.96it/s]\r\n",
      "bleu score on dev:  26.588074903708403\r\n",
      "(Epoch 2) TRAIN LOSS:0.4809 LR:0.00010000: 100%|█| 662/662 [02:13<00:00,  4.96it\r\n",
      "(Epoch 2) DEV LOSS:1.0558 LR:0.00010000: 100%|████| 5/5 [00:00<00:00, 20.19it/s]\r\n",
      "bleu score on dev:  24.33569919200407\r\n",
      "  0%|                                                    | 0/77 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|███████████████████████████████████████████| 77/77 [00:33<00:00,  2.33it/s]\r\n",
      "sample:  balon ditiupkan ilham ---- balon itu ditiup ilham\r\n",
      "sample:  puisi ditulis obe ---- obe menulis puisi\r\n",
      "sample:  saya mengetik makalah ---- saya mengetik makalah\r\n",
      "sample:  angga anak ajaib ---- angga anak ajaib\r\n",
      "sample:  ibu seorang dosen ---- ibuku seorang dosen\r\n",
      "bleu score on test dataset:  38.79592296609578\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"train_mT5.py\", line 281, in <module>\r\n",
      "    print(generate(\"( ketik :ARG0 ( saya ) :ARG1 ( makalah ) ) )\", model, tokenizer, num_beams, model_type, 'cpu'))    \r\n",
      "  File \"../utils/eval.py\", line 10, in generate\r\n",
      "    raise ValueError(f'Unknown model_type `{model_type}`')\r\n",
      "ValueError: Unknown model_type `mT5`\r\n"
     ]
    }
   ],
   "source": [
    "!python train_mT5.py --model_type mT5 --n_epochs 2 --lr 0.0001 --data_folder ../data/preprocessed_data/linearized_penman  --result_folder result/result_linearized_penman --resume_from_checkpoint True --saved_model_folder_path result/result_supervised_task_adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb7e1cd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T13:31:09.016091Z",
     "iopub.status.busy": "2022-06-15T13:31:09.015504Z",
     "iopub.status.idle": "2022-06-15T13:31:09.020457Z",
     "shell.execute_reply": "2022-06-15T13:31:09.019906Z"
    },
    "papermill": {
     "duration": 24.831678,
     "end_time": "2022-06-15T13:31:09.020583",
     "exception": false,
     "start_time": "2022-06-15T13:30:44.188905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52ad9f38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T13:31:58.547758Z",
     "iopub.status.busy": "2022-06-15T13:31:58.546961Z",
     "iopub.status.idle": "2022-06-15T13:36:31.534557Z",
     "shell.execute_reply": "2022-06-15T13:36:31.533988Z"
    },
    "papermill": {
     "duration": 297.681539,
     "end_time": "2022-06-15T13:36:31.534683",
     "exception": false,
     "start_time": "2022-06-15T13:31:33.853144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: result/result_linearized_penman/ (stored 0%)\r\n",
      "  adding: result/result_linearized_penman/loss_data.tsv (deflated 20%)\r\n",
      "  adding: result/result_linearized_penman/test_label.txt (deflated 60%)\r\n",
      "  adding: result/result_linearized_penman/model/ (stored 0%)\r\n",
      "  adding: result/result_linearized_penman/model/config.json (deflated 45%)\r\n",
      "  adding: result/result_linearized_penman/model/pytorch_model.bin (deflated 20%)\r\n",
      "  adding: result/result_linearized_penman/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/result_linearized_penman/test_generations.txt (deflated 62%)\r\n",
      "  adding: result/result_linearized_penman/tokenizer/ (stored 0%)\r\n",
      "  adding: result/result_linearized_penman/tokenizer/spiece.model (deflated 46%)\r\n",
      "  adding: result/result_linearized_penman/tokenizer/tokenizer_config.json (deflated 34%)\r\n",
      "  adding: result/result_linearized_penman/tokenizer/special_tokens_map.json (deflated 56%)\r\n",
      "  adding: result/result_linearized_penman/tokenizer/added_tokens.json (deflated 45%)\r\n"
     ]
    }
   ],
   "source": [
    "!zip -r result_with_sta.zip result/result_linearized_penman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "042a66a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T13:37:21.751129Z",
     "iopub.status.busy": "2022-06-15T13:37:21.748463Z",
     "iopub.status.idle": "2022-06-15T13:37:21.755340Z",
     "shell.execute_reply": "2022-06-15T13:37:21.756088Z"
    },
    "papermill": {
     "duration": 25.244816,
     "end_time": "2022-06-15T13:37:21.756299",
     "exception": false,
     "start_time": "2022-06-15T13:36:56.511483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/amr-to-text-indonesia/evaluate\n"
     ]
    }
   ],
   "source": [
    "%cd ../evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "334e4b8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T13:38:12.543920Z",
     "iopub.status.busy": "2022-06-15T13:38:12.543139Z",
     "iopub.status.idle": "2022-06-15T13:38:13.192110Z",
     "shell.execute_reply": "2022-06-15T13:38:13.191622Z"
    },
    "papermill": {
     "duration": 26.061942,
     "end_time": "2022-06-15T13:38:13.192267",
     "exception": false,
     "start_time": "2022-06-15T13:37:47.130325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm result/* -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "870f0e3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T13:39:03.640209Z",
     "iopub.status.busy": "2022-06-15T13:39:03.639426Z",
     "iopub.status.idle": "2022-06-15T13:42:35.313728Z",
     "shell.execute_reply": "2022-06-15T13:42:35.313193Z"
    },
    "papermill": {
     "duration": 236.926635,
     "end_time": "2022-06-15T13:42:35.313866",
     "exception": false,
     "start_time": "2022-06-15T13:38:38.387231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model folder ../train/result/result_linearized_penman\r\n",
      "preprocessing method linearized_penman\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data’: File exists\r\n",
      "preprocess amr_simple_test\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/amr_simple_test’: File exists\r\n",
      "Namespace(mode='linearized_penman', result_amr_path='data/test/preprocessed_data/amr_simple_test/test.amr.txt', result_sent_path='data/test/preprocessed_data/amr_simple_test/test.sent.txt', source_file_path='data/test/amr_simple_test.txt', source_folder_path=None)\r\n",
      "100%|███████████████████████████████████| 2618/2618 [00:00<00:00, 176127.80it/s]\r\n",
      "total: 306 pair sent-amr\r\n",
      "preprocess b-salah-darat\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/b-salah-darat’: File exists\r\n",
      "Namespace(mode='linearized_penman', result_amr_path='data/test/preprocessed_data/b-salah-darat/test.amr.txt', result_sent_path='data/test/preprocessed_data/b-salah-darat/test.sent.txt', source_file_path='data/test/b-salah-darat.txt', source_folder_path=None)\r\n",
      "100%|█████████████████████████████████████| 676/676 [00:00<00:00, 129930.78it/s]\r\n",
      "total: 32 pair sent-amr\r\n",
      "preprocess c-gedung-roboh\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/c-gedung-roboh’: File exists\r\n",
      "Namespace(mode='linearized_penman', result_amr_path='data/test/preprocessed_data/c-gedung-roboh/test.amr.txt', result_sent_path='data/test/preprocessed_data/c-gedung-roboh/test.sent.txt', source_file_path='data/test/c-gedung-roboh.txt', source_folder_path=None)\r\n",
      "100%|█████████████████████████████████████| 606/606 [00:00<00:00, 114312.94it/s]\r\n",
      "total: 29 pair sent-amr\r\n",
      "preprocess d-indo-fuji\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/d-indo-fuji’: File exists\r\n",
      "Namespace(mode='linearized_penman', result_amr_path='data/test/preprocessed_data/d-indo-fuji/test.amr.txt', result_sent_path='data/test/preprocessed_data/d-indo-fuji/test.sent.txt', source_file_path='data/test/d-indo-fuji.txt', source_folder_path=None)\r\n",
      "100%|█████████████████████████████████████| 745/745 [00:00<00:00, 127426.66it/s]\r\n",
      "total: 27 pair sent-amr\r\n",
      "preprocess f-bunuh-diri\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/f-bunuh-diri’: File exists\r\n",
      "Namespace(mode='linearized_penman', result_amr_path='data/test/preprocessed_data/f-bunuh-diri/test.amr.txt', result_sent_path='data/test/preprocessed_data/f-bunuh-diri/test.sent.txt', source_file_path='data/test/f-bunuh-diri.txt', source_folder_path=None)\r\n",
      "100%|█████████████████████████████████████| 468/468 [00:00<00:00, 128321.52it/s]\r\n",
      "total: 23 pair sent-amr\r\n",
      "preprocess g-gempa-dieng\r\n",
      "mkdir: cannot create directory ‘data/test/preprocessed_data/g-gempa-dieng’: File exists\r\n",
      "Namespace(mode='linearized_penman', result_amr_path='data/test/preprocessed_data/g-gempa-dieng/test.amr.txt', result_sent_path='data/test/preprocessed_data/g-gempa-dieng/test.sent.txt', source_file_path='data/test/g-gempa-dieng.txt', source_folder_path=None)\r\n",
      "100%|█████████████████████████████████████| 412/412 [00:00<00:00, 130734.85it/s]\r\n",
      "total: 19 pair sent-amr\r\n",
      "evaluate on data amr_simple_test\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='../train/result/result_linearized_penman/tokenizer', vocab_size=250100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': [':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "MT5Config {\r\n",
      "  \"_name_or_path\": \"../train/result/result_linearized_penman/model\",\r\n",
      "  \"architectures\": [\r\n",
      "    \"MT5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"mt5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"tokenizer_class\": \"T5Tokenizer\",\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 250109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 306\r\n",
      "  0%|                                                    | 0/77 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|███████████████████████████████████████████| 77/77 [00:33<00:00,  2.33it/s]\r\n",
      "sample:  balon ditiupkan ilham ---- balon itu ditiup ilham\r\n",
      "sample:  puisi ditulis obe ---- obe menulis puisi\r\n",
      "sample:  saya mengetik makalah ---- saya mengetik makalah\r\n",
      "sample:  angga anak ajaib ---- angga anak ajaib\r\n",
      "sample:  ibu seorang dosen ---- ibuku seorang dosen\r\n",
      "sample:  dia berenang ---- dia sedang berenang\r\n",
      "sample:  buku yang ilham cari ---- ilham sedang mencari bukunya yang hilang\r\n",
      "sample:  di halaman rumah, ibu menyapu ---- ibu sedang menyapu halaman rumah\r\n",
      "sample:  padi dibajak ayah ke sawah ---- ayah sedang membajak padi di sawah\r\n",
      "sample:  di tepi pantai, andi pergi kemah ---- andi pergi berkemah di tepi pantai\r\n",
      "bleu score on test dataset:  38.79592296609578\r\n",
      "evaluate on data b-salah-darat\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='../train/result/result_linearized_penman/tokenizer', vocab_size=250100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': [':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "MT5Config {\r\n",
      "  \"_name_or_path\": \"../train/result/result_linearized_penman/model\",\r\n",
      "  \"architectures\": [\r\n",
      "    \"MT5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"mt5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"tokenizer_class\": \"T5Tokenizer\",\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 250109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 32\r\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:13<00:00,  1.65s/it]\r\n",
      "sample:  kantor kantor sama dan pt angkasa pura ii otoritas bandara soekarno-hatta dari imigrasi bandara soekarno-hatta membahas insiden penumpang terbang pesawat yang tiba dari jakarta pada 10 mei 2016 di lion air jt 161 ---- kantor imigrasi bandara soekarno-hatta bersama kantor otoritas bandara soekarno-hatta dan pt angkasa pura ii membahas insiden penumpang penerbangan pesawat lion air jt 161 yang tiba di jakarta dari singapura 10 mei 2016.\r\n",
      "sample:  kepala kantor imigrasi soekarno-hatta alif suadi mengujarkan bahwa kami meeting soal kepada tempo pada sabtu malam ini 14/ mei 2016 ---- kami meeting soal ini,\" ujar kepala kantor imigrasi soekarno-hatta alif suadi kepada tempo, sabtu malam ini, 14 mei 2016.\r\n",
      "sample:  anak temannya natalie berangkat dan menggunakan pesawat lion air jt 161 pukul 18-55 ke singapura ---- anak temannya natalie berangkat dari singapura dan menggunakan pesawat lion air jt 161, pada pukul 18.50.\r\n",
      "sample:  sekretaris agus haryadi dari perusahaan angkasa pura ii mengatakan, perlakuan yang dikelola bandara internasional soekarno-hatta akan dikoordinasikan oleh kantor otoritas bandara wilayah 1 kaitan perisitiwa ---- sekretaris perusahaan pt angkasa pura ii agus haryadi mengatakan selaku pengelola bandara internasional soekarno-hatta, pihaknya akan berkoordinasi dengan kantor otoritas bandara wilayah i terkait dengan peristiwa ini.\r\n",
      "sample:  pesawat parkir di remote area, kami menyiapkan bus yang mengantar penumpang ke terminal ---- setiap pesawat yang parkir di remote area sudah kami siapkan bus untuk mengantar penumpang ke terminal.\r\n",
      "sample:  edward ujar mendapat sopir yang menjemput penumpang dari padang dari bus ---- terdapat sopir bus yang akan menjemput penumpang dari padang\" ujar edward.\r\n",
      "sample:  pihak otoritas bandara soetta memanggil semua pihak terkait dan yang melakukan investigasi ---- pihak otoritas bandara soetta akan memanggil pihak terkait dan dilakukan investigasi.\r\n",
      "sample:  ujar kemenhub memberikan sanksi kepada pihak-pihak yang lalai ---- kemenhub memberikan sanksi kepada pihak-pihak yang lalai,\" ujarnya.\r\n",
      "sample:  zara berkata mengutip cerita temannya bahwa pesawat itu tidak mendarat di terminal ii ---- pesawat itu mendarat tidak di terminal ii, kata zara mengutip cerita temannya.\r\n",
      "sample:  pesawat parkir di remote area, kami menyiapkan bus yang mengantar penumpang ke terminal ---- setiap pesawat yang parkir di remote area sudah kami siapkan bus untuk mengantar penumpang ke terminal.\r\n",
      "bleu score on test dataset:  26.05691681020793\r\n",
      "evaluate on data c-gedung-roboh\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='../train/result/result_linearized_penman/tokenizer', vocab_size=250100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': [':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "MT5Config {\r\n",
      "  \"_name_or_path\": \"../train/result/result_linearized_penman/model\",\r\n",
      "  \"architectures\": [\r\n",
      "    \"MT5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"mt5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"tokenizer_class\": \"T5Tokenizer\",\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 250109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 29\r\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:11<00:00,  1.41s/it]\r\n",
      "sample:  peralihan itu dilakukan kendaraan laju dari arah mal bintaro xchange dan tol bintaro menuju jalan boulevard bintaro dengan menggunakan flyover di atas lampu indomobil ---- pengalihan dilakukan bagi pengendara yang melaju dari arah mal bintaro xchange dan tol bintaro menuju jalan boulevard bintaro dengan menggunakan flyover di atas lampu merah indomobil.\r\n",
      "sample:  gagal dan menyalahi tes tanah menjadi gedung miring di menara jalan jakarta timur mt saidah ---- kegagalan struktur dan kesalahan tes tanah yang mengakibatkan gedung miring juga terjadi pada menara saidah di jalan mt haryono, jakarta timur.\r\n",
      "sample:  kapolres ayi supardan dari akbp di tangerang selatan membenarkan peristiwa di bintaro yang roboh gedung menarik hati masyarakat banyak ---- kapolres tangerang selatan, akbp ayi supardan membenarkan peristiwa robohnya gedung di bintaro yang menarik perhatian masyarakat banyak.\r\n",
      "sample:  panin memutuskan untuk melanjutkan pembangunan gedung karena dinyatakan tidak lulus ujian layak ---- panin memutuskan tidak melanjutkan pembangunan gedung itu karena dinyatakan tidak lulus uji kelayakan.\r\n",
      "sample:  gedung yang disebut menyatakan tidak lulus ujian sehingga gedung tersebut diputuskan tidak lanjut ---- gedung tersebut dinyatakan tidak lulus uji sehingga pembangunan gedung diputuskan tidak dilanjutkan.\r\n",
      "sample:  kasat akp samian dari polres tangerang selatan kepada reskrim mengatakan, penyelidikan dilakukan pihaknya saat ini ---- kasat reskrim polres tangerangg selatan, akp samian mengatakan saat ini pihaknya melakukan penyelidikan untuk mengetahui penyebab runtuhnya gedung.\r\n",
      "sample:  hingga ini, kami mendalam peristiwa yang disebut ---- hingga kini kami masih mendalami peristiwa tersebut.\r\n",
      "sample:  disebutkan, tidak semua kejadian menimbulkan korban ---- kejadian tersebut tidak timbul korban.\r\n",
      "sample:  kerugian material terjadi ---- terjadi kerugian material.\r\n",
      "sample:  di sektor bintaro tangerang selatan, 7 gedung diduga menyalahi prosedur ---- pembongkaran gedung di sektor 7, bintaro, tangerang selatan, diduga menyalahi prosedur.\r\n",
      "bleu score on test dataset:  21.949629924662855\r\n",
      "evaluate on data d-indo-fuji\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='../train/result/result_linearized_penman/tokenizer', vocab_size=250100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': [':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "MT5Config {\r\n",
      "  \"_name_or_path\": \"../train/result/result_linearized_penman/model\",\r\n",
      "  \"architectures\": [\r\n",
      "    \"MT5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"mt5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"tokenizer_class\": \"T5Tokenizer\",\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 250109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 27\r\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:10<00:00,  1.55s/it]\r\n",
      "sample:  sama dengan fujitsu indonesia, indosat ooredoo menandatangani nota kesepahaman di dalam rangka memantapkan mitra pembangunan yang telah yang melanggar bisnis di dalam menghadirkan solusi smart and internet of things ---- indosat ooredoo bersama fujitsu indonesia menandatangani nota kesepahaman dalam rangka memantapkan kemitraan dengan para pelanggan bisnis yang telah dibangun dalam menghadirkan solusi smart mobility dan internet of things.\r\n",
      "sample:  sama dengan fujitsu indonesia, indosat ooredoo menandatangani nota kesepahaman di dalam rangka memantapkan mitra pembangunan yang telah yang melanggar bisnis di dalam menghadirkan solusi smart and internet of things ---- indosat ooredoo bersama fujitsu indonesia menandatangani nota kesepahaman dalam rangka memantapkan kemitraan dengan para pelanggan bisnis yang telah dibangun dalam menghadirkan solusi smart mobility dan internet of things.\r\n",
      "sample:  mobil mobility dan iot mengalami perkembangan yang cukup signifikan hingga perubahan cara usaha kelola aset ---- smart mobility dan iot mengalami perkembangan cukup signifikan sehingga mengubah cara perusahaan dalam mengelola aset.\r\n",
      "sample:  sama dengan fujitsu indonesia, indosat ooredoo menandatangani nota kesepahaman di dalam rangka memantapkan mitra pembangunan yang telah yang melanggar bisnis di dalam menghadirkan solusi smart and internet of things ---- indosat ooredoo bersama fujitsu indonesia menandatangani nota kesepahaman dalam rangka memantapkan kemitraan dengan para pelanggan bisnis yang telah menghadirkan solusi smart mobility dan internet of things.\r\n",
      "sample:  kerja sama tersebut memfokuskan sektor transportasi dan otomotif yang luas untuk memenuhi kebutuhan para pelanggaran korporasi di indonesia dan sektor industri bagai ---- kerja sama ini akan berfokus pada sektor otomotif dan transportasi dan akan diperluas ke berbagai sektor industri untuk memenuhi kebutuhan pelanggan korporasi di indonesia.\r\n",
      "sample:  presiden achmad sofwan dari director fujitsu indonesia menuturkan bersedia memanfaatkan layanan dan data realtime dalam aplikasi dan mobilitas menggunakan cara mengoptimalkan strategi usaha ---- mobilitas akan menyediakan cara untuk mengoptimalkan strategi perusahaan dengan memanfaatkan aplikasi dan layanan yang dapat memproses data real-time, tutur achmad sofwan, president director fujitsu indonesia.\r\n",
      "sample:  kerja sama tersebut memfokuskan sektor transportasi dan otomotif yang luas untuk memenuhi kebutuhan para pelanggaran korporasi di indonesia dan sektor industri bagai ---- kerja sama ini akan berfokus pada sektor otomotif dan transportasi dan akan diperluas ke berbagai sektor industri untuk memenuhi kebutuhan pelanggan korporasi di indonesia.\r\n",
      "sample:  indosat ooredoo bekerja sama dengan fujitsu indonesia ---- indosat ooredoo bekerja sama dengan fujitsu indonesia menghadirkan solusi smart mobility dan internet of things.\r\n",
      "sample:  presiden achmad sofwan kepada director fujitsu mengungkapkan bersedia memanfaatkan layanan dan memproses data realtime dan aplikasi tersebut mobilitasnya dimanfaatkan dengan cara mengoptimalkan strategi usaha ---- president director fujitsu, achmad sofwan mengungkap, mobilitas akan menyediakan cara mengoptimalisasikan strategi perusahaan dengan memanfaatkan aplikasi dan layanan dalam aktivitas memproses data real-time.\r\n",
      "sample:  kerja sama tersebut memfokuskan sektor transportasi dan otomotif yang luas untuk memenuhi kebutuhan para pelanggaran korporasi di indonesia dan sektor industri bagai ---- kerja sama ini akan berfokus pada sektor otomotif dan transportasi dan akan diperluas ke berbagai sektor industri untuk memenuhi kebutuhan pelanggan korporasi di indonesia.\r\n",
      "bleu score on test dataset:  13.131758284211722\r\n",
      "evaluate on data f-bunuh-diri\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='../train/result/result_linearized_penman/tokenizer', vocab_size=250100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': [':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "MT5Config {\r\n",
      "  \"_name_or_path\": \"../train/result/result_linearized_penman/model\",\r\n",
      "  \"architectures\": [\r\n",
      "    \"MT5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"mt5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"tokenizer_class\": \"T5Tokenizer\",\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 250109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 23\r\n",
      "  0%|                                                     | 0/6 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:09<00:00,  1.52s/it]\r\n",
      "sample:  ciptadi melompat ke megatron jembatan yang tingginya diperkirakan mencapai 15 meter ---- ciptadi dengan nekat melompat dari megatron jembatan penyeberangan orang yang tingginya diperkirakan mencapai 15 meter.\r\n",
      "sample:  hal yang disebut diungkapkan oleh kasubag reny marthaliana humas kompol didampingi kabag dede rojudin kompol ops polrestabes bandung pada jumat di mapolrestabes bandung ---- hal tersebut diungkapkan kabag ops polrestabes bandung kompol dede rojudin didampingi kasubag humas kompol reny marthaliana, saat ditemui di mapolrestabes bandung, jumat.\r\n",
      "sample:  rezha, warga kota bandung noviana, mengatakan bahwa telah membubarkan salat jumat di depan masjid raya bandung, ia dan jemaat lainnya memperhatikan megatron di depan jembatan seberang orang ---- rezha noviana, warga kota bandung mengatakan ia dan jemaat lainnya langsung memperhatikan megatron jembatan penyeberangan orang depan kantor pos besar bandung setelah bubar salat jumat di masjid raya bandung.\r\n",
      "sample:  di atas jpo, petugas linmas berdiri dan berapa satpam ---- ketika itu, petugas linmas dan beberapa satpam berdiri di atas jpo.\r\n",
      "sample:  aksi pembunuh diri terjadi di alun bandung di alun belum lama ---- aksi bunuh diri di alun - alun bandung belum lama ini terjadi.\r\n",
      "sample:  orang tua menjatuhkan diri di jpo di alun kota bandung di alun ---- seorang pria tua nekat menjatuhkan diri dari jpo di alun - alun kota bandung.\r\n",
      "sample:  sudirman yang menjadi saksi mata pembunuh di alun bandung oleh satpol pp mengatakan bahwa pria yang disebutnya diperkirakan 30 tahun ---- sudirman, anggota linmas satpol pp kota bandung yang menjadi saksi mata aksi bunuh diri di alun - alun bandung itu mengatakan, pria tersebut diperkirakan berusia 50 tahun.\r\n",
      "sample:  lelaki orang menjatuhkan diri di megatron di depan bandung di pos giro besar bandung di jembatan seberang jumat ---- seorang lelaki menjatuhkan diri dari megatron jembatan penyeberangan di depan pos giro besar bandung, bandung, jumat.\r\n",
      "sample:  lelaki tengah baya mengakhiri hidupnya di tengah lalu lintas di jalan asia afrika ---- seorang lelaki tengah baya nekat mengakhiri hidupnya di tengah kepadatan lalu lintas jalan asia afrika.\r\n",
      "sample:  pria misterius yang membunuh diri di jembatan jalanan bandung jawa barat di asia afrika di seberang orang membuat pesanan belum nekat terjun ---- pria misterius yang bunuh diri dari jembatan penyeberangan orang di jalan asia afrika, bandung, jawa barat, membuat pesan sebelum nekat terjun.\r\n",
      "bleu score on test dataset:  21.252430416743167\r\n",
      "evaluate on data g-gempa-dieng\r\n",
      "Running on the GPU\r\n",
      "PreTrainedTokenizerFast(name_or_path='../train/result/result_linearized_penman/tokenizer', vocab_size=250100, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': [':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root', ':arg0', ':arg1', ':mod', ':time', ':name', ':location', ':op1', ':op2', ':root']})\r\n",
      "MT5Config {\r\n",
      "  \"_name_or_path\": \"../train/result/result_linearized_penman/model\",\r\n",
      "  \"architectures\": [\r\n",
      "    \"MT5ForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"d_ff\": 2048,\r\n",
      "  \"d_kv\": 64,\r\n",
      "  \"d_model\": 768,\r\n",
      "  \"decoder_start_token_id\": 0,\r\n",
      "  \"dropout_rate\": 0.1,\r\n",
      "  \"eos_token_id\": 1,\r\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\r\n",
      "  \"initializer_factor\": 1.0,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"layer_norm_epsilon\": 1e-06,\r\n",
      "  \"model_type\": \"mt5\",\r\n",
      "  \"num_decoder_layers\": 12,\r\n",
      "  \"num_heads\": 12,\r\n",
      "  \"num_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 0,\r\n",
      "  \"relative_attention_num_buckets\": 32,\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"tokenizer_class\": \"T5Tokenizer\",\r\n",
      "  \"transformers_version\": \"4.5.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 250109\r\n",
      "}\r\n",
      "\r\n",
      "len test dataset: 19\r\n",
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\r\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /usr/local/src/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)\r\n",
      "  return torch.floor_divide(self, other)\r\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:08<00:00,  1.72s/it]\r\n",
      "sample:  stasiun banjarnegara jawa tengah dari badan meteorologi klimatologi geofisika (geofisika) menyatakan geofisika gempa berkekuatan 4 8 skala richter mengguncang dataran tinggi dieng pada pukul 19 00 wib ---- stasiun geofisika badan meteorologi klimatologi dan geofisika banjarnegara, jawa tengah, menyatakan bahwa gempa yang mengguncang dataran tinggi dieng pukul 19.00 wib berkekuatan 4,8 pada skala richter.\r\n",
      "sample:  pusat gempa diperkirakan ada di desa tanji gugur, kecamatan kabupaten batang ---- pusat gempa diperkirakan berada di desa tanji gugur, kecamatan bawang, kabupaten batang.\r\n",
      "sample:  pvmbg merekomendasikan sementara jalan yang mendekati kawah di desa sumberejo untuk dipertimbangkan secara menyeluruh ---- pvmbg merekomendasikan seluruh jalan yang mendekati kawah timbang di desa sumberejo sementara ditutup.\r\n",
      "sample:  kepala surono dari pusat vulkanologi mitigasi bencana geologi mengatakan, sebanyak 86 kali rekaman gempa yang terjadi pukul 19 00 wib di dataran tinggi dieng ---- kepala pusat vulkanologi dan mitigasi bencana geologi surono mengatakan bahwa gempa yang terjadi di dataran tinggi dieng pukul 19.00 wib terekam sebanyak 86 kali.\r\n",
      "sample:  tutup dilakukan hingga hingga tim pengukur konsentrasi gas di lapangan menyatakan tidak ada gas berbahaya ---- penutupan ini dilakukan hingga tim di lapangan yang mengukur konsentrasi gas menyatakan tidak ada gas yang berbahaya.\r\n",
      "sample:  pvmbg merekomendasikan sementara jalan yang mendekati kawah di desa sumberejo untuk dipertimbangkan secara menyeluruh ---- pvmbg merekomendasikan seluruh jalan yang mendekati kawah timbang di desa sumberejo sementara ditutup.\r\n",
      "sample:  tugas pusat vulkanologi mitigasi bencana geologi terjun-01 untuk memantau aktivitas kawah pertimbangan dan memberikan informasi ---- petugas pusat vulkanologi dan mitigasi bencana geologi diterjunkan untuk memantau aktivitas kawah timbang dan memberikan informasi.\r\n",
      "sample:  data yang dikeluarkan dari pusat vulkanologi mitigasi bencana geologi menyebutkan bahwa merasa gempa sebanyak 86 kali dan gempa mulai ter rekam pada pukul 19 00 wib ---- data yang dikeluarkan dari pusat vulkanologi dan mitigasi bencana geologi menyebutkan gempa mulai terasa pukul 19.00 wib dan telah terekam gempa sebanyak 86 kali.\r\n",
      "sample:  pengungsi dari kabupaten banjarnegara meninggalkan pengungsi pada sabtu pagi ---- pengungsi di kabupaten banjarnegara, pada sabtu pagi mulai meninggalkan pengungsian.\r\n",
      "sample:  stasiun banjarnegara badan meteorologi klimatologi geofisika (geofisika) menyatakan geofisika bahwa gempa berkekuatan 4 8 skala richter mengguncang dataran tinggi dieng pada pukul 19 00 wib ---- stasiun geofisika badan meteorologi klimatologi dan geofisika banjarnegara menyatakan gempa yang mengguncang dataran tinggi dieng pukul 19.00 wib berkekuatan 4,8 skala richter *(sr)*.\r\n",
      "bleu score on test dataset:  27.936075536706568\r\n",
      "mv: cannot move 'result/linearized_penman' to a subdirectory of itself, 'result/linearized_penman/linearized_penman'\r\n"
     ]
    }
   ],
   "source": [
    "!chmod +x ./evaluate_mT5_to_all.sh\n",
    "!./evaluate_mT5_to_all.sh ../train/result/result_linearized_penman linearized_penman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "340f6c4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T13:43:25.232870Z",
     "iopub.status.busy": "2022-06-15T13:43:25.232113Z",
     "iopub.status.idle": "2022-06-15T13:43:25.893189Z",
     "shell.execute_reply": "2022-06-15T13:43:25.892756Z"
    },
    "papermill": {
     "duration": 25.966595,
     "end_time": "2022-06-15T13:43:25.893318",
     "exception": false,
     "start_time": "2022-06-15T13:42:59.926723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: result/ (stored 0%)\r\n",
      "  adding: result/linearized_penman/ (stored 0%)\r\n",
      "  adding: result/linearized_penman/g-gempa-dieng/ (stored 0%)\r\n",
      "  adding: result/linearized_penman/g-gempa-dieng/test_label.txt (deflated 67%)\r\n",
      "  adding: result/linearized_penman/g-gempa-dieng/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/linearized_penman/g-gempa-dieng/test_generations.txt (deflated 66%)\r\n",
      "  adding: result/linearized_penman/f-bunuh-diri/ (stored 0%)\r\n",
      "  adding: result/linearized_penman/f-bunuh-diri/test_label.txt (deflated 68%)\r\n",
      "  adding: result/linearized_penman/f-bunuh-diri/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/linearized_penman/f-bunuh-diri/test_generations.txt (deflated 65%)\r\n",
      "  adding: result/linearized_penman/amr_simple_test/ (stored 0%)\r\n",
      "  adding: result/linearized_penman/amr_simple_test/test_label.txt (deflated 60%)\r\n",
      "  adding: result/linearized_penman/amr_simple_test/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/linearized_penman/amr_simple_test/test_generations.txt (deflated 62%)\r\n",
      "  adding: result/linearized_penman/d-indo-fuji/ (stored 0%)\r\n",
      "  adding: result/linearized_penman/d-indo-fuji/test_label.txt (deflated 86%)\r\n",
      "  adding: result/linearized_penman/d-indo-fuji/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/linearized_penman/d-indo-fuji/test_generations.txt (deflated 86%)\r\n",
      "  adding: result/linearized_penman/b-salah-darat/ (stored 0%)\r\n",
      "  adding: result/linearized_penman/b-salah-darat/test_label.txt (deflated 66%)\r\n",
      "  adding: result/linearized_penman/b-salah-darat/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/linearized_penman/b-salah-darat/test_generations.txt (deflated 65%)\r\n",
      "  adding: result/linearized_penman/c-gedung-roboh/ (stored 0%)\r\n",
      "  adding: result/linearized_penman/c-gedung-roboh/test_label.txt (deflated 62%)\r\n",
      "  adding: result/linearized_penman/c-gedung-roboh/bleu_score_test.txt (stored 0%)\r\n",
      "  adding: result/linearized_penman/c-gedung-roboh/test_generations.txt (deflated 62%)\r\n"
     ]
    }
   ],
   "source": [
    "!zip -r result_with_sta.zip result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "032448db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T13:44:14.933850Z",
     "iopub.status.busy": "2022-06-15T13:44:14.933032Z",
     "iopub.status.idle": "2022-06-15T13:44:15.585297Z",
     "shell.execute_reply": "2022-06-15T13:44:15.584803Z"
    },
    "papermill": {
     "duration": 25.609211,
     "end_time": "2022-06-15T13:44:15.585432",
     "exception": false,
     "start_time": "2022-06-15T13:43:49.976221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate_indoBART.py\t     result\r\n",
      "evaluate_indoBART_to_all.sh  result_with_sta.zip\r\n",
      "evaluate_indoT5.py\t     zeroshot_evaluate_indoBART.py\r\n",
      "evaluate_indoT5_to_all.sh    zeroshot_evaluate_indoBART_to_all.sh\r\n",
      "evaluate_mT5.py\t\t     zeroshot_evaluate_indoT5.py\r\n",
      "evaluate_mT5_to_all.sh\t     zeroshot_evaluate_indoT5_to_all.sh\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d89290c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T13:45:05.317827Z",
     "iopub.status.busy": "2022-06-15T13:45:05.317275Z",
     "iopub.status.idle": "2022-06-15T13:45:05.321796Z",
     "shell.execute_reply": "2022-06-15T13:45:05.322185Z"
    },
    "papermill": {
     "duration": 25.077556,
     "end_time": "2022-06-15T13:45:05.322342",
     "exception": false,
     "start_time": "2022-06-15T13:44:40.244786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04dd98e6",
   "metadata": {
    "papermill": {
     "duration": 24.809636,
     "end_time": "2022-06-15T13:45:54.409670",
     "exception": false,
     "start_time": "2022-06-15T13:45:29.600034",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## linearized penman + tree level embeddings + supervised task adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "993f2c3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T13:46:44.222799Z",
     "iopub.status.busy": "2022-06-15T13:46:44.221860Z",
     "iopub.status.idle": "2022-06-15T13:46:44.223491Z",
     "shell.execute_reply": "2022-06-15T13:46:44.224053Z"
    },
    "papermill": {
     "duration": 25.002929,
     "end_time": "2022-06-15T13:46:44.224209",
     "exception": false,
     "start_time": "2022-06-15T13:46:19.221280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %cd /kaggle/working/amr-to-text-indonesia/tree_level_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2f56a1dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T13:47:33.626117Z",
     "iopub.status.busy": "2022-06-15T13:47:33.625097Z",
     "iopub.status.idle": "2022-06-15T13:47:33.627607Z",
     "shell.execute_reply": "2022-06-15T13:47:33.627125Z"
    },
    "papermill": {
     "duration": 25.213834,
     "end_time": "2022-06-15T13:47:33.627723",
     "exception": false,
     "start_time": "2022-06-15T13:47:08.413889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !rm result/* -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a56b2bdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T13:48:22.748629Z",
     "iopub.status.busy": "2022-06-15T13:48:22.747724Z",
     "iopub.status.idle": "2022-06-15T13:48:22.749470Z",
     "shell.execute_reply": "2022-06-15T13:48:22.749914Z"
    },
    "papermill": {
     "duration": 24.509385,
     "end_time": "2022-06-15T13:48:22.750053",
     "exception": false,
     "start_time": "2022-06-15T13:47:58.240668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !chmod +x train_mT5_on_silver_data.sh\n",
    "# !./train_mT5_on_silver_data.sh linearized_penman_with_tree_level ../amr-indo-dataset/data_154k_raw_silver_amr_indo4b_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "90e6b509",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T13:49:12.614893Z",
     "iopub.status.busy": "2022-06-15T13:49:12.613929Z",
     "iopub.status.idle": "2022-06-15T13:49:12.615586Z",
     "shell.execute_reply": "2022-06-15T13:49:12.616102Z"
    },
    "papermill": {
     "duration": 25.149464,
     "end_time": "2022-06-15T13:49:12.616281",
     "exception": false,
     "start_time": "2022-06-15T13:48:47.466817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python train_mT5.py --model_type mT5 --n_epochs 2 --lr 0.0001 --data_folder ../data/preprocessed_data/linearized_penman_with_tree_level  --result_folder result --resume_from_checkpoint True --saved_model_folder_path result/result_supervised_task_adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8a67cf60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T13:50:02.045973Z",
     "iopub.status.busy": "2022-06-15T13:50:02.045095Z",
     "iopub.status.idle": "2022-06-15T13:50:02.047599Z",
     "shell.execute_reply": "2022-06-15T13:50:02.047137Z"
    },
    "papermill": {
     "duration": 24.587777,
     "end_time": "2022-06-15T13:50:02.047714",
     "exception": false,
     "start_time": "2022-06-15T13:49:37.459937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !chmod +x ./evaluate_mT5_to_all.sh\n",
    "# !./evaluate_mT5_to_all.sh result linearized_penman_with_tree_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2e548527",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T13:50:52.054758Z",
     "iopub.status.busy": "2022-06-15T13:50:52.053806Z",
     "iopub.status.idle": "2022-06-15T13:50:52.056355Z",
     "shell.execute_reply": "2022-06-15T13:50:52.055789Z"
    },
    "papermill": {
     "duration": 25.107529,
     "end_time": "2022-06-15T13:50:52.056475",
     "exception": false,
     "start_time": "2022-06-15T13:50:26.948946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !zip -r result_with_sta.zip result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 12230.528522,
   "end_time": "2022-06-15T13:51:17.387976",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-06-15T10:27:26.859454",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
